{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c925d783-cebd-4765-a80d-b4ebc8e4bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"AIzaSyCHRr6uq4Q0rAKDoQ7VbYrpmf1-xehFqtk\"\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8deebe9c-10eb-46a8-9d95-ecf77f2c86e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q --upgrade langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "100809c6-4d2b-4f85-8e51-191809c8e374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.7\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "88d263ba-1ecd-48c1-abbf-23f3f5ade7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankit\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c64f5307-939a-4179-bdfd-ff9fc0a6a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q youtube-transcript-api langchain-community  langchain-anthropic faiss-cpu tiktoken python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dadb5ad1-d93f-4118-8b62-f8118a486345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5edae24d-bd02-4a20-8f3f-97f3403699df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text splitter working\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "print(\"Text splitter working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff53e3-768c-4df4-93de-88cb7be6db12",
   "metadata": {},
   "source": [
    "## Step 1 -> Document Ingestion(Indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "938d4ca3-9225-4579-9ffd-965b08f8fcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello everyone and uh welcome to lecture 9 of CM295. So as you know uh today is a kind of a special day because uh we're having the last lecture of the entire course. Um so the menu for today will be a little different compared to usual. uh we're going to try to divide the lecture in three parts. So in the first part we're going to recap actually what we did in the entire class just to see how different pieces kind of fit together. Uh in the second part we will look at some topics that are particularly trending uh in 2025 and what we think are going to be trending in the near future. And then uh the third part will be more uh way for us to just conclude and uh next steps uh for all of you. Does that sound good? Cool. So with that uh we're going to start with the first part which uh what I mentioned is about recapping what we did this entire quarter. So nothing new here. It's just a way for us to piece everything together. So if you remember u lot of weeks ago I believe it's like maybe 10 weeks ago we had lecture one which was focused on understanding what transformers were. So at the very beginning of the class we didn't even know how we could process text. So I guess the first step that we saw was this tokenization step which consists of dividing the input into atomic units. And so here the way you we divide the text is something that is arbitrary in some sense. So we have different algorithms that allow us to do that. Uh and we saw that the most common tokenization algorithm is the subword level tokenizer. And we saw that some of the advantages were that um roots of words could be reused um and leveraged especially when it came to representing those tokens. And speaking of representation, once we were able to divide the input text into atomic units, aka tokens, the next step for us was to learn how to represent these embeddings. So if you remember, we saw some methods that were very popular back then. So one of them was called wordtovec and the representation was learned from a proxy task which was something like predicting the center word or predicting the context words. But then we saw that this way of learning representations had some limitations. One of which was that these representations were not contextaware. Meaning that uh if a word is in a given sentence or in another sentence they will both have the same like that word will have the same representation in both sentences. And so for that reason we saw some uh other methods that were popular in the 2010s. one of which was RNN's if you remember. So RNN's um had this recurrent structure which process tokens one at a time and kept an internal representation of the sequence so far. But then we saw that a big limitation of this was this problem of long range dependency and in particular the fact that uh tokens that were encoded far in the past were not um quantities that were able to be kept I guess as the sequence got longer and this is the reason why we saw the central idea of this whole class which is the idea of self attention where tokens s can actually attend to one another regardless of where they are placed in the sequence. So you can think of this as a direct link. And so uh this for instance is what we saw. We we saw that there are like three main uh terminologies that people use. So query, key and value. So typically you want to know how similar a query is compared to the keys in the in the sequence and you quantify that by um taking some dot products that's kind of scaled and softmaxed and then you have the corresponding value that is taken. So at the end of the day we obtain some kind of weighted average of all the tokens that are in the sequence. And then uh you may also be familiar now with this formula. So soft max of q krpose over square root of dk um time v. So this is the matrix formulation of what I mentioned here which uh is able to process these computations in a very efficient way and it's something that uh today's hardware is well equipped to do and then we finish the first lecture by going through the architecture that is the foundation of modern day LLMs which is the transformer and we saw that there are two u not notable parts in the transformer. So one was the encoder in the left part of the uh um the figure and then the right part is the decoder and we saw how this was applied in the case of translation. So at the end of the first lecture we saw what motivated us to end up with the transformer and we saw that transformer was working quite well in the case of uh translation and so in the next lecture what we saw was what were the little improvements that people have made to this architecture since it was released and if you remember it was in 2017 that it was publicublished. So one particular improvement that people have made is in the way we consider positions because in the original transformer paper positions were encoded in an absolute way as in each position had its own embedding and this embedding was added to the token embedding. But then if we think about it positions actually we don't really care about the absolute position. We care about the relative position between tokens and in particular we care about how far tokens are in the self attention computation. Which is why we saw this methods that is now quite popular called rotary position embeddings aka rope that is now quite used. And it is a method that rotates query and keys both of which happen in the self attention computation. And so here um what is uh quantified here is purely a function of the relative distance between um two tokens and not only that it is something that is uh taken care of in the self attention layer which is what we care about. So this was one big improvement and then we saw some other improvements especially when it came to how the multi head attention um layer multi head attention layer was composed of and in particular we saw that it was possible for us to have some groupings of the matrices that we learn. So we don't need to have one matrix one projection matrix per head for let's say keys and values. We can actually uh group them. So this is uh for instance what is mentioned here. So group query attention. Um and then we also saw some other techniques that I have not represented here like for instance the normalization layer in the transformer which here happens after each sub layer but I guess nowadays people have tried moving the normalization piece before the sub layer. So here it's the postnorm version and then the before the sub layer part is called the prenorm version. And then the last thing that we saw was that from this transformer architecture there were a lot of derived models that were based from that. So we saw that if we only keep the encoder part we could compute very meaningful embeddings. If you remember there was this um uh kind of landmark paper on encoder only model which is birds which was heavily used in the context of classification because it relied on the encoded embedding of the CLS token. And so that was one. But then we also saw that there was a number of other kinds of models all more or less derived from the transformer. So you could only keep the encoder which was for birds. You could only keep the decoder which is for instance for GPT and you could also have both which is for instance the case of T5. And one particular aspect of each of these models is that encoder only is not able in the way that we saw is not able to generate text but is able to generate embeddings which can be used for downstream tasks. But then encoder decoder models like T5 or decoder only models like GPT they can be auto reggressive and generate text. The paradigm can be text in text out. And with that we then focused on what now everyone calls large language models which are transformerbased models specifically texttoext models. So decoder only transformer-based models and we saw that people have come up with a lot of new tricks now because um you know these models as the name uh indicates um people have scaled them up. But then one question was uh kind of kind of thrown which is do you actually need all these parameters to just do a forward pass. So we saw uh one kind of uh variant which was based on mixture of experts. So what mixture of experts are is instead of running everything through the whole entire model, you're going to instead have a number of experts that you're going to activate in a sparse way. So for instance, for one input, you're going to just activate just a subset and then for another input you're going to activate another subset so that you don't need to do all the computations all the time. And we saw that these mixture of experts they were used in LLMs in particular in the feed for neural network layer. So here you would have experts as being different feed for neural networks and you would have a gating mechanism that would reroute to the correct feed for neural network. And then we also saw that some papers were also able to kind of produce some nice visualization in terms of uh I guess which token gets routed to which experts because this rerouting we saw that it was done at the token level. And so one reason why it's done at the token level is to be able to I guess smartly put the experts on different pieces of hardware, different GPUs and then kind of parallelize the computation a little bit more. And then we also saw that these LLMs they always are tasked with predicting the next token. And in order to predict the next token, we were interested in uh I guess how we were uh you know doing this. And so one particular uh method that people use is just sample sample from the output distribution. So you have let's say given an input you have a distribution of probabilities of what the next token would be that is output by the model. And what you do is instead of let's say taking the highest probability which is called the greedy decoding uh greedy kind of decoding you actually sample. So it introduces some randomness and allows the model to produce kind of a bigger variety of uh kinds of outputs. And we saw uh that you could adjust how how much I guess variety you want in your output by tweaking a hyperparameter called temperature. So very low temperature leads to very spiky distribution. So more deterministic outputs and higher temperatures are I guess a bit more uh random a bit more creative. Okay. So until then we saw what LLMs were, how they were based on the transformer, how they connected to the architecture that we saw in the first lecture and then in lecture lecture four we saw how people actually trained those LLMs because as I mentioned these LLMs are large and so you cannot kind of naively fit them in your hardware. you need to be a little bit smart about it. So in particular, what people have uh kind of noticed in the early 2020s is that the bigger your model is, the better your performance. So people just started building bigger and bigger models. So here in the uh illustration we saw that so on the y- axis is the test loss. So the lower the better. So we saw that the more compute you use the better your tests uh performance and same with uh increasing the data set size and same with increasing the number of parameters but then as you know compute is not infinite. So there was a natural question that came out of the community which was okay if we give you a given budget a given compute budget can you choose I guess some quote unquote optimal number of parameters and data set size on which you want to train your model. And so we saw that there was this paper that was um published in the early 2020s uh which actually studied the relationship between um I guess if you vary the data set size and uh the size of your model and the performance on the test set. And then we saw that actually most models at the time were what we say undertrained because they were too big compared to the data set that they were trained on. Like the data set that they were trained on it was not as big as they should have been. And so in particular there was a kind of a rule of thumb that came out of this which was if you have a given number of parameters in your model you should at least train it on 20 times the number of parameters in terms of tokens. So for instance, if you have uh a 100 billion parameter model, you should train it on at least two trillion tokens because two trillion is 100 billion * 20. So that's kind of the rule of thumb that people have uh used and then you know as I mentioned previously you know these models are huge. So people have tried to also make the computation more efficient and so there was this uh method that we saw which is actually quite important called flash attention and flash attention is a method that leverages the strength the strength of the underlying hardware and in particular it looks at so GPUs more particularly it looks at the kinds of memory memories that a GPU has. So it has a big but slow memory and a small but fast memory. So the HPM and the SRAMM respectively. And we saw that this method tries to minimize the number of reads and writes to the big and slow memory to the HPM. And so the the way it was doing this was to divide the computation in uh little bits that it would send to uh the SRAMM which is the small but fast memory so that it can do the end to end computation and then send it back to where it was in order to do the full end toend computation. So that method is an exact method meaning that we're not doing any approximations to the results but it led to significant speedups and in particular there was this second idea from uh the paper which is a kind of an important one as well which was that sometimes it's okay for you to not store results. it's okay for you to just throw them out and then recomputee when you need them again. So there is this idea of recomputation using what I described which led to faster run times even though we were doing more computations. So that was flash flash attention and uh we also saw a number of other methods that were meant to I guess parallelize the computation. So we saw uh data parallelism which was this idea of not having all your data be processed on a single GPU but instead divided into uh kind of multiple places. And then we had the second method which was model parallelism where even for a given forward pass you would actually involve multiple GPUs. So anyway, there were a lot of very interesting techniques, a lot of different uh ideas about how to train this model in an efficient way. And uh in particular um so what I described here is mostly important for the first step of uh the training process of an LLM which is called the pre-training which is meant to teach the model about the structure of language about the structure of codes. Uh and in particular this model was trained with huge amounts of data. So think about trillions of tokens or even tens of trillions of tokens. Um and so that first step goes from an initialized model to a model that is able to autocomplete because it is trained with an objective of predicting the next token. So at the end of this first stage, you have a model that knows how to autocomplete, but you have a model that is not very helpful because it only knows how to complete things. So in order to have the model be useful for our use cases, we had this second step which is called the fine-tuning step. uh where we teach the model on the kinds of input output pairs that we want it to perform well. So this is also called uh the SFT stage supervised fine-tuning stage. And at the end of this second step, we have a model that not only knows the structure of text and codes, but also is able to behave in the way you want. But so far up until step number two, we have only taught our model what to do. We have not taught it what to not do. And this is why we had our third step which was the preference tuning step where we took our model that went through the pre-training stage that went to the SFT stage and now we want to inject some negative signal as well as in I want you to prefer this compared to this output. And this third step uses preference data. So like the name uh suggests so preference tuning uses preference data which is typically pair-wise data where humans say okay I prefer this output compared to that output. And typically the model here is able to align the kind of output it produces with human preferences that could be along the dimension of uh usefulness of safety, friendliness, tone. Um there's a bunch of different dimensions but uh yeah so that's what is happening in this third step. And in this third step, it's actually in lecture five that we dug into what that third step was about. So if you remember uh we had drawn a parallel between the way our LLM produces tokens and I guess what people in the reinforcement learning field um I guess consider how uh given policy is uh interacting with some environment and performing some action and being in some states. uh and the reason why we drew drew that parallel was to be able to leverage some RLbased techniques in order to train our model. So in this case we said our LLM is a little bit like a policy. So given some state which is the input it has received so far it can perform the next action and in this case it is to predict the next token and this prediction is made in the environment of tokens and when we u like predict a completion what we do is at the end of the day we have some signal some reward part which can be the human preference. So this is the parallel we drew with the RL worlds and with that in mind we talked about rewards but the problem is that rewards are only available for a limited set of data which is why we saw how to model rewards. So we saw this formula if you remember it's called the Bradley Terry formulation which um models how the probability of an output being better than another one is as a function of I guess two scores like the score of output I and the score of output J. And we saw that reward models they are typically trained by having this formulation in mind in a pair-wise fashion. So what this means is a reward model you give it two outputs. You say this one is good, this one is bad and then I want you to say this one is good. You train it in a pair wise fashion. But then your model is actually predicting always two scores. It's always predicting the score RA I for output I RJ for output J. Um and so at inference time you're only giving it one output. So I think that's like one subtlety like we train it in a pair wise way but at inference time we're kind of using it in a in an individual way if that makes sense. And so once we trained our reward model using this formulation then we were able to use it to steer our LLM towards the direction that we care about. So if you remember the way we steer our LLM in the direction of human preferences is to give it a prompt so that it can produce a completion aka a rollout or in simpler terms an an answer. And then we take this prompt, we take this answer, we put them both in the reward model that tells us how good the model response is. And depending on what the reward model says, we can tune the weights of the LLM in a way that maximizes human or the reward that we saw which is trained on human preferences. And the loss function of this RL uh setup is typically something that tries to maximize rewards but also keep the model close to the base model. And here by base model we mean the SFT model. And the reason why we want that is because this reward is imperfect. So we saw this uh phenomenon of reward hacking where your reward can be imperfect and the LLM can exploit its imperfect nature to tune it in a way that actually does not align with what you want it to be. So you want the LLM to not be too far from the base model which is actually already a good model. So it's a way to regularize that if you want and you also want the iteration updates to not be too big either. So you typically have these two constraints. You don't want it to deviate too much from the base model, but you don't want it to deviate too much from the previous RL iteration. And then just as a reminder, I think this was lecture five. I think was the most technically challenging of the whole class. So completely fine if the first time you were like you know what's happening. Uh but hopefully now it should be a little bit more more clear. Uh cool. And then after lecture five we're like okay we've done a lot of uh hard work. So uh the good thing is you know we're in 2025 and in the past 12 months or now 14 months we've seen a lot of models that were being released with these reasoning capabilities and the way they were trained to exhibit these advanced reasoning capabilities was actually leveraging a lot of the techniques that we saw in lecture 5 just like oral based techniques. And in particular, what we want our LLM to do is to output a reasoning chain before producing the final answer. And the reason why we wanted to do that is because people have seen that it improves the performance of the model. And so it's actually relying on this idea of chain of thoughts, which I believe we saw at lecture three. which is a prompting technique to have your model output the reasoning before outputting the the response. So long story short, up until lecture six, our LLM was having a prompt as input directly outputting the output. But in lecture seven, we said, sorry, in lecture six, we said, uh, well, let's have our LLM actually first output a reasoning chain that the user may or may not have access to before outputting the final answer. So you want to teach the LM to do that. So how do you do that? Well, first before doing this, I just want to show you this chart which we saw which is the performance of uh the model as we're teaching it to produce these reasoning chains. So people have typically measured uh the improvement in performance by comparing it to uh I guess certain benchmarks and this one is a popular one the AIM benchmark which is the math math benchmark and we saw that as the training progresses the accuracy number of uh I guess what the LLM outputs is increasing. But back to what I was I was saying uh the key technique that we use to teach the model how to output these reasoning chains is leveraging the RL techniques that we saw in lecture five. And in particular um up until now we saw PO which was the main RL algorithm that people were using up to maybe last year and now people are kind of prioritizing GRPO as an R algorithm in order to teach the model to be better at reasoning tasks. And there are several reasons to do to to that that I will explicit right now. So we saw this illustration that compared how GRPO was differing with PO and if you can see in the graph uh there are a few things that are different. The first thing is that GRPO does not rely on a value model. So, who remembers what a value model is? Yep. Yes. Exactly. So, the value function is trying to predict what the reward would be if you um were to follow the policy of the LLM. Um, and I guess it's a way to have some baseline as to how good some predictions are. You want to make it more relative. So the value function is a way for us to make these uh rewards a little bit more relative to one another. Um, and so that's what that's how PPU was doing this. So it was having a value model that was um making these predictions and then we had uh this generalized advantage estimation method that was combining the reward predictions with the value function predictions in order to have what we call advantages. So advantages is how good your output is compared to some baseline. But then in contrast to that, GRPL said, \"Okay, tree, we don't need a value function because it's, you know, too expensive to to train, to maintain. What we're going to do instead is generate several completions and then have some formula that compares the rewards of these completion these completions to one another. So it's going to have some relative effect in a sense that it will make things more relative and in doing so you are actually not uh needed to maintain and train a value function and that's like one big difference compared to PO. Um and uh the second big difference which is not represented in this illustration uh is that uh GRPO is typically an algorithm that people have used in the context of teaching your model to be better at reasoning tasks. And so we saw that these kinds of problems have a verifiable reward because when you complete a math problem, you actually know the answer you need to get to. So you don't need to train a reward model to tell you how good your final answer is because you you already know the answer. And so we saw that GRPO was in particular used in the context of when you actually don't even need a reward model when you actually have a verifiable reward. So at the end of the day, the only two models you need to keep are the policy model and the reference model to be able to just compare how far you are from the reference model. Cool. Um, I know this one was also a challenging class, I guess. So far so good. And this is also on on the final. So, which is why I'm I'm taking things more slowly for this second part of the recap. So, is everything good so far? Yeah. Okay. Perfect. We also saw some extensions of GRPO. So if you remember there was um some kind of bias that was um a result of the loss function of GRPO having some normalization term that penalized tokens that were in shorter outputs. So we saw that if you use GRPO in its original case in its original form we saw that after a certain point the algorithm will incentivize your model to produce longer and longer answers longer and longer incorrect answers. And the reason why it does that is because relative to short incorrect answers, it penalizes less long incorrect answers. And so this is the reason why there are some extensions that people have worked on this year. One of which was uh GRPO done rights. So we saw like um that they basically removed the normalization term and there was another method that we saw it was called depo dapo which also had some variance and that's for reasoning models and then lecture seven we had a model that you know we knew how to train it we knew how to uh use it for uh reasoning tasks how to train it to be better but now we wanted the model to be useful and interacting with outside systems. So we saw one technique that is kind of an an essential technique called rag short for retrieval augmented generation that is meant for you to be able to fetch relevant documents from some knowledge base in order to answer a question or answer a prompt. And the reason why you want to do that is that the knowledge of your LLM is including up to the data that is up to the knowledge cut updates which is the max dates of what your LM has been trained on. And from a practical standpoint, I guess from what we see nowadays, you're typically not training your LLM daily or continuously. And so in cases where you need your LLM to know about things that happened recently or about things that happened that were not in your LM training data, you want your LLM to have access to such information. And so that's how rag is very useful. So we saw that rag dependent very heavily on the way it retrieves data. So we saw that the retrieval part was mainly composed of two steps. So the first one was candidate retrieval which use which uses a by encoder kind of setup where you're basically doing some semantic search. So you're computing the embedding of the query. you have some precomputed embeddings of the documents in your knowledge base and you're taking the ones that maximize some similarity score like let's say some cosign similarity. So the this first step is allowing you to retrieve um I guess a filtered version of the potential documents and then typically you have a second step which is called ranking or reranking because the first step already gives you a ranking which has typically a more sophisticated setup. So it's a cross encoder kind of setup where you have your query and your document that are both fed to some model and produces a more precise score and then you use this final score to rank the final results and you typically choose the top let's say K and then you add them to your prompt. So it's the augmented part. So retrieval is everything I mentioned so far and then once you have the relevant documents you add them in your prompt which is the augmented part and you generate the answer. So the reason why I'm taking so much time on rag is rag is such an important concept also if you were to you know have interviews or you know also maybe in the exam who knows um so I think it's a it's an important concept to uh to have in mind the second one that we saw was tool calling and tool calling is allowing your LLM to leverage tools. The way it does that is in two steps. The first step is for your model to know which API there is out there. At the end of which your LLM says, okay, I want to use this API and I want to use it with these arguments. And then you have an intermediary step which is you just run your API with these arguments. And then the second step is you feed the results of this operation back to the LLM which then produces a final answer. So that's how tool calling works. So if you say to your LM okay you can use this use this API this is how your LM would leverage that. And then we saw that modern-day agentic workflows were leveraging both rag and tool calling as key methods to um perform actions. And we saw an example detail example uh which was such that you had some inputs and then your LLM had a series of different calls um in order to perform some action and then at the end of it it retrieves sorry it returns an answer. Cool. And then last lecture we saw how we could evaluate LLMs which is a much tougher thing to do now that LLMs can do a bunch of different things. So we first saw that there were some rulebased metrics that people were using before LMS came into play. metrics that you may have heard like blur, rouge, meor and so on, but the main limitation was that they were not considering how language could differ but still be correct. And so uh this key idea that we saw was why not leverage LLMs to evaluate outputs. And so there is this uh key idea of LLM as a judge where you receive as input the prompts the model response along with the criteria that you want the response to be evaluated on. And then you want your LM messages to output two things. The first one is a rationale for why a given score is output. along with that score. So nowadays, LM as a judges, they're typically outputting a binary response either uh pass or fail, true or false, just because it's easier. And we're also having the rational be output before the score because in practice it's something that also improves the performance of uh the element as a judge a little bit if you want like reasoning models do by outputting the reasoning chain before they output the answer. But then we also saw that there were uh some biases that came with this approach. We saw position bias which is the way you present the elements to compare matters. So if you present something first then maybe the LLM will just prioritize that first. Uh so there was position bias, there was verbosity bias which is your LLM just preferring longer outputs. Uh and self-enhancement bias was another one where it prefers its own outputs. Um and then we also saw a number of benchmarks uh that people use nowadays in order to say how great their LLM is. So if you see the releases that come out, there are typically a bunch of metrics across a number of different benchmarks that people know about. So that spans uh knowledge, the ability to reason, coding which is very important because a lot of applications are coding related and then safety and then this is not an an extensive list so there's actually many more dimensions. Um so yeah I think that's where we stopped and it was last lecture and this is all you are expected to know for the final. Everything after that is not going to be part of the final. Any questions on this so far? Cool. Okay. I'm expecting a hundreds for everyone for the final. But yeah, um I would say what I went through is going to be foundational for the final. So I guess if you understood everything I said, I think you're going to be ready for the final. So um yeah, but if you have any questions, you know, Shervin and I are always here um to uh Oh, yeah. You have a question? Yes. So the question is, is the scope for the final of lecture 5 to lecture 8? Yes. So for midterm it was lectures 1 2 3 4 and this one is 5 6 7 8. So I guess it's u equal equal size. Cool. Okay, great. So, with that said, we just finished recapping this entire quarter worth of lectures and now we're going to go to the second item of today's menu, which is looking at some trending topics. And so, I'm going to start with the first one. And I'm going to introduce it as follows. So if you remember we saw that the transformer was a concept and an architecture that was first introduced in the context of machine translation. So it performed great. People said okay it performs great on machine translation why not try it on other text tasks. So they tried it performs great but now the question is can you not use it for things other than text it's a natural question right so in order to answer that question I just want us to remind ourselves that this architecture is relying on this concept of self attention and this is what is making the transformer work so Well, so if we just recap what self attention is, this uh illustration kind of does the job quite well. You have a query and then you have a bunch of other elements which are represented by your keys and your values and you want to know which other elements are actually relevant in order to compute the embedding for that query. So right now we have only used tokens you know text tokens but text tokens they're actually vectors. So if you take those vectors and you actually represent something else than text like for instance parts of an image. The question is would the transformer based on that kind of input also perform well. And so here the key question that I want to ask is how can we adapt our transformer to work on non-ext input and for instance here we can think of image understanding input. So you have some image and so it's a traditional um computer vision task where you want to know in which class this image belongs to. So you want to know if having some transformer-based architecture would work well in that situation. Well, the answer to that is well, first in order to adapt it to this task, you would take the encoder part of the transformer because in order to understand what is in an image, you need to classify that image in some sense. So if you remember if there's one model in what we saw that was working very well for classification was BERT because BERT is encoder only. It computes meaningful embeddings that can then be used for projection purposes or for classification purposes. So it's a very natural choice that here we would have. So here we would just keep the encoder part of the transformer and then have the self attention mechanism come into play and um compute meaningful embeddings that we could then project for our relevant task. And this is exactly what a group of researchers did back in 2020. So have you heard of VIT vision transformer? Yeah. No. Yeah. So what I described here is exactly what they did. So they took an image, they divided that image into patches. Those patches were represented by some vectors. And of course you have some some kind of position information that allows you to know where your your patch is in the image. And then you just put it through the transformer encoder. So the encoder part of the transformer and you compute the representation corresponding to the CLS class very similar to birds and you would just project that representation over some classes of interest and then you would perform your um your uh I guess computation uh like this. So what that paper found was that if you train such a model on a lot of image data on a lot of image data you then outperform these traditional convolutional neural network kind of methods. And so those kind of uh remarkable because so why is it remarkable? Because in the vision case, so there is this concept of inductive bias where you want to gear your model towards looking at certain things in order to to deduce the results. So convolutional neural networks are a kind of model that are designed in a way for you to look at the image in some you know sliding way. You know you look at your image a little bit like you would look at it in practice as a human. And people had hypothesized that such such a bias such an indictive bias would actually make sense for something like a vision task. So you contrast that with the vision transformer which is actually letting all parts of the image attend to one another which has on the other side very low inductive bias. So what this paper showed was if you give your model enough data then it will actually learn how to classify um I guess your images in this in this classes. So this was like kind of a remarkable results. Um so I think this is like pretty remarkable and a nice extension of everything we saw. So with that in mind, um I want us to just go through an end toend example of how you would process an image and go through that um vit so vision transformer in order to make your um prediction. So here you would take uh like your favorite image that you would just split into patches. So here you can think of you predefining some uh fixed size patches. So here I would say like 3x3 let's say and then each patch has some um fixed number of pixels and then what you do is for each patch you try to have some vector representation. So you can think of each patch as so what is a patch? So it's composed of pixels. So if each pixel has three values which correspond to red, green and blue, then you can find a way to project those on some lower dimensional flattened space and you can learn how you would project that through some kind of linear layer. So long story short, you just find a way to associate a vector to each of these patches which you you then represent every single one of your inputs. And then you have of course a special embedding for the CLS token which you can also learn. And you add the position embedding. So you do the same for all of your inputs and then very similar to birds just put that through your encoder. Let everyone interact with everyone and then at the end of the day what you care about is a representation of the input that is meaningful. So typically people take the encoded embedding of the CLS token. So the reason why they take that is one because it's a convention but second one is this CLS token. So the encoded embedding is actually an embedding that has interacted with all other tokens through this self attention mechanism. So it has seen everything and then you would project that CLS token encoded embedding onto some class through a feed for neural network in order to predict your final class. So in this case we know it's a picture of a teddy bear. So here we would want the model to classify this as a teddy bear. So far so good. Does that make sense? Cool. Uh, so now, okay, we know how to process image input, right? Now, so another question is how would you have your LLM answer questions about your image, which is something that you can do actually nowadays. Like if you open chat GPT you can input an image and ask it questions. So you would have two kinds of inputs. So you would have an image which we saw we can find a way to represent and then the text which you now know very well how to represent like with tokens. So the way you would allow the model or let the model process. All of this is typically as follows. So there are like a couple of methods. The first one is the more most common one which is you just feed everything as input. So the image token as input, the um text tokens as input and you have some representation to have the model just know that these are image tokens and this is like text token and then you let it generate an answer in a decoder only fashion, auto reggressive fashion exactly like you would do it the first method and a lot of such models are designed that way. So there is for instance a very popular uh open weight I believe um vision language model VLM that's what they are called uh model called lava and this is how they do it. So they have some encoder on the image parts uh that produces some tokens that are then uh concatenated with text tokens that are input into the LLM. So that's one method. The second method which is less common is to have the images be input at the cross attention layer. So here what you would do is you have your text input and then your image input. You don't put it in the input. You actually let it interact with the text tokens within the cross attention layer. And this is something that for instance llama 3 had represented in their paper. This technique is typically less common. The first one is more common. So I guess what I want to say is CME 295 focused on the transformer specifically in the case of texttoext problems. So text generation is all you know this class but we also have the transformer that was used for non-ext applications. So here we saw image understanding so vision understanding with the vit and then uh we will not have the time to say this now but also for image generation tasks we can also have parts of the transformer be used in that architecture and so you may uh you know hear about diffusion transformer or multimodel diffusion transformer that's actually rely on the self attention mechanism and um this is actually not an exhaustive list. This is also something that has been used in other uh domains like recommendations, speech and so on. So I guess I what I want you to remember from this is that transformers were like was an architecture that performed very well for machine translation tasks but then it proved to perform very well for other text related tasks and it was then reused in a bunch of other domains which also proved to be quite successful. So I would just encourage you after this class to also keep an open mind for non-ext related transformer applications and the ones that I mentioned here are maybe just a few first few pointers into the kind of papers that you can look at. Cool. So here we said that transformer was something that came from the text world that's also uh useful and used in other worlds. Now I want to tell you about something else that was uh I guess used and useful in the non-ext world that may be useful in the text world and I want to tell you about diffusionbased LLMs. So who has heard the term diffusion? Who knows about diffusion? Yeah, cool. So we will see how we can apply that to LLM. So this is a very trendy topic. I believe the first paper started in the early 2020s, but I guess it's only now that people are starting to have this really work. I just want to start with a motivation which is that up until now we have taken for granted the fact that our LLM is an auto reggressive LLM and by auto reggressive what do I mean by that? So it takes some input and what the LLM tries to do is to predict the next token. So given everything so far, we predict the next token. We do that and then we take that token that we just predicted along with everything that we have predicted so far and then we again predict the next token. We predict it and we go again and again up until you know finishing the sequence with that end of sequence token which makes the generation stop. So this is a true auto reggressive generation as in we take the input so far in order to predict the next token and then we repeat this process until the end. So it's something that people now try to kind of give it a name which is like auto reggressive model kind of model. So, ARM, if you kind of see this notation, that's what it means. Um, the problem with that kind of paradigm is that inference time generation is actually not something you can parallelize because you always need what's before in order to predict the next one. But I just want to say that inference time generation is not paralyzable. But training is paralyzable. So if you remember the way we do training is we input all the tokens that we want our model to predict and then we let the model generate tokens out of this. So basically in a decoder only setting you have this causal mask which lets your model not cheat if you want and not use the future ones. So I just want to say that when I say that uh this paradigm is not paralyzable I just want to emphasize on the fact that it's a inference time that I'm saying training time you can actually paralyze that quite well. So as I mentioned that's one of the reasons why people have tried to look at other paradigms and in particular um so if you know about diffusion you know that it works very well for the vision domain and so people have tried adapting this paradigm for the text generation case and uh so this is like a bunch of screenshots we took from announcement that happened this year. So for instance uh earlier this year there was an experimental text diffusion model from Google that they presented during the IO event um which was very impressive because it led to a lot of speedups. And then we have some um like different startups. So Inception is one of them uh that made headlines I believe a couple of weeks ago or last week no sorry a month ago um that also are pursuing this route. Um, so all of that to say that this direction is a very trendy and hot direction that potentially has a lot of promise. But the key issue with this is that text is discrete whereas images are continuous. And we're going to see why that distinction that I just made matters. So I'm going to try to explain to you what diffusion is in two minutes. So in the image world in order to generate an image what people typically do is they start from noise and then they try to generate some image. Now now you may wonder okay why noise? Well, you cannot do something that's um you know uh auto reggressive because I guess like if you were to say okay let's predict the pixels one at a time uh it's just not tractable because there are many pixel in in an image and this is typically not how you produce uh an image but some other reasons are that uh noise is just something that you can model very well with uh some very popular distributions so gausian distribution if you know about it has very nice properties. Um, also noise is very easy to sample. So, it's very easy to start with that. Um, noise is also a way for you to introduce randomness because you don't necessarily want to always produce the same image. You want to have uh the uh I guess choice of generating images that are slightly different from one another. And uh just mathematically it works quite well. And um speaking of that, the goal is to learn some transformation that would allow you to go from noise to the target image distribution. So all of what I said here is just kind of reasons for me to tell you, okay, noise is actually a choice that is quite natural to start with in order to generate an image. And to give you an analogy, um let's suppose you're a sculpture sculptor. So the person who does sculptures. So if you want to do a sculpture, you typically start with some rock. But then rocks are, you know, different from one another. They always have uh things that are unique to them. And still you would focus on what to remove in order to obtain the end sculpture. So you can think of the rock as being your noise and your end result as being your target data distribution. So I just want to have this quote by Michelangelo. So the sculpture is already complete within the marble block before I start my work. It is already there. I just have to chisel away the superus material. The reason why I'm reading that is you can have a a nice analogy between what Michelangelo said and the process of denoising the noise to get an image. So this is all just motivating how image generation is done. So you start from noise and you want to generate an image. So the way you do that for diffusion is to learn some transformation that would allow you to go from noise to image. So you have two steps. I mean you have more than two steps but we have these two main steps for diffusion models where you first want to start from clean images and you add noise gradually until until you obtain some very noisy image and then from that what diffusion models try to do is to predict the noise to remove in order to obtain the image. So, it's a little bit like, you know, you're the sculpture sculpture person and you have your rock. You just want to learn what pieces of rock you need to remove in order to obtain your final piece of art. So, this is what diffusion is. So it works pretty well because noise as I mentioned is typically something that people draw from a gausian distribution. Gausian distributions are mathematically very well defined have a lot of nice properties. So that's why they work so well. But now the question is how would you adapt this to the text world? Because in the text world as you know we're talking about tokens. Tokens are discrete. So there's not this concept of you know adding noise. Cannot have that. So pe what people have tried to um to do was to find a text equivalent that would make sense. And this is what the current research points to which is that noise is to images what the mask token is to text. So mask is just a way for us to just not have the information coming from one part of the sequence. And I just want to go through the revised two-step process that we saw here for text. So here for the forward process instead of noising your input you would just have more and more inputs that would be masked. So that's the for process and at the end you would just obtain a sequence full of mass tokens. So what you want to do is to learn some model that allows you to unmask these mass tokens in a way that reconstructs the original sentence. So there's some math that goes into it. Obviously in a few minutes we will not have time to go into that. But I just want to emphasize on the key idea which is you want to do diffusion but in a way that makes sense for text inputs. And the way the way it would make sense is to consider the noise for images as being mask tokens for text input. Cool. And so with that in mind, you have a bunch of models that are being released these days which are called masked diffusion models, MDM. So whenever you see MDM now, you know what kind of model we're talking about. So notations are still very um not very well defined. So it may change in the future. But one other term you will see out there is also DLLM diffusion based LLM and this is what it's doing. So instead of predicting a token in an auto reggressive fashion like one at a time, what it does is that at inference time it goes from a completely masked input sequence and it tries to predict what tokens were behind these mass tokens. So of course um you know in a real life setting you would have some prompts here. you would have some prompts. So of course in order to predict this answer you would have some conditioning. So you would tell your model okay given this prompts you're going to start with all these mass tokens just try to predict what the answer is. So in case you're having trouble with the intuition. So I also had trouble in the beginning you know why would it make sense for text to be solved in a diffusion manner because typically when you write you write one word at a time. So one helpful way to think about this is let's suppose you want to write a speech. So you would not directly write your speech in a linear way. You would first have like a rough plan. you say okay I'm going to talk about this in the first place second third you have some kind of draft and then you try to refine what is in each of these sections so you can think of diffusion as kind of working like this so it tries to have a course to fine refinement of the output so it can predict things that are you know after a certain token that has not been predicted But you can think of this as being something that goes from a very drafty version to a very refined version. So that's what I think about this process. Hopefully that's helpful. And the key advantage here is that the decoding is now done in much fewer forward passes because previously you had to do as many forward passes as there were tokens to predict. But here for diffusion you only need to do as many passes as there are steps in your diffusion process. And the number of steps is something you can fix. So the higher the step, the more high quality your output is, but it's typically much lower than the length of your output. So that is the core reason why this model is so much faster than the auto reggressive one. And um of course you know uh we don't have uh that much time but in case you're curious in case you're interested after the final once you're completely freed in terms of uh things to think of uh just put some references that could be help helpful. There's a paper that came out earlier this year called LADA large language uh diffusion model with masking. Actually, I don't remember the full acronym, but it is actually going through the math and why the thing that I just mentioned works. Uh, and then there's like a bunch of other papers that would also be helpful. So, the links are in the at the bottom of the slide in case you're interested. And I just want to go through two last things before giving it to Shervin. So first on the advantages of this new paradigm. So the first one is the speed. So as we mentioned it's going to be much faster than traditional auto reggressive models especially for outputs that are longer. And so some benchmarks they even say that it's something along the lines of 10x faster. So for cases like coding it can be very powerful because you may have to do several model calls and uh you know you as a user you're just waiting for that code to happen and you know just having a lower latency makes a lot of difference. The other thing is that the nature of this approach is actually considering the text as a whole in order to make the predictions. And so there's a category of coding tasks that are called fill in the middle which is about trying to figure out you know you have a bunch of code and you want to know what's missing. in the middle and so fill in the middle and diffusion models are typically better formulated for the kind these kinds of tasks because they can consider I guess input from multiple directions and um you know that's why this approach can be probably something that can be useful for some applications. So in terms of the current work, so these models they look great you know what I mentioned to you looks great but the performance was not on par with the current frontier models at least for some time but it's something that may change. So the papers that I mentioned they are actually posting performance that is kind of catching up with the models that are auto reggressive. So there is some promise in there. And then uh the other line of work is just to adapt all the techniques that people have come up with uh like for instance you know reasoning chains. How do you adapt that for diffusion? Um like you know and so on. You know there are so many techniques that are intrinsically more better suited for auto reggressive kinds of models that can be adapted for that and that's what people are working on. So long story short, what we saw was that things we saw in this class could be used in other domains. Like for instance, we saw the vision transformer uh that was borrowing the transformer for vision related tasks. But we also saw that things from other domains could also be used in the text world. And that's what we saw with diffusion LMS. Um, and so this is probably, you know, of course a subset of everything that's happening. And so with that, I think we're concluding our second item of our menu. And um, I'm going to just give it to Shervin. Thank you, Ashin. And with that, welcome to the last part of the season finale of CM295. And as Ein mentioned, now is the time for some closing thoughts and see um what we can get away from this class and uh concepts that are u neighboring to it. Uh so first Afin went through the concept of diffusion and images and we saw some similarities. we could draw with text. And now we're going to see what kinds of inspirations have both modalities taken from each other. And we're going to see um that actually like a lot of things can be um reused. So the first thing that I want to mention in terms of what has been reused is the architecture part. So Afinen uh mentioned this uh like diffusion concept that was born in the field of images but that was taken for text and was able to yield uh lower latency like a higher speedups which is great when you're a user. Uh so this was one example of a win. Uh and then on the other direction um traditionally images have been dealing with um convolutions mostly as as uh model architecture type but uh these papers saw that replacing convolutions with transformers uh was very good even um yielding better results. So all these latest diffusionbased papers in the field of images typically use transformers and then here I'm linking one of the papers that Afin already uh briefly went through. But not only uh is it the architecture sides that is uh that that is the subject of pollination between these modalities. You could even think of other kinds of components like the input. And for this one I want to mention the example of deepsek OCR. So I don't know if you've heard of this paper. It just came out very recently and contrary to what the names the name suggests. So, OCR stands for optical rec uh like recognition, character recognition and it's usually a field that tries to convert some scanned image into text but actually that paper doesn't boast some improvement on the OCR task itself rather it showed that you could learn some function that reconstructs text tokens based on vision tokens and not only on vision tokens on very few vision tokens. So it showed that the representation power of patches of images as tokens was very strong. And you have some researchers that bring some rationale to it like um you know hey tokenizers are not the best tool anyway. and then things in patches convey the meaning of text already with the example of emojis and so on that you would otherwise need to represent with way more tokens in text. Um and then another example I want to mention is even when you look inside the architectures some of the tricks uh can be reused and adapted in each field. So here I'm mentioning the example of rope which fin mentioned in the recap that was used in text to represent uh the relative position of tokens and in the case of images or even multimodel setting where you have the presence of both text and image within the architecture. you're able to adapt that trick uh by reformulating it in 2D. So here uh the figure shows how you can attribute rope positions in the 2D grids and how you could place text tokens such that the relative computation of position still makes sense. And you know even beyond that I would say that the ongoing research for transformers is very much alive and people are still figuring out all the details that we're working with today and you see refinements all the time coming uh in terms of new papers. So it's um you know it's something that is still developing and you can look at it from multiple angles. One is each of these design decisions that we've had they are still being iterated on. So like I'm listing a few items here as an example. So one is the optimizer side. You might be familiar with the atom optimizer and its update role which has been popular for quite some time and it seems that uh state is being challenged with a newer paper. So I referenced here the Kim K2 paper that came out a few months ago that uh introduces a new kind of optimizer called muon and the latest version of that muon clip seems to be a potential candidate for this optimizer to to become like the new standard. So this field even like as basic as it can be is still developing but it's not only the optimizer side you also have the topic of normalization where Afin mentioned that the difference between the original transformer paper and what you see today in LLM papers um you don't have the same kind of normalization anymore in the past you had postnorm but Now you have pre-norm which brings the normalization earlier on in the layer. Uh but beyond that design choice of the loca location of normalization you even have the type of loca uh of normalization that changes. So the transformer paper used layer norm but these days you might see other kinds of uh normalization techniques like RMS norm which uses less parameters and others. So the theory behind it is not set just yet. Uh so you have other kinds of parameters. Um Ashin mentioned the grouped query attention paper and you see these days in LLM papers not a fixed design rather every paper adopts their uh their own technique. Sometimes you see one kind of u attention used at a given layer but then it switches and different papers take different design decisions so it's not set in stone. Um then you also have activation functions. So traditionally in deep learning a lot of emphasis was put on ReLU which is uh very simple and used worked very well. But in the world of LLM the shift was towards uh ReLU like um activation functions but not exactly relu. So you had gausian error linear uh units you you had like other kinds and the the research there is still ongoing. So you you still see um you still see new activation functions coming in uh now and then and then you have also whether to take the design option of uh considering the LLM as ane or not and uh even the number of layers of your LLM and other hyperparameters like number of heads um size of the number of units in the FFN all of that is still up for debates uh in terms of like design decisions. So it's not fixed. Uh and then another area of research I want to mention is the data part which is crucial. So the first LLMs they enjoyed a relatively clean state of things because you could scrape the internet and hope for a lot of data that was for sure human generated. So you could learn these patterns from quote unquote a high quality source even though it's like not in high quality format when you look at typical internet data but it was still uh generated by human. So these days the state has changed. You type anything you want in your favorite search browser. Chances are the first results are 80% LLM generated. So are we doomed? Maybe not uh because actually you see the development of more and more work in data curation. So in the past you would just scrape the whole internet and train next token prediction on it. But now you have more and more this work of curating data sets of interest and you have companies that work on it and you have the emergence of newer fine-tuning modes. So in the past you had pre-training and then fine-tuning. Now you have pre-training, mid training and fine-tuning. And the mid-training part trains still on a large corpus of data but higher quality. So people are finding ways around it. Um and I would say the picture is not all grim but it's just that we need to do more work in order to be um to have meaningful data at hand. And the paper that is linked and at the bottom of the of the slide is dealing with the phenomenon of what if you were training on LLM generated data and it's talking about a concept called model collapse and it says that LLM generated text is typically less diverse. So the data distribution that you would see at training time changes and it leads to less meaningful learning at training time which is why it's typically bad and it motivates the need for more work on the data part. Okay. Nice. Um and then you know even taking a step back on the very architecture we've been um using all along is it the best one? it's not it's not clear. So that itself is an area of research and um future breakthroughs might come from redesigning this uh this architecture. Okay. So in the past few years a lot of the research that we have seen has been on improving benchmarks even more each time. So you have a set of benchmarks. Everyone tries to get the best results. So it's a natural trend because you want to have more and more powerful models that fulfill all your use cases. But let's say we reach a point where all the use cases we care about are solved. Then what? So I think we're going to see the emergence of this second border of the Parto Frontier where we care most about making predictions from LLM cost effective um and still very high quality. So uh we see this emergence of uh smaller and smaller LLMs like I think it has been dubbed small language models SLM uh like in the literature and um yeah typically you hear sometimes LLM providers say that they lose money even on the highest tier plans. So I think it reflects the fact that you need to be smarter in the compute that you spend for serving LLM queries at test time and uh yeah I think this this will motivate more and more uh this line of research in the coming years and then there is another area that we've not touched on at all in this class which is the hardware part. So typically the kind of device that you use to train these LLMs are GPUs which are great at one thing matrix multiply. Uh but the thing is uh we've kept these kinds of architectures to train our models even though the architecture doesn't only need matrix multiplies as a foundational um like atomic unit of compute. the uh self attention world and the transformer world has all these special needs. Um you know the Q K transpose part we saw was actually very expensive which has motivated papers such as flash attention to as Afin mentioned actually forgo of some of the data for the sake of not doing too much movement on the memory side even if it meant recomputing the same things afterwards. And then a lot of work has been on optimizing where the flow of memory within the GPU resided. And this shows that maybe you need a more um optimized uh hardware architecture in order to uh to to um to solve these use cases. So there is a recent paper that came out um that actually encodes all of these operations as part of the hardware. So in the past the core um the core operation that the GPU was great at is matrix multiply and based on it you try to build all of the input output that you want. But here this paper that came out I think in September shows a proof of concept where you can all do all of these computations as a side effect of implementing input and outputs with analog signals. So you have all of these computations that are embedded as part of the hardware and based on pulses as input that simulates your array values. These uh hardware architectures have some physical properties like you could think of kirhoff uh law in the like field of um I think intensity um you can add them up and it uses properties like this to have um what you need as input and just read out the result uh as output. So uh when uh the paper simulated this kind of architecture uh they observed without uh too much surprise quite a bit of improvement both on the latency and energy saving parts. Uh both explained because you don't need to do the computations yourself. Uh you just get them as a side effect of uh of your hardware. Now I want to take a step back and look at our users at our use cases of LLMs today and what could lie ahead. Uh what could be the most exciting for you. So today we've seen that in just a few years I think it has become quite important to know how to use them if you want to speed up everything you you do in your daily life. So a few lectures ago we talked about the coding case where um do you have all these AI assistant coding tools that um enable enable you to turn into code some natural language prompts. So you just you know ask for something and it will uh help you do that task with a so-called agent mode. And um this is just something that you would do as an engineer. But even beyond that uh other use cases are deeply impacted by it because you have um a lot of problems that today can be turned into a text to query or text to code problem. Uh so you could think of even the visualization world. you could um so for example there was a launch from Google uh recently that showed that you could uh generate visualizations on the fly based on some principles and this is already changing um quite a bit the picture of what you can do today. Uh something else that I think is used by most people actually today when using these chat bots is general uh like being a general assistant. So you ask about common facts and all the facts that it has learned at training time becomes useful. It browses the web um more efficiently than you and converts into natural language the things that you care about. Um but then there are also other domains that were impacted by it. So you could think creativity where a lot of jobs such as marketing uh or others rely on uh getting something out of a blank page and usually if you start from a draft it's much easier to get something done rather than just thinking of it from from scratch. So it's used as an eight here. And also one use case that I've seen in class that I think is is great that some of you do you know sometimes I talk about something or Afin talks about something and I see people typing typing on JGPT related concepts and I think it's very smart to do that because brainstorming the concepts that you learn is great for actually grasping the concepts of interest and getting that early feedback loop is uh very useful for learning. So I have a lot of hopes regarding uh how like how great of a time it is for you to learn as opposed to maybe uh you know a nice time maybe 10 years ago. So yeah keep doing that and I think it will be a growing use case. So looking forward um so I said tomorrow on the slide but actually two days ago there was a launch uh that went in the direction of what I was thinking about which is uh like all the agentic things that we talked about they are still very much confined into people that know about the field like everyday people they wouldn't typically use quote unquote agentic workflows. So I think one field of development that we will see more and more is all these use cases being democratized. So people can now create things that can be useful to them with easier um you know mediums just natural language no need to code. uh moving forward uh to later um so all this AI assistant coding that I was mentioning you could think of it as helping you browse the internet in a very natural fashion so it seems right now when you just execute tasks you're way too microscopic in what you do and this is typically what uh AI assistant could help you do so there are like recent product launches that reflect these growing interest such as chat GPT's atlas. So I think it launched in October. I don't know if they released some public number uh on usage. I suspect it's still timid because you still have challenges when it comes to security. Uh anyone could inject some uh bad prompt in there and maybe exfiltrate things from you, but I'm sure the community will come up with uh more ways to get around it. So in the past you had https for example to say that the connection was secure. Maybe tomorrow you'll have some certificate that will guarantee that a site website is safe for AI assistant browsing. um and looking even at a higher level, maybe just browsing on your uh desktop or your mobile phone at the LLM level. Uh at the OS level might be um something that the LLM can u can help. So when we talked about agents, we mentioned how um nonreliable it could be because as you have more and more steps, the probability for a failure increases and stabilizing predictions is something of interest. And um even in the longer run, I think one test that we can have in mind as to how far we've come is whether the common use case of having a customer service that is served by AI is truly useful. So I don't know about you, but every time I have a problem and I'm on the phone and I hear some AI assistant maybe LLM powered robot and like you know quick quick I want a human. I don't want that. And uh and I think it shows how hard this space is, the space of problems is because human has way more dimensions of of value that an LLM could bring. So empathy, um like groundedness, there are some things that you and I we perceive as you know things that make sense even though they're not in our system prompts. So I think there there are hard problems to to solve there. And even moving forward um there are some key challenges that we have with the current architecture. So um we saw during the class that you had to go through a training process that u went to like fix some weights but these weights are not changing afterwards. And we use tricks such as rags a rag or tools to get around this issue. But could we think of a system that learns continuously? I think that is an open question. Then there is a topic of hallucinations which I put into quotation marks because I'm not sure if it's fair to say that the LLM hallucinates just because we've trained the LLM to predict the next token by nature, not map statements to facts. So hallucinating is in some sense a core design uh choice of the these LLMs. Uh personalization, interpretability, safety, the the list goes on. Um now I want to briefly cover what you can um like how you can exercise this muscle of staying up to date from now. So you have archive that uh usually contains all these great greatest and latest papers that you can take a look at. Of course the venues like new rips right now are great to highlight papers um like some papers uh and then uh I highly encourage you be besides the papers uh looking at the associated code bases that the authors provide. So right now it's a common place to just provide the implementation of what you are proposing and I think it's very insightful to learn the concepts and uh there is a paper with code that existed in the past and that has been replaced by hugging facees uh trending papers which I think is a good place to to take a look at the latest uh methods and then um on the uh social network side uh Twitter or X uh has a lot of u a lot of the latest that is often discussed. So you have a strong community there and if you have an account on that social media you have a lot of great people to follow um to like stay updated but also you have resources on YouTube uh with a highlight on Yanik Kilchshire which I think was the first uh YouTuber to cover the transformer paper back in 2017 in great detail and I think you know some of these YouTubers they're very good at um talking through um like papers in great detail. And another highlight is Andrish Karpath uh who was at Stanford about 10 years ago and he's I think one of the best educators out there. So I highly recommend his videos and you have a company blogs that are also great and uh like this study guide that we associated with the class. Um, so we've had it for this year and what we'll try to do uh in the coming years is try to keep it updated at least on a yearly basis. So you can consider this resource as maybe some companion and we've got the chance to collaborate with uh experts around the world to make it available in other languages in case you're interested. And taking a step back, just want to say that Afin and I were very grateful to teach this class this quarter. Um, thank you so much for coming here, you know, on Friday evening, which is quite telling cuz, uh, you know, Friday evening is usually time for fun, not for lectures. And also now I think it's probably your last lecture of the whole quarter because uh, yeah, next week is finals. So yeah, thank you for coming and for asking all these great questions. You were one of the reasons why this class was so great and interactive. Also, thank you to the folks who are watching online from home. I was one of you uh eight years ago. I would uh almost never go to class, always watching lectures from home from a cozy place. I hope the lectures were entertaining and that you got something from it. Um, and I couldn't conclude uh without bringing our favorite teddy bear one last time. Thanking you uh all for your attention and wishing you all the best. Thank you.\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import (\n",
    "    YouTubeTranscriptApi,\n",
    "    TranscriptsDisabled,\n",
    "    NoTranscriptFound,\n",
    "    VideoUnavailable\n",
    ")\n",
    "\n",
    "video_id = \"Q86qzJ1K1Ss\"\n",
    "\n",
    "try:\n",
    "    api = YouTubeTranscriptApi()\n",
    "\n",
    "    transcript_list = api.fetch(video_id, languages=[\"en\"])\n",
    "\n",
    "    transcript = \" \".join(chunk.text for chunk in transcript_list)\n",
    "\n",
    "    print(transcript)\n",
    "\n",
    "except TranscriptsDisabled:\n",
    "    print(\"No captions available for this video.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "99dbd52a-cfef-4d80-8b2f-1e7843137929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchedTranscript(snippets=[FetchedTranscriptSnippet(text='Hello everyone and uh welcome to lecture', start=5.759, duration=6.241), FetchedTranscriptSnippet(text='9 of CM295.', start=8.8, duration=6.48), FetchedTranscriptSnippet(text='So as you know uh today is a kind of a', start=12.0, duration=5.6), FetchedTranscriptSnippet(text=\"special day because uh we're having the\", start=15.28, duration=6.32), FetchedTranscriptSnippet(text='last lecture of the entire course. Um so', start=17.6, duration=6.24), FetchedTranscriptSnippet(text='the menu for today will be a little', start=21.6, duration=4.96), FetchedTranscriptSnippet(text='different compared to usual.', start=23.84, duration=5.04), FetchedTranscriptSnippet(text=\"uh we're going to try to divide the\", start=26.56, duration=5.519), FetchedTranscriptSnippet(text='lecture in three parts. So in the first', start=28.88, duration=6.0), FetchedTranscriptSnippet(text=\"part we're going to recap actually what\", start=32.079, duration=6.8), FetchedTranscriptSnippet(text='we did in the entire class', start=34.88, duration=7.199), FetchedTranscriptSnippet(text='just to see how different pieces kind of', start=38.879, duration=6.561), FetchedTranscriptSnippet(text='fit together. Uh in the second part we', start=42.079, duration=5.521), FetchedTranscriptSnippet(text='will look at some topics that are', start=45.44, duration=5.439), FetchedTranscriptSnippet(text='particularly trending uh in 2025 and', start=47.6, duration=5.2), FetchedTranscriptSnippet(text='what we think are going to be trending', start=50.879, duration=5.121), FetchedTranscriptSnippet(text='in the near future. And then uh the', start=52.8, duration=6.88), FetchedTranscriptSnippet(text='third part will be more uh way for us to', start=56.0, duration=7.039), FetchedTranscriptSnippet(text='just conclude and uh next steps uh for', start=59.68, duration=5.6), FetchedTranscriptSnippet(text='all of you.', start=63.039, duration=4.641), FetchedTranscriptSnippet(text='Does that sound good?', start=65.28, duration=6.159), FetchedTranscriptSnippet(text=\"Cool. So with that uh we're going to\", start=67.68, duration=6.0), FetchedTranscriptSnippet(text='start with the first part which uh what', start=71.439, duration=4.881), FetchedTranscriptSnippet(text='I mentioned is about recapping what we', start=73.68, duration=6.0), FetchedTranscriptSnippet(text='did this entire quarter.', start=76.32, duration=5.6), FetchedTranscriptSnippet(text=\"So nothing new here. It's just a way for\", start=79.68, duration=5.04), FetchedTranscriptSnippet(text='us to piece everything together.', start=81.92, duration=6.239), FetchedTranscriptSnippet(text='So if you remember u lot of weeks ago I', start=84.72, duration=6.16), FetchedTranscriptSnippet(text=\"believe it's like maybe 10 weeks ago we\", start=88.159, duration=6.881), FetchedTranscriptSnippet(text='had lecture one which was focused on', start=90.88, duration=7.279), FetchedTranscriptSnippet(text='understanding what transformers were. So', start=95.04, duration=6.079), FetchedTranscriptSnippet(text='at the very beginning of the class we', start=98.159, duration=5.521), FetchedTranscriptSnippet(text=\"didn't even know how we could process\", start=101.119, duration=5.121), FetchedTranscriptSnippet(text='text. So I guess the first step that we', start=103.68, duration=6.64), FetchedTranscriptSnippet(text='saw was this tokenization step which', start=106.24, duration=7.519), FetchedTranscriptSnippet(text='consists of dividing the input into', start=110.32, duration=7.68), FetchedTranscriptSnippet(text='atomic units. And so here the way you we', start=113.759, duration=7.601), FetchedTranscriptSnippet(text='divide the text is something that is', start=118.0, duration=6.399), FetchedTranscriptSnippet(text='arbitrary in some sense. So we have', start=121.36, duration=5.28), FetchedTranscriptSnippet(text='different algorithms that allow us to do', start=124.399, duration=5.92), FetchedTranscriptSnippet(text='that. Uh and we saw that the most common', start=126.64, duration=7.04), FetchedTranscriptSnippet(text='tokenization algorithm is the subword', start=130.319, duration=5.681), FetchedTranscriptSnippet(text='level tokenizer.', start=133.68, duration=4.72), FetchedTranscriptSnippet(text='And we saw that some of the advantages', start=136.0, duration=7.68), FetchedTranscriptSnippet(text='were that um roots of words could be', start=138.4, duration=8.64), FetchedTranscriptSnippet(text='reused um and leveraged especially when', start=143.68, duration=6.96), FetchedTranscriptSnippet(text='it came to representing those tokens.', start=147.04, duration=5.279), FetchedTranscriptSnippet(text='And', start=150.64, duration=4.08), FetchedTranscriptSnippet(text='speaking of representation,', start=152.319, duration=5.441), FetchedTranscriptSnippet(text='once we were able to divide the input', start=154.72, duration=7.84), FetchedTranscriptSnippet(text='text into atomic units, aka tokens, the', start=157.76, duration=8.479), FetchedTranscriptSnippet(text='next step for us was to learn how to', start=162.56, duration=6.8), FetchedTranscriptSnippet(text='represent these embeddings. So if you', start=166.239, duration=5.521), FetchedTranscriptSnippet(text='remember, we saw some methods that were', start=169.36, duration=4.879), FetchedTranscriptSnippet(text='very popular back then. So one of them', start=171.76, duration=4.96), FetchedTranscriptSnippet(text='was called wordtovec', start=174.239, duration=5.121), FetchedTranscriptSnippet(text='and the representation was learned from', start=176.72, duration=6.48), FetchedTranscriptSnippet(text='a proxy task which was something like', start=179.36, duration=6.959), FetchedTranscriptSnippet(text='predicting the center word or predicting', start=183.2, duration=5.84), FetchedTranscriptSnippet(text='the context words.', start=186.319, duration=5.041), FetchedTranscriptSnippet(text='But then we saw that this way of', start=189.04, duration=4.72), FetchedTranscriptSnippet(text='learning representations had some', start=191.36, duration=4.0), FetchedTranscriptSnippet(text='limitations.', start=193.76, duration=3.44), FetchedTranscriptSnippet(text='One of which was that these', start=195.36, duration=5.84), FetchedTranscriptSnippet(text='representations were not contextaware.', start=197.2, duration=7.6), FetchedTranscriptSnippet(text='Meaning that uh if a word is in a given', start=201.2, duration=6.399), FetchedTranscriptSnippet(text='sentence or in another sentence they', start=204.8, duration=5.68), FetchedTranscriptSnippet(text='will both have the same like that word', start=207.599, duration=4.56), FetchedTranscriptSnippet(text='will have the same representation in', start=210.48, duration=4.0), FetchedTranscriptSnippet(text='both sentences.', start=212.159, duration=5.44), FetchedTranscriptSnippet(text='And so for that reason we saw some uh', start=214.48, duration=5.36), FetchedTranscriptSnippet(text='other methods that were popular in the', start=217.599, duration=6.0), FetchedTranscriptSnippet(text='2010s. one of which was', start=219.84, duration=7.84), FetchedTranscriptSnippet(text=\"RNN's if you remember. So RNN's um had\", start=223.599, duration=7.36), FetchedTranscriptSnippet(text='this recurrent structure which process', start=227.68, duration=6.08), FetchedTranscriptSnippet(text='tokens one at a time and kept an', start=230.959, duration=5.28), FetchedTranscriptSnippet(text='internal representation of the sequence', start=233.76, duration=4.32), FetchedTranscriptSnippet(text='so far.', start=236.239, duration=4.241), FetchedTranscriptSnippet(text='But then we saw that a big limitation of', start=238.08, duration=4.96), FetchedTranscriptSnippet(text='this was this problem of long range', start=240.48, duration=5.119), FetchedTranscriptSnippet(text='dependency and in particular the fact', start=243.04, duration=6.16), FetchedTranscriptSnippet(text='that uh tokens that were encoded far in', start=245.599, duration=7.601), FetchedTranscriptSnippet(text='the past were not um quantities that', start=249.2, duration=6.48), FetchedTranscriptSnippet(text='were able to be kept I guess as the', start=253.2, duration=5.039), FetchedTranscriptSnippet(text='sequence got longer', start=255.68, duration=5.519), FetchedTranscriptSnippet(text='and this is the reason why we saw the', start=258.239, duration=4.96), FetchedTranscriptSnippet(text='central idea of this whole class which', start=261.199, duration=5.921), FetchedTranscriptSnippet(text='is the idea of self attention where', start=263.199, duration=6.72), FetchedTranscriptSnippet(text='tokens s can actually', start=267.12, duration=5.76), FetchedTranscriptSnippet(text='attend to one another regardless of', start=269.919, duration=5.361), FetchedTranscriptSnippet(text='where they are placed in the sequence.', start=272.88, duration=4.48), FetchedTranscriptSnippet(text='So you can think of this as a direct', start=275.28, duration=4.4), FetchedTranscriptSnippet(text='link.', start=277.36, duration=5.6), FetchedTranscriptSnippet(text='And so uh this for instance is what we', start=279.68, duration=5.76), FetchedTranscriptSnippet(text='saw. We we saw that there are like three', start=282.96, duration=5.6), FetchedTranscriptSnippet(text='main uh terminologies that people use.', start=285.44, duration=7.039), FetchedTranscriptSnippet(text='So query, key and value. So typically', start=288.56, duration=7.84), FetchedTranscriptSnippet(text='you want to know how similar a query is', start=292.479, duration=6.561), FetchedTranscriptSnippet(text='compared to the keys in the in the', start=296.4, duration=7.2), FetchedTranscriptSnippet(text='sequence and you quantify that by um', start=299.04, duration=6.8), FetchedTranscriptSnippet(text=\"taking some dot products that's kind of\", start=303.6, duration=4.72), FetchedTranscriptSnippet(text='scaled and softmaxed', start=305.84, duration=4.4), FetchedTranscriptSnippet(text='and then you have the corresponding', start=308.32, duration=5.04), FetchedTranscriptSnippet(text='value that is taken. So at the end of', start=310.24, duration=6.48), FetchedTranscriptSnippet(text='the day we obtain some kind of weighted', start=313.36, duration=6.399), FetchedTranscriptSnippet(text='average of all the tokens that are in', start=316.72, duration=6.08), FetchedTranscriptSnippet(text='the sequence.', start=319.759, duration=5.921), FetchedTranscriptSnippet(text='And then uh you may also be familiar now', start=322.8, duration=5.44), FetchedTranscriptSnippet(text='with this formula. So soft max of q', start=325.68, duration=7.6), FetchedTranscriptSnippet(text='krpose over square root of dk um time v.', start=328.24, duration=9.04), FetchedTranscriptSnippet(text='So this is the matrix formulation of', start=333.28, duration=7.6), FetchedTranscriptSnippet(text='what I mentioned here which uh is able', start=337.28, duration=5.84), FetchedTranscriptSnippet(text='to process these computations in a very', start=340.88, duration=5.36), FetchedTranscriptSnippet(text=\"efficient way and it's something that uh\", start=343.12, duration=7.28), FetchedTranscriptSnippet(text=\"today's hardware is well equipped to do\", start=346.24, duration=7.44), FetchedTranscriptSnippet(text='and then we finish the first lecture by', start=350.4, duration=5.84), FetchedTranscriptSnippet(text='going through the architecture that is', start=353.68, duration=6.0), FetchedTranscriptSnippet(text='the foundation of modern day LLMs which', start=356.24, duration=6.08), FetchedTranscriptSnippet(text='is the transformer and we saw that there', start=359.68, duration=6.72), FetchedTranscriptSnippet(text='are two u not notable parts in the', start=362.32, duration=6.96), FetchedTranscriptSnippet(text='transformer. So one was the encoder in', start=366.4, duration=6.16), FetchedTranscriptSnippet(text='the left part of the uh um the figure', start=369.28, duration=5.84), FetchedTranscriptSnippet(text='and then the right part is the decoder', start=372.56, duration=4.72), FetchedTranscriptSnippet(text='and we saw how this was applied in the', start=375.12, duration=5.6), FetchedTranscriptSnippet(text='case of translation.', start=377.28, duration=6.32), FetchedTranscriptSnippet(text='So at the end of the first lecture we', start=380.72, duration=8.24), FetchedTranscriptSnippet(text='saw what motivated us to end up with the', start=383.6, duration=7.439), FetchedTranscriptSnippet(text='transformer', start=388.96, duration=4.32), FetchedTranscriptSnippet(text='and we saw that transformer was working', start=391.039, duration=5.121), FetchedTranscriptSnippet(text='quite well in the case of uh translation', start=393.28, duration=5.12), FetchedTranscriptSnippet(text='and so in the next lecture what we saw', start=396.16, duration=6.879), FetchedTranscriptSnippet(text='was what were the little improvements', start=398.4, duration=6.239), FetchedTranscriptSnippet(text='that people have made to this', start=403.039, duration=4.481), FetchedTranscriptSnippet(text='architecture since it was released and', start=404.639, duration=5.28), FetchedTranscriptSnippet(text='if you remember it was in 2017 that it', start=407.52, duration=4.88), FetchedTranscriptSnippet(text='was publicublished.', start=409.919, duration=2.481), FetchedTranscriptSnippet(text='So one particular improvement that', start=413.28, duration=7.199), FetchedTranscriptSnippet(text='people have made is in the way we', start=416.08, duration=7.519), FetchedTranscriptSnippet(text='consider positions', start=420.479, duration=5.28), FetchedTranscriptSnippet(text='because in the original transformer', start=423.599, duration=6.081), FetchedTranscriptSnippet(text='paper positions were encoded', start=425.759, duration=7.761), FetchedTranscriptSnippet(text='in an absolute way as in each position', start=429.68, duration=6.88), FetchedTranscriptSnippet(text='had its own embedding', start=433.52, duration=5.28), FetchedTranscriptSnippet(text='and this embedding was added to the', start=436.56, duration=5.28), FetchedTranscriptSnippet(text='token embedding.', start=438.8, duration=3.04), FetchedTranscriptSnippet(text='But then if we think about it', start=442.0, duration=5.84), FetchedTranscriptSnippet(text=\"positions actually we don't really care\", start=445.599, duration=4.801), FetchedTranscriptSnippet(text='about the absolute position. We care', start=447.84, duration=5.359), FetchedTranscriptSnippet(text='about the relative position between', start=450.4, duration=4.48), FetchedTranscriptSnippet(text='tokens', start=453.199, duration=4.4), FetchedTranscriptSnippet(text='and in particular we care about how far', start=454.88, duration=5.28), FetchedTranscriptSnippet(text='tokens are in the self attention', start=457.599, duration=4.241), FetchedTranscriptSnippet(text='computation.', start=460.16, duration=4.24), FetchedTranscriptSnippet(text='Which is why we saw this methods that is', start=461.84, duration=5.199), FetchedTranscriptSnippet(text='now quite popular called rotary position', start=464.4, duration=5.84), FetchedTranscriptSnippet(text='embeddings aka rope', start=467.039, duration=5.841), FetchedTranscriptSnippet(text='that is now quite used. And it is a', start=470.24, duration=5.92), FetchedTranscriptSnippet(text='method that rotates', start=472.88, duration=5.68), FetchedTranscriptSnippet(text='query and keys', start=476.16, duration=5.039), FetchedTranscriptSnippet(text='both of which happen in the self', start=478.56, duration=4.8), FetchedTranscriptSnippet(text='attention computation.', start=481.199, duration=7.041), FetchedTranscriptSnippet(text='And so here um what is uh quantified', start=483.36, duration=7.2), FetchedTranscriptSnippet(text='here is purely a function of the', start=488.24, duration=6.959), FetchedTranscriptSnippet(text='relative distance between um two tokens', start=490.56, duration=7.039), FetchedTranscriptSnippet(text='and not only that it is something that', start=495.199, duration=5.201), FetchedTranscriptSnippet(text='is uh taken care of in the self', start=497.599, duration=5.04), FetchedTranscriptSnippet(text='attention layer which is what we care', start=500.4, duration=4.239), FetchedTranscriptSnippet(text='about.', start=502.639, duration=4.321), FetchedTranscriptSnippet(text='So this was one big improvement and then', start=504.639, duration=4.481), FetchedTranscriptSnippet(text='we saw some other improvements', start=506.96, duration=5.28), FetchedTranscriptSnippet(text='especially when it came to how the multi', start=509.12, duration=6.08), FetchedTranscriptSnippet(text='head attention um layer multi head', start=512.24, duration=6.4), FetchedTranscriptSnippet(text='attention layer was composed of and in', start=515.2, duration=5.6), FetchedTranscriptSnippet(text='particular we saw that it was possible', start=518.64, duration=6.0), FetchedTranscriptSnippet(text='for us to have some groupings', start=520.8, duration=7.28), FetchedTranscriptSnippet(text='of the matrices that we learn. So we', start=524.64, duration=6.0), FetchedTranscriptSnippet(text=\"don't need to have one matrix one\", start=528.08, duration=6.72), FetchedTranscriptSnippet(text=\"projection matrix per head for let's say\", start=530.64, duration=7.84), FetchedTranscriptSnippet(text='keys and values. We can actually uh', start=534.8, duration=6.24), FetchedTranscriptSnippet(text='group them. So this is uh for instance', start=538.48, duration=4.64), FetchedTranscriptSnippet(text='what is mentioned here. So group query', start=541.04, duration=6.16), FetchedTranscriptSnippet(text='attention. Um and then we also saw some', start=543.12, duration=5.839), FetchedTranscriptSnippet(text='other techniques that I have not', start=547.2, duration=3.92), FetchedTranscriptSnippet(text='represented here like for instance the', start=548.959, duration=5.121), FetchedTranscriptSnippet(text='normalization layer in the transformer', start=551.12, duration=7.12), FetchedTranscriptSnippet(text='which here happens after each', start=554.08, duration=6.72), FetchedTranscriptSnippet(text='sub layer but I guess nowadays people', start=558.24, duration=5.52), FetchedTranscriptSnippet(text='have tried moving the normalization', start=560.8, duration=6.159), FetchedTranscriptSnippet(text=\"piece before the sub layer. So here it's\", start=563.76, duration=5.6), FetchedTranscriptSnippet(text='the postnorm', start=566.959, duration=4.88), FetchedTranscriptSnippet(text='version and then the before the sub', start=569.36, duration=6.24), FetchedTranscriptSnippet(text='layer part is called the prenorm', start=571.839, duration=5.44), FetchedTranscriptSnippet(text='version.', start=575.6, duration=4.16), FetchedTranscriptSnippet(text='And then the last thing that we saw was', start=577.279, duration=6.24), FetchedTranscriptSnippet(text='that from this transformer architecture', start=579.76, duration=6.32), FetchedTranscriptSnippet(text='there were a lot of derived models that', start=583.519, duration=6.161), FetchedTranscriptSnippet(text='were based from that. So we saw that if', start=586.08, duration=8.0), FetchedTranscriptSnippet(text='we only keep the encoder part we could', start=589.68, duration=7.599), FetchedTranscriptSnippet(text='compute very meaningful embeddings.', start=594.08, duration=5.84), FetchedTranscriptSnippet(text='If you remember there was this um uh', start=597.279, duration=5.761), FetchedTranscriptSnippet(text='kind of landmark paper on encoder only', start=599.92, duration=6.4), FetchedTranscriptSnippet(text='model which is birds which was heavily', start=603.04, duration=6.08), FetchedTranscriptSnippet(text='used in the context of classification', start=606.32, duration=5.519), FetchedTranscriptSnippet(text='because it relied on the encoded', start=609.12, duration=5.52), FetchedTranscriptSnippet(text='embedding of the CLS token. And so that', start=611.839, duration=4.56), FetchedTranscriptSnippet(text='was one.', start=614.64, duration=3.759), FetchedTranscriptSnippet(text='But then we also saw that there was a', start=616.399, duration=5.361), FetchedTranscriptSnippet(text='number of other kinds of models all more', start=618.399, duration=5.921), FetchedTranscriptSnippet(text='or less derived from the transformer. So', start=621.76, duration=4.24), FetchedTranscriptSnippet(text='you could only keep the encoder which', start=624.32, duration=4.079), FetchedTranscriptSnippet(text='was for birds. You could only keep the', start=626.0, duration=6.0), FetchedTranscriptSnippet(text='decoder which is for instance for GPT', start=628.399, duration=7.201), FetchedTranscriptSnippet(text='and you could also have both', start=632.0, duration=7.519), FetchedTranscriptSnippet(text='which is for instance the case of T5.', start=635.6, duration=7.679), FetchedTranscriptSnippet(text='And one particular aspect of each of', start=639.519, duration=7.841), FetchedTranscriptSnippet(text='these models is that encoder only is not', start=643.279, duration=6.961), FetchedTranscriptSnippet(text='able in the way that we saw is not able', start=647.36, duration=5.28), FetchedTranscriptSnippet(text='to generate text', start=650.24, duration=4.719), FetchedTranscriptSnippet(text='but is able to generate embeddings which', start=652.64, duration=4.72), FetchedTranscriptSnippet(text='can be used for downstream tasks. But', start=654.959, duration=6.241), FetchedTranscriptSnippet(text='then encoder decoder models like T5 or', start=657.36, duration=7.76), FetchedTranscriptSnippet(text='decoder only models like GPT they can be', start=661.2, duration=7.28), FetchedTranscriptSnippet(text='auto reggressive and', start=665.12, duration=6.719), FetchedTranscriptSnippet(text='generate text. The paradigm can be text', start=668.48, duration=7.799), FetchedTranscriptSnippet(text='in text out.', start=671.839, duration=4.44), FetchedTranscriptSnippet(text='And with that we then focused on what', start=676.48, duration=7.68), FetchedTranscriptSnippet(text='now everyone calls large language models', start=680.64, duration=6.16), FetchedTranscriptSnippet(text='which are transformerbased models', start=684.16, duration=6.32), FetchedTranscriptSnippet(text='specifically texttoext models. So', start=686.8, duration=8.8), FetchedTranscriptSnippet(text='decoder only transformer-based models', start=690.48, duration=7.359), FetchedTranscriptSnippet(text='and we saw that people have come up with', start=695.6, duration=5.2), FetchedTranscriptSnippet(text='a lot of new tricks now because um you', start=697.839, duration=5.361), FetchedTranscriptSnippet(text='know these models as the name uh', start=700.8, duration=6.0), FetchedTranscriptSnippet(text='indicates um people have scaled them up.', start=703.2, duration=8.319), FetchedTranscriptSnippet(text='But then one question was uh kind of', start=706.8, duration=7.84), FetchedTranscriptSnippet(text='kind of thrown which is do you actually', start=711.519, duration=7.361), FetchedTranscriptSnippet(text='need all these parameters to just do a', start=714.64, duration=6.319), FetchedTranscriptSnippet(text='forward pass.', start=718.88, duration=5.92), FetchedTranscriptSnippet(text='So we saw uh one kind of uh variant', start=720.959, duration=8.641), FetchedTranscriptSnippet(text='which was based on mixture of experts.', start=724.8, duration=7.839), FetchedTranscriptSnippet(text='So what mixture of experts are is', start=729.6, duration=5.84), FetchedTranscriptSnippet(text='instead of running everything through', start=732.639, duration=5.921), FetchedTranscriptSnippet(text=\"the whole entire model, you're going to\", start=735.44, duration=6.88), FetchedTranscriptSnippet(text='instead have a number of experts', start=738.56, duration=6.399), FetchedTranscriptSnippet(text=\"that you're going to activate in a\", start=742.32, duration=4.8), FetchedTranscriptSnippet(text='sparse way.', start=744.959, duration=4.081), FetchedTranscriptSnippet(text=\"So for instance, for one input, you're\", start=747.12, duration=4.8), FetchedTranscriptSnippet(text='going to just activate just a subset and', start=749.04, duration=4.4), FetchedTranscriptSnippet(text=\"then for another input you're going to\", start=751.92, duration=4.24), FetchedTranscriptSnippet(text='activate another subset so that you', start=753.44, duration=5.04), FetchedTranscriptSnippet(text=\"don't need to do all the computations\", start=756.16, duration=4.88), FetchedTranscriptSnippet(text='all the time.', start=758.48, duration=6.08), FetchedTranscriptSnippet(text='And we saw that these mixture of experts', start=761.04, duration=7.28), FetchedTranscriptSnippet(text='they were used in LLMs in particular in', start=764.56, duration=7.04), FetchedTranscriptSnippet(text='the feed for neural network layer. So', start=768.32, duration=6.48), FetchedTranscriptSnippet(text='here you would have experts as being', start=771.6, duration=5.679), FetchedTranscriptSnippet(text='different feed for neural networks and', start=774.8, duration=5.76), FetchedTranscriptSnippet(text='you would have a gating mechanism that', start=777.279, duration=5.441), FetchedTranscriptSnippet(text='would reroute', start=780.56, duration=6.8), FetchedTranscriptSnippet(text='to the correct feed for neural network.', start=782.72, duration=7.359), FetchedTranscriptSnippet(text='And then we also saw that some papers', start=787.36, duration=5.76), FetchedTranscriptSnippet(text='were also able to kind of produce some', start=790.079, duration=5.76), FetchedTranscriptSnippet(text='nice visualization in terms of uh I', start=793.12, duration=4.56), FetchedTranscriptSnippet(text='guess which token gets routed to which', start=795.839, duration=4.961), FetchedTranscriptSnippet(text='experts because this rerouting we saw', start=797.68, duration=7.12), FetchedTranscriptSnippet(text='that it was done at the token level.', start=800.8, duration=5.68), FetchedTranscriptSnippet(text=\"And so one reason why it's done at the\", start=804.8, duration=4.8), FetchedTranscriptSnippet(text='token level is to be able to I guess', start=806.48, duration=5.919), FetchedTranscriptSnippet(text='smartly put the experts on different', start=809.6, duration=5.52), FetchedTranscriptSnippet(text='pieces of hardware, different GPUs and', start=812.399, duration=4.721), FetchedTranscriptSnippet(text='then kind of parallelize the computation', start=815.12, duration=5.56), FetchedTranscriptSnippet(text='a little bit more.', start=817.12, duration=3.56), FetchedTranscriptSnippet(text='And then we also saw that these LLMs', start=820.959, duration=7.361), FetchedTranscriptSnippet(text='they always are tasked with predicting', start=826.079, duration=5.2), FetchedTranscriptSnippet(text='the next token. And in order to predict', start=828.32, duration=6.639), FetchedTranscriptSnippet(text='the next token, we were interested in uh', start=831.279, duration=5.521), FetchedTranscriptSnippet(text='I guess how we were uh you know doing', start=834.959, duration=5.601), FetchedTranscriptSnippet(text='this. And so one particular uh method', start=836.8, duration=6.56), FetchedTranscriptSnippet(text='that people use is just sample', start=840.56, duration=4.719), FetchedTranscriptSnippet(text='sample from the output distribution. So', start=843.36, duration=4.24), FetchedTranscriptSnippet(text=\"you have let's say given an input you\", start=845.279, duration=5.761), FetchedTranscriptSnippet(text='have a distribution of probabilities of', start=847.6, duration=6.72), FetchedTranscriptSnippet(text='what the next token would be that is', start=851.04, duration=7.359), FetchedTranscriptSnippet(text='output by the model. And what you do is', start=854.32, duration=6.72), FetchedTranscriptSnippet(text=\"instead of let's say taking the highest\", start=858.399, duration=4.401), FetchedTranscriptSnippet(text='probability which is called the greedy', start=861.04, duration=3.44), FetchedTranscriptSnippet(text='decoding', start=862.8, duration=4.719), FetchedTranscriptSnippet(text='uh greedy kind of decoding you actually', start=864.48, duration=5.599), FetchedTranscriptSnippet(text='sample.', start=867.519, duration=5.68), FetchedTranscriptSnippet(text='So it introduces some randomness and', start=870.079, duration=6.56), FetchedTranscriptSnippet(text='allows the model to produce kind of a', start=873.199, duration=6.401), FetchedTranscriptSnippet(text='bigger variety of uh kinds of outputs.', start=876.639, duration=8.0), FetchedTranscriptSnippet(text='And we saw uh that you could adjust how', start=879.6, duration=7.84), FetchedTranscriptSnippet(text='how much I guess variety you want in', start=884.639, duration=5.601), FetchedTranscriptSnippet(text='your output by tweaking a hyperparameter', start=887.44, duration=5.36), FetchedTranscriptSnippet(text='called temperature.', start=890.24, duration=4.64), FetchedTranscriptSnippet(text='So very low temperature leads to very', start=892.8, duration=4.0), FetchedTranscriptSnippet(text='spiky distribution. So more', start=894.88, duration=4.399), FetchedTranscriptSnippet(text='deterministic outputs and higher', start=896.8, duration=5.92), FetchedTranscriptSnippet(text='temperatures are I guess a bit more uh', start=899.279, duration=7.401), FetchedTranscriptSnippet(text='random a bit more creative.', start=902.72, duration=3.96), FetchedTranscriptSnippet(text='Okay. So until then we saw what LLMs', start=907.12, duration=6.32), FetchedTranscriptSnippet(text='were, how they were based on the', start=911.199, duration=3.841), FetchedTranscriptSnippet(text='transformer, how they connected to the', start=913.44, duration=3.199), FetchedTranscriptSnippet(text='architecture that we saw in the first', start=915.04, duration=5.84), FetchedTranscriptSnippet(text='lecture and then in lecture lecture four', start=916.639, duration=7.841), FetchedTranscriptSnippet(text='we saw how people actually trained those', start=920.88, duration=5.36), FetchedTranscriptSnippet(text='LLMs', start=924.48, duration=4.479), FetchedTranscriptSnippet(text='because as I mentioned these LLMs are', start=926.24, duration=6.64), FetchedTranscriptSnippet(text='large and so you cannot kind of naively', start=928.959, duration=7.041), FetchedTranscriptSnippet(text='fit them in your hardware. you need to', start=932.88, duration=5.6), FetchedTranscriptSnippet(text='be a little bit smart about it.', start=936.0, duration=6.48), FetchedTranscriptSnippet(text='So in particular, what people have uh', start=938.48, duration=6.88), FetchedTranscriptSnippet(text='kind of noticed in the early 2020s is', start=942.48, duration=5.919), FetchedTranscriptSnippet(text='that the bigger your model is,', start=945.36, duration=5.919), FetchedTranscriptSnippet(text='the better your performance.', start=948.399, duration=5.68), FetchedTranscriptSnippet(text='So people just started building bigger', start=951.279, duration=6.081), FetchedTranscriptSnippet(text='and bigger models. So here in the uh', start=954.079, duration=6.0), FetchedTranscriptSnippet(text='illustration we saw that so on the y-', start=957.36, duration=5.52), FetchedTranscriptSnippet(text='axis is the test loss. So the lower the', start=960.079, duration=7.281), FetchedTranscriptSnippet(text='better. So we saw that the more compute', start=962.88, duration=8.56), FetchedTranscriptSnippet(text='you use the better your tests uh', start=967.36, duration=7.52), FetchedTranscriptSnippet(text='performance and same with uh increasing', start=971.44, duration=6.24), FetchedTranscriptSnippet(text='the data set size and same with', start=974.88, duration=6.16), FetchedTranscriptSnippet(text='increasing the number of parameters', start=977.68, duration=6.24), FetchedTranscriptSnippet(text='but then as you know compute is not', start=981.04, duration=5.28), FetchedTranscriptSnippet(text='infinite. So there was a natural', start=983.92, duration=5.599), FetchedTranscriptSnippet(text='question that came out of the community', start=986.32, duration=6.48), FetchedTranscriptSnippet(text='which was okay if we give you a given', start=989.519, duration=7.041), FetchedTranscriptSnippet(text='budget a given compute budget', start=992.8, duration=6.159), FetchedTranscriptSnippet(text='can you choose', start=996.56, duration=6.719), FetchedTranscriptSnippet(text='I guess some quote unquote optimal', start=998.959, duration=8.24), FetchedTranscriptSnippet(text='number of parameters and data set size', start=1003.279, duration=7.36), FetchedTranscriptSnippet(text='on which you want to train your model.', start=1007.199, duration=5.601), FetchedTranscriptSnippet(text='And so we saw that there was this paper', start=1010.639, duration=7.041), FetchedTranscriptSnippet(text='that was um published in the early 2020s', start=1012.8, duration=7.2), FetchedTranscriptSnippet(text='uh which actually studied the', start=1017.68, duration=4.719), FetchedTranscriptSnippet(text='relationship between', start=1020.0, duration=4.799), FetchedTranscriptSnippet(text='um I guess if you vary the data set size', start=1022.399, duration=6.56), FetchedTranscriptSnippet(text='and uh the size of your model and the', start=1024.799, duration=7.76), FetchedTranscriptSnippet(text='performance on the test set.', start=1028.959, duration=5.84), FetchedTranscriptSnippet(text='And then we saw that actually most', start=1032.559, duration=4.721), FetchedTranscriptSnippet(text='models at the time were what we say', start=1034.799, duration=5.841), FetchedTranscriptSnippet(text='undertrained because they were too big', start=1037.28, duration=4.96), FetchedTranscriptSnippet(text='compared to the data set that they were', start=1040.64, duration=3.12), FetchedTranscriptSnippet(text='trained on. Like the data set that they', start=1042.24, duration=3.599), FetchedTranscriptSnippet(text='were trained on it was not as big as', start=1043.76, duration=4.159), FetchedTranscriptSnippet(text='they should have been.', start=1045.839, duration=3.921), FetchedTranscriptSnippet(text='And so in particular there was a kind of', start=1047.919, duration=3.601), FetchedTranscriptSnippet(text='a rule of thumb that came out of this', start=1049.76, duration=6.24), FetchedTranscriptSnippet(text='which was if you have a given number of', start=1051.52, duration=7.2), FetchedTranscriptSnippet(text='parameters in your model', start=1056.0, duration=6.32), FetchedTranscriptSnippet(text='you should at least train it on 20 times', start=1058.72, duration=5.12), FetchedTranscriptSnippet(text='the number of parameters in terms of', start=1062.32, duration=3.68), FetchedTranscriptSnippet(text='tokens.', start=1063.84, duration=4.719), FetchedTranscriptSnippet(text='So for instance, if you have uh a 100', start=1066.0, duration=4.559), FetchedTranscriptSnippet(text='billion parameter model, you should', start=1068.559, duration=5.601), FetchedTranscriptSnippet(text='train it on at least two trillion', start=1070.559, duration=7.281), FetchedTranscriptSnippet(text='tokens because two trillion is 100', start=1074.16, duration=6.639), FetchedTranscriptSnippet(text=\"billion * 20. So that's kind of the rule\", start=1077.84, duration=6.64), FetchedTranscriptSnippet(text='of thumb that people have uh used and', start=1080.799, duration=5.841), FetchedTranscriptSnippet(text='then you know as I mentioned previously', start=1084.48, duration=4.8), FetchedTranscriptSnippet(text='you know these models are huge. So', start=1086.64, duration=5.6), FetchedTranscriptSnippet(text='people have tried to also make the', start=1089.28, duration=5.84), FetchedTranscriptSnippet(text='computation more efficient', start=1092.24, duration=4.88), FetchedTranscriptSnippet(text='and so there was this uh method that we', start=1095.12, duration=4.08), FetchedTranscriptSnippet(text='saw which is actually quite important', start=1097.12, duration=5.679), FetchedTranscriptSnippet(text='called flash attention', start=1099.2, duration=7.44), FetchedTranscriptSnippet(text='and flash attention is a method that', start=1102.799, duration=6.641), FetchedTranscriptSnippet(text='leverages the strength the strength of', start=1106.64, duration=5.2), FetchedTranscriptSnippet(text='the underlying hardware', start=1109.44, duration=6.08), FetchedTranscriptSnippet(text='and in particular it looks at so GPUs', start=1111.84, duration=6.079), FetchedTranscriptSnippet(text='more particularly it looks at the kinds', start=1115.52, duration=7.039), FetchedTranscriptSnippet(text='of memory memories that a GPU has.', start=1117.919, duration=10.0), FetchedTranscriptSnippet(text='So it has a big but slow memory and a', start=1122.559, duration=7.841), FetchedTranscriptSnippet(text='small but fast memory. So the HPM and', start=1127.919, duration=5.601), FetchedTranscriptSnippet(text='the SRAMM respectively.', start=1130.4, duration=7.36), FetchedTranscriptSnippet(text='And we saw that this method tries to', start=1133.52, duration=8.32), FetchedTranscriptSnippet(text='minimize the number of reads and writes', start=1137.76, duration=7.279), FetchedTranscriptSnippet(text='to the big and slow memory to the HPM.', start=1141.84, duration=7.12), FetchedTranscriptSnippet(text='And so the the way it was doing this was', start=1145.039, duration=7.841), FetchedTranscriptSnippet(text='to divide the computation in uh little', start=1148.96, duration=8.16), FetchedTranscriptSnippet(text='bits that it would send to uh the SRAMM', start=1152.88, duration=8.08), FetchedTranscriptSnippet(text='which is the small but fast memory so', start=1157.12, duration=5.6), FetchedTranscriptSnippet(text='that it can do the end to end', start=1160.96, duration=3.44), FetchedTranscriptSnippet(text='computation', start=1162.72, duration=4.56), FetchedTranscriptSnippet(text='and then send it back to where it was in', start=1164.4, duration=4.56), FetchedTranscriptSnippet(text='order to do the full end toend', start=1167.28, duration=4.48), FetchedTranscriptSnippet(text='computation.', start=1168.96, duration=5.36), FetchedTranscriptSnippet(text='So that method is an exact method', start=1171.76, duration=4.56), FetchedTranscriptSnippet(text=\"meaning that we're not doing any\", start=1174.32, duration=4.88), FetchedTranscriptSnippet(text='approximations to the results', start=1176.32, duration=6.0), FetchedTranscriptSnippet(text='but it led to significant speedups and', start=1179.2, duration=5.28), FetchedTranscriptSnippet(text='in particular there was this second idea', start=1182.32, duration=4.88), FetchedTranscriptSnippet(text='from uh the paper which is a kind of an', start=1184.48, duration=5.36), FetchedTranscriptSnippet(text='important one as well which was that', start=1187.2, duration=4.24), FetchedTranscriptSnippet(text='sometimes', start=1189.84, duration=6.48), FetchedTranscriptSnippet(text=\"it's okay for you to not store results.\", start=1191.44, duration=7.359), FetchedTranscriptSnippet(text=\"it's okay for you to just throw them out\", start=1196.32, duration=4.96), FetchedTranscriptSnippet(text='and then recomputee when you need them', start=1198.799, duration=5.041), FetchedTranscriptSnippet(text='again. So there is this idea of', start=1201.28, duration=4.16), FetchedTranscriptSnippet(text='recomputation', start=1203.84, duration=5.6), FetchedTranscriptSnippet(text='using what I described which led to', start=1205.44, duration=6.96), FetchedTranscriptSnippet(text='faster run times even though we were', start=1209.44, duration=6.84), FetchedTranscriptSnippet(text='doing more computations.', start=1212.4, duration=3.88), FetchedTranscriptSnippet(text='So that was flash flash attention and uh', start=1216.32, duration=6.8), FetchedTranscriptSnippet(text='we also saw a number of other methods', start=1219.44, duration=7.599), FetchedTranscriptSnippet(text='that were meant to I guess parallelize', start=1223.12, duration=6.88), FetchedTranscriptSnippet(text='the computation. So we saw uh data', start=1227.039, duration=4.64), FetchedTranscriptSnippet(text='parallelism', start=1230.0, duration=5.2), FetchedTranscriptSnippet(text='which was this idea of not having all', start=1231.679, duration=6.081), FetchedTranscriptSnippet(text='your data be processed on a single GPU', start=1235.2, duration=5.839), FetchedTranscriptSnippet(text='but instead divided into uh kind of', start=1237.76, duration=6.0), FetchedTranscriptSnippet(text='multiple places.', start=1241.039, duration=4.64), FetchedTranscriptSnippet(text='And then we had the second method which', start=1243.76, duration=5.279), FetchedTranscriptSnippet(text='was model parallelism', start=1245.679, duration=6.561), FetchedTranscriptSnippet(text='where even for a given forward pass you', start=1249.039, duration=7.841), FetchedTranscriptSnippet(text='would actually involve multiple GPUs.', start=1252.24, duration=6.48), FetchedTranscriptSnippet(text='So anyway, there were a lot of very', start=1256.88, duration=3.44), FetchedTranscriptSnippet(text='interesting techniques, a lot of', start=1258.72, duration=5.839), FetchedTranscriptSnippet(text='different uh ideas about how to train', start=1260.32, duration=7.92), FetchedTranscriptSnippet(text='this model in an efficient way.', start=1264.559, duration=6.721), FetchedTranscriptSnippet(text='And uh in particular um so what I', start=1268.24, duration=5.2), FetchedTranscriptSnippet(text='described here is mostly important for', start=1271.28, duration=5.68), FetchedTranscriptSnippet(text='the first step of uh the training', start=1273.44, duration=5.2), FetchedTranscriptSnippet(text='process of an LLM which is called the', start=1276.96, duration=3.92), FetchedTranscriptSnippet(text='pre-training', start=1278.64, duration=6.399), FetchedTranscriptSnippet(text='which is meant to teach the model about', start=1280.88, duration=6.88), FetchedTranscriptSnippet(text='the structure of language about the', start=1285.039, duration=5.601), FetchedTranscriptSnippet(text='structure of codes. Uh and in particular', start=1287.76, duration=5.6), FetchedTranscriptSnippet(text='this model was trained with huge amounts', start=1290.64, duration=6.159), FetchedTranscriptSnippet(text='of data. So think about trillions of', start=1293.36, duration=5.92), FetchedTranscriptSnippet(text='tokens or even tens of trillions of', start=1296.799, duration=4.561), FetchedTranscriptSnippet(text='tokens.', start=1299.28, duration=5.6), FetchedTranscriptSnippet(text='Um and so that first step goes from an', start=1301.36, duration=6.64), FetchedTranscriptSnippet(text='initialized model to a model that is', start=1304.88, duration=5.84), FetchedTranscriptSnippet(text='able to autocomplete because it is', start=1308.0, duration=5.52), FetchedTranscriptSnippet(text='trained with an objective of predicting', start=1310.72, duration=5.52), FetchedTranscriptSnippet(text='the next token.', start=1313.52, duration=6.48), FetchedTranscriptSnippet(text='So at the end of this first stage, you', start=1316.24, duration=6.08), FetchedTranscriptSnippet(text='have a model that knows how to', start=1320.0, duration=4.4), FetchedTranscriptSnippet(text='autocomplete, but you have a model that', start=1322.32, duration=5.359), FetchedTranscriptSnippet(text='is not very helpful because it only', start=1324.4, duration=6.8), FetchedTranscriptSnippet(text='knows how to complete things.', start=1327.679, duration=7.601), FetchedTranscriptSnippet(text='So in order to have the model be useful', start=1331.2, duration=7.44), FetchedTranscriptSnippet(text='for our use cases, we had this second', start=1335.28, duration=5.36), FetchedTranscriptSnippet(text='step which is called the fine-tuning', start=1338.64, duration=6.96), FetchedTranscriptSnippet(text='step. uh where we teach the model on the', start=1340.64, duration=7.76), FetchedTranscriptSnippet(text='kinds of input output pairs that we want', start=1345.6, duration=6.0), FetchedTranscriptSnippet(text='it to perform well. So this is also', start=1348.4, duration=6.72), FetchedTranscriptSnippet(text='called uh the SFT stage supervised', start=1351.6, duration=6.559), FetchedTranscriptSnippet(text='fine-tuning stage. And at the end of', start=1355.12, duration=6.4), FetchedTranscriptSnippet(text='this second step, we have a model that', start=1358.159, duration=7.441), FetchedTranscriptSnippet(text='not only knows the structure of text and', start=1361.52, duration=6.8), FetchedTranscriptSnippet(text='codes, but also is able to behave in the', start=1365.6, duration=5.439), FetchedTranscriptSnippet(text='way you want.', start=1368.32, duration=6.96), FetchedTranscriptSnippet(text='But so far up until step number two, we', start=1371.039, duration=8.801), FetchedTranscriptSnippet(text='have only taught our model what to do.', start=1375.28, duration=8.32), FetchedTranscriptSnippet(text='We have not taught it what to not do.', start=1379.84, duration=5.92), FetchedTranscriptSnippet(text='And this is why we had our third step', start=1383.6, duration=5.92), FetchedTranscriptSnippet(text='which was the preference tuning step', start=1385.76, duration=6.159), FetchedTranscriptSnippet(text='where we took our model that went', start=1389.52, duration=4.159), FetchedTranscriptSnippet(text='through the pre-training stage that went', start=1391.919, duration=4.801), FetchedTranscriptSnippet(text='to the SFT stage and now we want to', start=1393.679, duration=6.161), FetchedTranscriptSnippet(text='inject some negative signal as well as', start=1396.72, duration=7.839), FetchedTranscriptSnippet(text='in I want you to prefer this compared to', start=1399.84, duration=6.959), FetchedTranscriptSnippet(text='this output.', start=1404.559, duration=6.721), FetchedTranscriptSnippet(text='And this third step uses preference', start=1406.799, duration=8.081), FetchedTranscriptSnippet(text='data. So like the name uh suggests so', start=1411.28, duration=5.36), FetchedTranscriptSnippet(text='preference tuning uses preference data', start=1414.88, duration=5.44), FetchedTranscriptSnippet(text='which is typically pair-wise data where', start=1416.64, duration=5.919), FetchedTranscriptSnippet(text='humans say okay I prefer this output', start=1420.32, duration=5.96), FetchedTranscriptSnippet(text='compared to that output.', start=1422.559, duration=3.721), FetchedTranscriptSnippet(text='And typically the model here is able to', start=1426.32, duration=5.599), FetchedTranscriptSnippet(text='align the kind of output it produces', start=1429.2, duration=5.28), FetchedTranscriptSnippet(text='with human preferences that could be', start=1431.919, duration=6.481), FetchedTranscriptSnippet(text='along the dimension of uh usefulness of', start=1434.48, duration=7.439), FetchedTranscriptSnippet(text=\"safety, friendliness, tone. Um there's a\", start=1438.4, duration=5.68), FetchedTranscriptSnippet(text='bunch of different dimensions but uh', start=1441.919, duration=4.081), FetchedTranscriptSnippet(text=\"yeah so that's what is happening in this\", start=1444.08, duration=4.56), FetchedTranscriptSnippet(text='third step.', start=1446.0, duration=5.6), FetchedTranscriptSnippet(text=\"And in this third step, it's actually in\", start=1448.64, duration=7.2), FetchedTranscriptSnippet(text='lecture five that we dug into what that', start=1451.6, duration=8.4), FetchedTranscriptSnippet(text='third step was about. So if you remember', start=1455.84, duration=6.959), FetchedTranscriptSnippet(text='uh we had drawn a parallel', start=1460.0, duration=7.679), FetchedTranscriptSnippet(text='between the way our LLM produces tokens', start=1462.799, duration=7.521), FetchedTranscriptSnippet(text='and I guess what people in the', start=1467.679, duration=6.641), FetchedTranscriptSnippet(text='reinforcement learning field um I guess', start=1470.32, duration=8.56), FetchedTranscriptSnippet(text='consider how uh given policy is uh', start=1474.32, duration=6.88), FetchedTranscriptSnippet(text='interacting with some environment and', start=1478.88, duration=4.08), FetchedTranscriptSnippet(text='performing some action and being in some', start=1481.2, duration=4.959), FetchedTranscriptSnippet(text='states. uh and the reason why we drew', start=1482.96, duration=5.839), FetchedTranscriptSnippet(text='drew that parallel was to be able to', start=1486.159, duration=6.561), FetchedTranscriptSnippet(text='leverage some RLbased techniques', start=1488.799, duration=6.641), FetchedTranscriptSnippet(text='in order to train our model. So in this', start=1492.72, duration=5.36), FetchedTranscriptSnippet(text='case we said our LLM is a little bit', start=1495.44, duration=4.88), FetchedTranscriptSnippet(text='like a policy.', start=1498.08, duration=5.12), FetchedTranscriptSnippet(text='So given some state which is the input', start=1500.32, duration=7.12), FetchedTranscriptSnippet(text='it has received so far it can perform', start=1503.2, duration=6.8), FetchedTranscriptSnippet(text='the next action and in this case it is', start=1507.44, duration=5.76), FetchedTranscriptSnippet(text='to predict the next token', start=1510.0, duration=7.2), FetchedTranscriptSnippet(text='and this prediction is made in the', start=1513.2, duration=7.04), FetchedTranscriptSnippet(text='environment of tokens', start=1517.2, duration=8.16), FetchedTranscriptSnippet(text='and when we u like predict a completion', start=1520.24, duration=6.96), FetchedTranscriptSnippet(text='what we do is at the end of the day we', start=1525.36, duration=5.52), FetchedTranscriptSnippet(text='have some signal some reward part which', start=1527.2, duration=7.28), FetchedTranscriptSnippet(text='can be the human preference.', start=1530.88, duration=5.84), FetchedTranscriptSnippet(text='So this is the parallel we drew with the', start=1534.48, duration=5.28), FetchedTranscriptSnippet(text='RL worlds and with that in mind we', start=1536.72, duration=5.04), FetchedTranscriptSnippet(text='talked about rewards', start=1539.76, duration=4.48), FetchedTranscriptSnippet(text='but the problem is that rewards are only', start=1541.76, duration=6.24), FetchedTranscriptSnippet(text='available for a limited set of data', start=1544.24, duration=6.799), FetchedTranscriptSnippet(text='which is why we saw how to model', start=1548.0, duration=4.559), FetchedTranscriptSnippet(text='rewards.', start=1551.039, duration=3.681), FetchedTranscriptSnippet(text='So we saw this formula if you remember', start=1552.559, duration=4.24), FetchedTranscriptSnippet(text=\"it's called the Bradley Terry\", start=1554.72, duration=4.0), FetchedTranscriptSnippet(text='formulation', start=1556.799, duration=5.36), FetchedTranscriptSnippet(text='which um models', start=1558.72, duration=7.199), FetchedTranscriptSnippet(text='how the probability of an output being', start=1562.159, duration=7.12), FetchedTranscriptSnippet(text='better than another one is as a function', start=1565.919, duration=6.64), FetchedTranscriptSnippet(text='of I guess two scores like the score of', start=1569.279, duration=6.801), FetchedTranscriptSnippet(text='output I and the score of output J. And', start=1572.559, duration=6.321), FetchedTranscriptSnippet(text='we saw that reward models they are', start=1576.08, duration=5.76), FetchedTranscriptSnippet(text='typically trained by having this', start=1578.88, duration=5.279), FetchedTranscriptSnippet(text='formulation in mind in a pair-wise', start=1581.84, duration=4.16), FetchedTranscriptSnippet(text='fashion.', start=1584.159, duration=5.201), FetchedTranscriptSnippet(text='So what this means is a reward model you', start=1586.0, duration=5.76), FetchedTranscriptSnippet(text='give it two outputs. You say this one is', start=1589.36, duration=5.28), FetchedTranscriptSnippet(text='good, this one is bad and then I want', start=1591.76, duration=5.68), FetchedTranscriptSnippet(text='you to say this one is good. You train', start=1594.64, duration=5.68), FetchedTranscriptSnippet(text='it in a pair wise fashion. But then your', start=1597.44, duration=5.359), FetchedTranscriptSnippet(text='model is actually predicting always two', start=1600.32, duration=4.88), FetchedTranscriptSnippet(text=\"scores. It's always predicting the score\", start=1602.799, duration=7.12), FetchedTranscriptSnippet(text='RA I for output I RJ for output J. Um', start=1605.2, duration=8.079), FetchedTranscriptSnippet(text=\"and so at inference time you're only\", start=1609.919, duration=7.201), FetchedTranscriptSnippet(text='giving it one output.', start=1613.279, duration=5.921), FetchedTranscriptSnippet(text=\"So I think that's like one subtlety like\", start=1617.12, duration=3.919), FetchedTranscriptSnippet(text='we train it in a pair wise way but at', start=1619.2, duration=6.32), FetchedTranscriptSnippet(text=\"inference time we're kind of using it\", start=1621.039, duration=6.401), FetchedTranscriptSnippet(text='in a in an individual way if that makes', start=1625.52, duration=4.159), FetchedTranscriptSnippet(text='sense.', start=1627.44, duration=5.119), FetchedTranscriptSnippet(text='And so once we trained our reward model', start=1629.679, duration=5.041), FetchedTranscriptSnippet(text='using this formulation', start=1632.559, duration=6.561), FetchedTranscriptSnippet(text='then we were able to use it to steer our', start=1634.72, duration=7.199), FetchedTranscriptSnippet(text='LLM towards the direction that we care', start=1639.12, duration=4.32), FetchedTranscriptSnippet(text='about.', start=1641.919, duration=4.801), FetchedTranscriptSnippet(text='So if you remember the way we steer our', start=1643.44, duration=6.479), FetchedTranscriptSnippet(text='LLM in the direction of human', start=1646.72, duration=7.92), FetchedTranscriptSnippet(text='preferences is to give it a prompt', start=1649.919, duration=8.561), FetchedTranscriptSnippet(text='so that it can produce a completion', start=1654.64, duration=8.48), FetchedTranscriptSnippet(text='aka a rollout or in simpler terms an an', start=1658.48, duration=6.4), FetchedTranscriptSnippet(text='answer.', start=1663.12, duration=4.24), FetchedTranscriptSnippet(text='And then we take this prompt, we take', start=1664.88, duration=5.039), FetchedTranscriptSnippet(text='this answer, we put them both in the', start=1667.36, duration=6.0), FetchedTranscriptSnippet(text='reward model that tells us how good the', start=1669.919, duration=5.681), FetchedTranscriptSnippet(text='model response is.', start=1673.36, duration=4.08), FetchedTranscriptSnippet(text='And depending on what the reward model', start=1675.6, duration=6.64), FetchedTranscriptSnippet(text='says, we can tune the weights of the LLM', start=1677.44, duration=8.0), FetchedTranscriptSnippet(text='in a way that maximizes human or the', start=1682.24, duration=5.52), FetchedTranscriptSnippet(text='reward that we saw which is trained on', start=1685.44, duration=5.52), FetchedTranscriptSnippet(text='human preferences.', start=1687.76, duration=8.799), FetchedTranscriptSnippet(text='And the loss function of this RL uh', start=1690.96, duration=7.12), FetchedTranscriptSnippet(text='setup', start=1696.559, duration=4.401), FetchedTranscriptSnippet(text='is typically something that tries to', start=1698.08, duration=5.68), FetchedTranscriptSnippet(text='maximize rewards', start=1700.96, duration=6.64), FetchedTranscriptSnippet(text='but also keep the model close to the', start=1703.76, duration=6.24), FetchedTranscriptSnippet(text='base model. And here by base model we', start=1707.6, duration=5.6), FetchedTranscriptSnippet(text='mean the SFT model. And the reason why', start=1710.0, duration=6.159), FetchedTranscriptSnippet(text='we want that is because this reward is', start=1713.2, duration=4.479), FetchedTranscriptSnippet(text='imperfect.', start=1716.159, duration=4.081), FetchedTranscriptSnippet(text='So we saw this uh phenomenon of reward', start=1717.679, duration=4.161), FetchedTranscriptSnippet(text='hacking', start=1720.24, duration=5.039), FetchedTranscriptSnippet(text='where your reward can be imperfect and', start=1721.84, duration=8.24), FetchedTranscriptSnippet(text='the LLM can exploit its imperfect nature', start=1725.279, duration=6.961), FetchedTranscriptSnippet(text='to tune it in a way that actually does', start=1730.08, duration=4.88), FetchedTranscriptSnippet(text='not align with what you want it to be.', start=1732.24, duration=5.439), FetchedTranscriptSnippet(text='So you want the LLM to not be too far', start=1734.96, duration=6.0), FetchedTranscriptSnippet(text='from the base model which is actually', start=1737.679, duration=5.841), FetchedTranscriptSnippet(text=\"already a good model. So it's a way to\", start=1740.96, duration=6.319), FetchedTranscriptSnippet(text='regularize that if you want and you also', start=1743.52, duration=6.72), FetchedTranscriptSnippet(text='want the', start=1747.279, duration=6.4), FetchedTranscriptSnippet(text='iteration updates to not be too big', start=1750.24, duration=5.039), FetchedTranscriptSnippet(text='either.', start=1753.679, duration=3.521), FetchedTranscriptSnippet(text='So you typically have these two', start=1755.279, duration=3.12), FetchedTranscriptSnippet(text=\"constraints. You don't want it to\", start=1757.2, duration=2.8), FetchedTranscriptSnippet(text='deviate too much from the base model,', start=1758.399, duration=2.961), FetchedTranscriptSnippet(text=\"but you don't want it to deviate too\", start=1760.0, duration=5.52), FetchedTranscriptSnippet(text='much from the previous RL iteration.', start=1761.36, duration=5.76), FetchedTranscriptSnippet(text='And then just as a reminder, I think', start=1765.52, duration=3.759), FetchedTranscriptSnippet(text='this was lecture five. I think was the', start=1767.12, duration=4.64), FetchedTranscriptSnippet(text='most technically challenging of the', start=1769.279, duration=5.76), FetchedTranscriptSnippet(text='whole class. So completely fine if the', start=1771.76, duration=4.88), FetchedTranscriptSnippet(text=\"first time you were like you know what's\", start=1775.039, duration=3.921), FetchedTranscriptSnippet(text='happening. Uh but hopefully now it', start=1776.64, duration=6.08), FetchedTranscriptSnippet(text='should be a little bit more more clear.', start=1778.96, duration=5.92), FetchedTranscriptSnippet(text='Uh cool. And then after lecture five', start=1782.72, duration=4.0), FetchedTranscriptSnippet(text=\"we're like okay we've done a lot of uh\", start=1784.88, duration=5.039), FetchedTranscriptSnippet(text='hard work. So uh the good thing is you', start=1786.72, duration=7.199), FetchedTranscriptSnippet(text=\"know we're in 2025 and in the past 12\", start=1789.919, duration=8.081), FetchedTranscriptSnippet(text=\"months or now 14 months we've seen a lot\", start=1793.919, duration=6.64), FetchedTranscriptSnippet(text='of models that were being released with', start=1798.0, duration=5.2), FetchedTranscriptSnippet(text='these reasoning capabilities', start=1800.559, duration=6.72), FetchedTranscriptSnippet(text='and the way they were trained to exhibit', start=1803.2, duration=7.44), FetchedTranscriptSnippet(text='these advanced reasoning capabilities', start=1807.279, duration=5.841), FetchedTranscriptSnippet(text='was actually leveraging a lot of the', start=1810.64, duration=5.84), FetchedTranscriptSnippet(text='techniques that we saw in lecture 5', start=1813.12, duration=6.159), FetchedTranscriptSnippet(text='just like oral based techniques.', start=1816.48, duration=5.439), FetchedTranscriptSnippet(text='And in particular, what we want our LLM', start=1819.279, duration=8.961), FetchedTranscriptSnippet(text='to do is to output a reasoning chain', start=1821.919, duration=10.081), FetchedTranscriptSnippet(text='before producing the final answer.', start=1828.24, duration=5.6), FetchedTranscriptSnippet(text='And the reason why we wanted to do that', start=1832.0, duration=4.24), FetchedTranscriptSnippet(text='is because people have seen that it', start=1833.84, duration=5.439), FetchedTranscriptSnippet(text='improves the performance of the model.', start=1836.24, duration=4.96), FetchedTranscriptSnippet(text=\"And so it's actually relying on this\", start=1839.279, duration=5.441), FetchedTranscriptSnippet(text='idea of chain of thoughts, which I', start=1841.2, duration=6.32), FetchedTranscriptSnippet(text='believe we saw at lecture three.', start=1844.72, duration=4.959), FetchedTranscriptSnippet(text='which is a prompting technique to have', start=1847.52, duration=5.6), FetchedTranscriptSnippet(text='your model output the reasoning before', start=1849.679, duration=6.321), FetchedTranscriptSnippet(text='outputting the the response.', start=1853.12, duration=5.919), FetchedTranscriptSnippet(text='So long story short, up until lecture', start=1856.0, duration=6.0), FetchedTranscriptSnippet(text='six, our LLM was having a prompt as', start=1859.039, duration=6.561), FetchedTranscriptSnippet(text='input directly outputting the output.', start=1862.0, duration=6.24), FetchedTranscriptSnippet(text='But in lecture seven, we said, sorry, in', start=1865.6, duration=6.0), FetchedTranscriptSnippet(text=\"lecture six, we said, uh, well, let's\", start=1868.24, duration=6.72), FetchedTranscriptSnippet(text='have our LLM actually first output a', start=1871.6, duration=6.0), FetchedTranscriptSnippet(text='reasoning chain that the user may or may', start=1874.96, duration=5.599), FetchedTranscriptSnippet(text='not have access to before outputting the', start=1877.6, duration=6.16), FetchedTranscriptSnippet(text='final answer.', start=1880.559, duration=5.921), FetchedTranscriptSnippet(text='So you want to teach the LM to do that.', start=1883.76, duration=5.12), FetchedTranscriptSnippet(text='So how do you do that? Well, first', start=1886.48, duration=4.48), FetchedTranscriptSnippet(text='before doing this, I just want to show', start=1888.88, duration=4.799), FetchedTranscriptSnippet(text='you this chart which we saw which is the', start=1890.96, duration=7.28), FetchedTranscriptSnippet(text=\"performance of uh the model as we're\", start=1893.679, duration=7.921), FetchedTranscriptSnippet(text='teaching it to produce these reasoning', start=1898.24, duration=6.24), FetchedTranscriptSnippet(text='chains. So people have typically', start=1901.6, duration=5.199), FetchedTranscriptSnippet(text='measured uh the improvement in', start=1904.48, duration=6.0), FetchedTranscriptSnippet(text='performance by comparing it to uh I', start=1906.799, duration=5.521), FetchedTranscriptSnippet(text='guess certain benchmarks and this one is', start=1910.48, duration=5.12), FetchedTranscriptSnippet(text='a popular one the AIM benchmark which is', start=1912.32, duration=7.52), FetchedTranscriptSnippet(text='the math math benchmark and we saw that', start=1915.6, duration=7.6), FetchedTranscriptSnippet(text='as the training progresses the accuracy', start=1919.84, duration=6.24), FetchedTranscriptSnippet(text='number of uh I guess what the LLM', start=1923.2, duration=5.44), FetchedTranscriptSnippet(text='outputs is increasing.', start=1926.08, duration=5.28), FetchedTranscriptSnippet(text='But back to what I was I was saying uh', start=1928.64, duration=7.039), FetchedTranscriptSnippet(text='the key technique that we use to teach', start=1931.36, duration=8.72), FetchedTranscriptSnippet(text='the model how to output these reasoning', start=1935.679, duration=7.041), FetchedTranscriptSnippet(text='chains is', start=1940.08, duration=5.04), FetchedTranscriptSnippet(text='leveraging the RL techniques that we saw', start=1942.72, duration=6.16), FetchedTranscriptSnippet(text='in lecture five. And in particular', start=1945.12, duration=8.88), FetchedTranscriptSnippet(text='um up until now we saw PO which was the', start=1948.88, duration=9.12), FetchedTranscriptSnippet(text='main RL algorithm that people were using', start=1954.0, duration=9.12), FetchedTranscriptSnippet(text='up to maybe last year and now people are', start=1958.0, duration=8.72), FetchedTranscriptSnippet(text='kind of prioritizing GRPO as an R', start=1963.12, duration=6.48), FetchedTranscriptSnippet(text='algorithm in order to teach the model to', start=1966.72, duration=5.839), FetchedTranscriptSnippet(text='be better at reasoning tasks.', start=1969.6, duration=4.88), FetchedTranscriptSnippet(text='And there are several reasons to do to', start=1972.559, duration=4.801), FetchedTranscriptSnippet(text='to that that I will explicit right now.', start=1974.48, duration=6.72), FetchedTranscriptSnippet(text='So we saw this illustration that', start=1977.36, duration=9.6), FetchedTranscriptSnippet(text='compared how GRPO was differing with PO', start=1981.2, duration=8.4), FetchedTranscriptSnippet(text='and if you can see in the graph uh there', start=1986.96, duration=5.36), FetchedTranscriptSnippet(text='are a few things that are different.', start=1989.6, duration=6.0), FetchedTranscriptSnippet(text='The first thing is that GRPO does not', start=1992.32, duration=8.0), FetchedTranscriptSnippet(text='rely on a value model.', start=1995.6, duration=9.64), FetchedTranscriptSnippet(text='So, who remembers what a value model is?', start=2000.32, duration=4.92), FetchedTranscriptSnippet(text='Yep.', start=2009.12, duration=3.0), FetchedTranscriptSnippet(text='Yes. Exactly. So, the value function is', start=2015.6, duration=5.439), FetchedTranscriptSnippet(text='trying to predict what the reward would', start=2018.96, duration=6.319), FetchedTranscriptSnippet(text='be if you um were to follow the policy', start=2021.039, duration=8.801), FetchedTranscriptSnippet(text=\"of the LLM. Um, and I guess it's a way\", start=2025.279, duration=11.441), FetchedTranscriptSnippet(text='to have some baseline as to how good', start=2029.84, duration=9.36), FetchedTranscriptSnippet(text='some predictions are. You want to make', start=2036.72, duration=5.28), FetchedTranscriptSnippet(text='it more relative. So the value function', start=2039.2, duration=6.56), FetchedTranscriptSnippet(text='is a way for us to make these uh rewards', start=2042.0, duration=5.84), FetchedTranscriptSnippet(text='a little bit more relative to one', start=2045.76, duration=4.879), FetchedTranscriptSnippet(text=\"another. Um, and so that's what that's\", start=2047.84, duration=5.2), FetchedTranscriptSnippet(text='how PPU was doing this. So it was having', start=2050.639, duration=5.76), FetchedTranscriptSnippet(text='a value model that was um making these', start=2053.04, duration=6.559), FetchedTranscriptSnippet(text='predictions and then we had uh this', start=2056.399, duration=6.161), FetchedTranscriptSnippet(text='generalized advantage estimation method', start=2059.599, duration=6.0), FetchedTranscriptSnippet(text='that was combining the reward', start=2062.56, duration=4.799), FetchedTranscriptSnippet(text='predictions', start=2065.599, duration=5.04), FetchedTranscriptSnippet(text='with the value function predictions in', start=2067.359, duration=6.48), FetchedTranscriptSnippet(text='order to have what we call advantages.', start=2070.639, duration=7.121), FetchedTranscriptSnippet(text='So advantages is how good your output is', start=2073.839, duration=7.121), FetchedTranscriptSnippet(text='compared to some baseline.', start=2077.76, duration=7.28), FetchedTranscriptSnippet(text='But then in contrast to that, GRPL said,', start=2080.96, duration=7.76), FetchedTranscriptSnippet(text='\"Okay, tree, we don\\'t need a value', start=2085.04, duration=5.52), FetchedTranscriptSnippet(text=\"function because it's, you know, too\", start=2088.72, duration=4.8), FetchedTranscriptSnippet(text='expensive to to train, to maintain. What', start=2090.56, duration=5.44), FetchedTranscriptSnippet(text=\"we're going to do instead\", start=2093.52, duration=6.079), FetchedTranscriptSnippet(text='is generate several completions', start=2096.0, duration=8.72), FetchedTranscriptSnippet(text='and then have some formula that compares', start=2099.599, duration=8.081), FetchedTranscriptSnippet(text='the rewards of these completion these', start=2104.72, duration=4.639), FetchedTranscriptSnippet(text='completions', start=2107.68, duration=4.64), FetchedTranscriptSnippet(text='to one another.', start=2109.359, duration=7.601), FetchedTranscriptSnippet(text=\"So it's going to have some relative\", start=2112.32, duration=6.64), FetchedTranscriptSnippet(text='effect in a sense that it will make', start=2116.96, duration=5.119), FetchedTranscriptSnippet(text='things more relative', start=2118.96, duration=8.08), FetchedTranscriptSnippet(text='and in doing so you are actually not', start=2122.079, duration=8.321), FetchedTranscriptSnippet(text='uh needed to maintain and train a value', start=2127.04, duration=6.0), FetchedTranscriptSnippet(text=\"function and that's like one big\", start=2130.4, duration=5.28), FetchedTranscriptSnippet(text='difference compared to PO.', start=2133.04, duration=6.48), FetchedTranscriptSnippet(text='Um and uh the second big difference', start=2135.68, duration=5.52), FetchedTranscriptSnippet(text='which is not represented in this', start=2139.52, duration=5.52), FetchedTranscriptSnippet(text='illustration uh is that uh GRPO is', start=2141.2, duration=6.399), FetchedTranscriptSnippet(text='typically an algorithm that people have', start=2145.04, duration=5.76), FetchedTranscriptSnippet(text='used in the context of', start=2147.599, duration=4.961), FetchedTranscriptSnippet(text='teaching your model to be better at', start=2150.8, duration=4.48), FetchedTranscriptSnippet(text='reasoning tasks.', start=2152.56, duration=5.279), FetchedTranscriptSnippet(text='And so we saw that these kinds of', start=2155.28, duration=4.079), FetchedTranscriptSnippet(text='problems', start=2157.839, duration=5.76), FetchedTranscriptSnippet(text='have a verifiable reward', start=2159.359, duration=6.161), FetchedTranscriptSnippet(text='because when you complete a math', start=2163.599, duration=3.681), FetchedTranscriptSnippet(text='problem,', start=2165.52, duration=3.44), FetchedTranscriptSnippet(text='you actually know the answer you need to', start=2167.28, duration=4.799), FetchedTranscriptSnippet(text=\"get to. So you don't need to train a\", start=2168.96, duration=5.68), FetchedTranscriptSnippet(text='reward model to tell you how good your', start=2172.079, duration=4.561), FetchedTranscriptSnippet(text='final answer is because you you already', start=2174.64, duration=4.4), FetchedTranscriptSnippet(text='know the answer.', start=2176.64, duration=5.28), FetchedTranscriptSnippet(text='And so we saw that GRPO was in', start=2179.04, duration=6.16), FetchedTranscriptSnippet(text='particular used in the context of when', start=2181.92, duration=5.12), FetchedTranscriptSnippet(text=\"you actually don't even need a reward\", start=2185.2, duration=3.84), FetchedTranscriptSnippet(text='model when you actually have a', start=2187.04, duration=4.72), FetchedTranscriptSnippet(text='verifiable reward. So at the end of the', start=2189.04, duration=6.0), FetchedTranscriptSnippet(text='day, the only two models you need to', start=2191.76, duration=6.96), FetchedTranscriptSnippet(text='keep are the policy model', start=2195.04, duration=6.96), FetchedTranscriptSnippet(text='and the reference model to be able to', start=2198.72, duration=5.6), FetchedTranscriptSnippet(text='just compare how far you are from the', start=2202.0, duration=5.72), FetchedTranscriptSnippet(text='reference model.', start=2204.32, duration=3.4), FetchedTranscriptSnippet(text='Cool. Um, I know this one was also a', start=2209.52, duration=5.839), FetchedTranscriptSnippet(text='challenging class, I guess. So far so', start=2212.32, duration=5.44), FetchedTranscriptSnippet(text='good. And this is also on on the final.', start=2215.359, duration=5.681), FetchedTranscriptSnippet(text=\"So, which is why I'm I'm taking things\", start=2217.76, duration=6.48), FetchedTranscriptSnippet(text='more slowly for this second part of the', start=2221.04, duration=7.36), FetchedTranscriptSnippet(text='recap. So, is everything good so far?', start=2224.24, duration=5.92), FetchedTranscriptSnippet(text='Yeah.', start=2228.4, duration=3.679), FetchedTranscriptSnippet(text='Okay. Perfect. We also saw some', start=2230.16, duration=4.32), FetchedTranscriptSnippet(text='extensions of GRPO. So if you remember', start=2232.079, duration=7.76), FetchedTranscriptSnippet(text='there was um some kind of bias that was', start=2234.48, duration=12.48), FetchedTranscriptSnippet(text='um a result of the loss function of GRPO', start=2239.839, duration=10.481), FetchedTranscriptSnippet(text='having some normalization term that', start=2246.96, duration=5.6), FetchedTranscriptSnippet(text='penalized', start=2250.32, duration=8.72), FetchedTranscriptSnippet(text='tokens that were in shorter outputs.', start=2252.56, duration=11.36), FetchedTranscriptSnippet(text='So we saw that if you use GRPO in its', start=2259.04, duration=8.16), FetchedTranscriptSnippet(text='original case in its original form', start=2263.92, duration=6.88), FetchedTranscriptSnippet(text='we saw that after a certain point', start=2267.2, duration=5.76), FetchedTranscriptSnippet(text='the algorithm will incentivize your', start=2270.8, duration=5.6), FetchedTranscriptSnippet(text='model to produce longer and longer', start=2272.96, duration=5.44), FetchedTranscriptSnippet(text='answers longer and longer incorrect', start=2276.4, duration=3.679), FetchedTranscriptSnippet(text='answers.', start=2278.4, duration=3.76), FetchedTranscriptSnippet(text='And the reason why it does that is', start=2280.079, duration=5.04), FetchedTranscriptSnippet(text='because relative to short incorrect', start=2282.16, duration=4.48), FetchedTranscriptSnippet(text='answers,', start=2285.119, duration=4.321), FetchedTranscriptSnippet(text='it penalizes less', start=2286.64, duration=6.24), FetchedTranscriptSnippet(text='long incorrect answers. And so this is', start=2289.44, duration=5.52), FetchedTranscriptSnippet(text='the reason why there are some extensions', start=2292.88, duration=5.84), FetchedTranscriptSnippet(text='that people have worked on this year.', start=2294.96, duration=7.2), FetchedTranscriptSnippet(text='One of which was uh GRPO done rights. So', start=2298.72, duration=6.0), FetchedTranscriptSnippet(text='we saw like um that they basically', start=2302.16, duration=5.04), FetchedTranscriptSnippet(text='removed the normalization term and there', start=2304.72, duration=4.8), FetchedTranscriptSnippet(text='was another method that we saw it was', start=2307.2, duration=5.44), FetchedTranscriptSnippet(text='called depo dapo', start=2309.52, duration=7.16), FetchedTranscriptSnippet(text='which also had some variance', start=2312.64, duration=4.04), FetchedTranscriptSnippet(text=\"and that's for reasoning models and then\", start=2317.04, duration=7.039), FetchedTranscriptSnippet(text='lecture seven we had a model that you', start=2319.839, duration=8.081), FetchedTranscriptSnippet(text='know we knew how to train it we knew how', start=2324.079, duration=7.201), FetchedTranscriptSnippet(text='to uh use it for uh reasoning tasks how', start=2327.92, duration=5.36), FetchedTranscriptSnippet(text='to train it to be better but now we', start=2331.28, duration=4.72), FetchedTranscriptSnippet(text='wanted the model to be useful and', start=2333.28, duration=7.76), FetchedTranscriptSnippet(text='interacting with outside systems.', start=2336.0, duration=9.44), FetchedTranscriptSnippet(text='So we saw one technique that is kind of', start=2341.04, duration=6.88), FetchedTranscriptSnippet(text='an an essential technique called rag', start=2345.44, duration=6.399), FetchedTranscriptSnippet(text='short for retrieval augmented generation', start=2347.92, duration=7.76), FetchedTranscriptSnippet(text='that is meant for you to be able to', start=2351.839, duration=7.361), FetchedTranscriptSnippet(text='fetch relevant documents from some', start=2355.68, duration=7.52), FetchedTranscriptSnippet(text='knowledge base in order to answer', start=2359.2, duration=7.04), FetchedTranscriptSnippet(text='a question or answer a prompt.', start=2363.2, duration=5.84), FetchedTranscriptSnippet(text='And the reason why you want to do that', start=2366.24, duration=8.0), FetchedTranscriptSnippet(text='is that the knowledge of your LLM is', start=2369.04, duration=8.48), FetchedTranscriptSnippet(text='including up to', start=2374.24, duration=7.04), FetchedTranscriptSnippet(text='the data that is up to the knowledge cut', start=2377.52, duration=8.0), FetchedTranscriptSnippet(text='updates which is the max dates of what', start=2381.28, duration=7.12), FetchedTranscriptSnippet(text='your LM has been trained on.', start=2385.52, duration=5.52), FetchedTranscriptSnippet(text='And from a practical standpoint,', start=2388.4, duration=5.52), FetchedTranscriptSnippet(text='I guess from what we see nowadays,', start=2391.04, duration=5.12), FetchedTranscriptSnippet(text=\"you're typically not training your LLM\", start=2393.92, duration=6.32), FetchedTranscriptSnippet(text='daily or continuously. And so in cases', start=2396.16, duration=6.24), FetchedTranscriptSnippet(text='where you need your LLM to know about', start=2400.24, duration=6.08), FetchedTranscriptSnippet(text='things that happened recently or about', start=2402.4, duration=6.88), FetchedTranscriptSnippet(text='things that happened that were not', start=2406.32, duration=6.16), FetchedTranscriptSnippet(text='in your LM training data,', start=2409.28, duration=5.44), FetchedTranscriptSnippet(text='you want your LLM to have access to such', start=2412.48, duration=7.2), FetchedTranscriptSnippet(text=\"information. And so that's how rag is\", start=2414.72, duration=7.6), FetchedTranscriptSnippet(text='very useful. So we saw that rag', start=2419.68, duration=6.24), FetchedTranscriptSnippet(text='dependent very heavily on the way it', start=2422.32, duration=6.799), FetchedTranscriptSnippet(text='retrieves data. So we saw that the', start=2425.92, duration=5.919), FetchedTranscriptSnippet(text='retrieval part was mainly composed of', start=2429.119, duration=6.24), FetchedTranscriptSnippet(text='two steps. So the first one was', start=2431.839, duration=6.0), FetchedTranscriptSnippet(text='candidate retrieval', start=2435.359, duration=6.081), FetchedTranscriptSnippet(text='which use which uses a by encoder kind', start=2437.839, duration=8.161), FetchedTranscriptSnippet(text=\"of setup where you're basically doing\", start=2441.44, duration=6.8), FetchedTranscriptSnippet(text=\"some semantic search. So you're\", start=2446.0, duration=4.32), FetchedTranscriptSnippet(text='computing the embedding of the query.', start=2448.24, duration=4.96), FetchedTranscriptSnippet(text='you have some precomputed embeddings of', start=2450.32, duration=5.44), FetchedTranscriptSnippet(text='the documents in your knowledge base and', start=2453.2, duration=5.119), FetchedTranscriptSnippet(text=\"you're taking the ones that maximize\", start=2455.76, duration=5.599), FetchedTranscriptSnippet(text=\"some similarity score like let's say\", start=2458.319, duration=6.961), FetchedTranscriptSnippet(text='some cosign similarity.', start=2461.359, duration=6.641), FetchedTranscriptSnippet(text='So the this first step is allowing you', start=2465.28, duration=4.48), FetchedTranscriptSnippet(text='to retrieve', start=2468.0, duration=5.2), FetchedTranscriptSnippet(text='um I guess a filtered version of the', start=2469.76, duration=6.079), FetchedTranscriptSnippet(text='potential documents and then typically', start=2473.2, duration=5.84), FetchedTranscriptSnippet(text='you have a second step which is called', start=2475.839, duration=6.48), FetchedTranscriptSnippet(text='ranking or reranking because the first', start=2479.04, duration=6.16), FetchedTranscriptSnippet(text='step already gives you a ranking which', start=2482.319, duration=6.0), FetchedTranscriptSnippet(text='has typically a more sophisticated', start=2485.2, duration=5.04), FetchedTranscriptSnippet(text='setup.', start=2488.319, duration=5.04), FetchedTranscriptSnippet(text=\"So it's a cross encoder kind of setup\", start=2490.24, duration=6.96), FetchedTranscriptSnippet(text='where you have your query and your', start=2493.359, duration=7.76), FetchedTranscriptSnippet(text='document that are both fed to some model', start=2497.2, duration=8.32), FetchedTranscriptSnippet(text='and produces a more precise score', start=2501.119, duration=7.361), FetchedTranscriptSnippet(text='and then you use this final score to', start=2505.52, duration=6.96), FetchedTranscriptSnippet(text='rank the final results and you typically', start=2508.48, duration=6.72), FetchedTranscriptSnippet(text=\"choose the top let's say K\", start=2512.48, duration=5.04), FetchedTranscriptSnippet(text='and then you add them to your prompt. So', start=2515.2, duration=4.72), FetchedTranscriptSnippet(text=\"it's the augmented part. So retrieval is\", start=2517.52, duration=4.88), FetchedTranscriptSnippet(text='everything I mentioned so far and then', start=2519.92, duration=5.04), FetchedTranscriptSnippet(text='once you have the relevant documents you', start=2522.4, duration=4.959), FetchedTranscriptSnippet(text='add them in your prompt which is the', start=2524.96, duration=4.56), FetchedTranscriptSnippet(text='augmented part and you generate the', start=2527.359, duration=4.561), FetchedTranscriptSnippet(text='answer.', start=2529.52, duration=4.0), FetchedTranscriptSnippet(text=\"So the reason why I'm taking so much\", start=2531.92, duration=5.36), FetchedTranscriptSnippet(text='time on rag is rag is such an important', start=2533.52, duration=6.559), FetchedTranscriptSnippet(text='concept also', start=2537.28, duration=5.28), FetchedTranscriptSnippet(text='if you were to you know have interviews', start=2540.079, duration=5.121), FetchedTranscriptSnippet(text='or you know also maybe in the exam who', start=2542.56, duration=5.759), FetchedTranscriptSnippet(text=\"knows um so I think it's a it's an\", start=2545.2, duration=5.76), FetchedTranscriptSnippet(text='important concept to uh to have in mind', start=2548.319, duration=4.961), FetchedTranscriptSnippet(text='the second one that we saw was tool', start=2550.96, duration=4.24), FetchedTranscriptSnippet(text='calling', start=2553.28, duration=9.559), FetchedTranscriptSnippet(text='and tool calling is allowing your LLM to', start=2555.2, duration=7.639), FetchedTranscriptSnippet(text='leverage tools. The way it does that is', start=2563.119, duration=7.521), FetchedTranscriptSnippet(text='in two steps. The first step is for your', start=2567.04, duration=7.039), FetchedTranscriptSnippet(text='model to know which API there is out', start=2570.64, duration=5.84), FetchedTranscriptSnippet(text='there.', start=2574.079, duration=4.24), FetchedTranscriptSnippet(text='At the end of which your LLM says, okay,', start=2576.48, duration=4.879), FetchedTranscriptSnippet(text='I want to use this API and I want to use', start=2578.319, duration=6.641), FetchedTranscriptSnippet(text='it with these arguments.', start=2581.359, duration=5.201), FetchedTranscriptSnippet(text='And then you have an intermediary step', start=2584.96, duration=3.359), FetchedTranscriptSnippet(text='which is you just run your API with', start=2586.56, duration=4.08), FetchedTranscriptSnippet(text='these arguments.', start=2588.319, duration=6.161), FetchedTranscriptSnippet(text='And then the second step is you feed the', start=2590.64, duration=6.56), FetchedTranscriptSnippet(text='results of this operation back to the', start=2594.48, duration=7.839), FetchedTranscriptSnippet(text='LLM which then produces a final answer.', start=2597.2, duration=7.6), FetchedTranscriptSnippet(text=\"So that's how tool calling works. So if\", start=2602.319, duration=5.76), FetchedTranscriptSnippet(text='you say to your LM okay you can use this', start=2604.8, duration=6.559), FetchedTranscriptSnippet(text='use this API this is how your LM would', start=2608.079, duration=5.601), FetchedTranscriptSnippet(text='leverage that.', start=2611.359, duration=5.841), FetchedTranscriptSnippet(text='And then we saw that modern-day agentic', start=2613.68, duration=8.32), FetchedTranscriptSnippet(text='workflows were leveraging both rag and', start=2617.2, duration=9.68), FetchedTranscriptSnippet(text='tool calling as key methods to um', start=2622.0, duration=7.44), FetchedTranscriptSnippet(text='perform actions.', start=2626.88, duration=5.439), FetchedTranscriptSnippet(text='And we saw an example detail example uh', start=2629.44, duration=5.44), FetchedTranscriptSnippet(text='which was such that you had some inputs', start=2632.319, duration=6.321), FetchedTranscriptSnippet(text='and then your LLM had a series of', start=2634.88, duration=5.6), FetchedTranscriptSnippet(text='different calls', start=2638.64, duration=3.92), FetchedTranscriptSnippet(text='um in order to perform some action and', start=2640.48, duration=5.04), FetchedTranscriptSnippet(text='then at the end of it it retrieves sorry', start=2642.56, duration=6.84), FetchedTranscriptSnippet(text='it returns an answer.', start=2645.52, duration=3.88), FetchedTranscriptSnippet(text='Cool. And then last lecture', start=2650.079, duration=7.76), FetchedTranscriptSnippet(text='we saw how we could evaluate LLMs which', start=2653.44, duration=7.36), FetchedTranscriptSnippet(text='is a much tougher thing to do now that', start=2657.839, duration=7.201), FetchedTranscriptSnippet(text='LLMs can do a bunch of different things.', start=2660.8, duration=8.559), FetchedTranscriptSnippet(text='So we first saw that there were some', start=2665.04, duration=8.319), FetchedTranscriptSnippet(text='rulebased metrics that people were using', start=2669.359, duration=7.041), FetchedTranscriptSnippet(text='before LMS came into play. metrics that', start=2673.359, duration=6.72), FetchedTranscriptSnippet(text='you may have heard like blur, rouge,', start=2676.4, duration=7.919), FetchedTranscriptSnippet(text='meor and so on, but the main limitation', start=2680.079, duration=8.401), FetchedTranscriptSnippet(text='was that they were not considering how', start=2684.319, duration=6.881), FetchedTranscriptSnippet(text='language could differ but still be', start=2688.48, duration=4.639), FetchedTranscriptSnippet(text='correct.', start=2691.2, duration=5.84), FetchedTranscriptSnippet(text='And so uh this key idea that we saw was', start=2693.119, duration=7.2), FetchedTranscriptSnippet(text='why not leverage LLMs to evaluate', start=2697.04, duration=6.24), FetchedTranscriptSnippet(text='outputs. And so there is this uh key', start=2700.319, duration=8.561), FetchedTranscriptSnippet(text='idea of LLM as a judge where you receive', start=2703.28, duration=8.079), FetchedTranscriptSnippet(text='as input the prompts', start=2708.88, duration=5.199), FetchedTranscriptSnippet(text='the model response along with the', start=2711.359, duration=5.281), FetchedTranscriptSnippet(text='criteria that you want the response to', start=2714.079, duration=5.28), FetchedTranscriptSnippet(text='be evaluated on.', start=2716.64, duration=5.439), FetchedTranscriptSnippet(text='And then you want your LM messages to', start=2719.359, duration=6.0), FetchedTranscriptSnippet(text='output two things. The first one is a', start=2722.079, duration=7.76), FetchedTranscriptSnippet(text='rationale for why a given score is', start=2725.359, duration=5.76), FetchedTranscriptSnippet(text='output.', start=2729.839, duration=5.081), FetchedTranscriptSnippet(text='along with that score.', start=2731.119, duration=3.801), FetchedTranscriptSnippet(text=\"So nowadays, LM as a judges, they're\", start=2734.96, duration=5.76), FetchedTranscriptSnippet(text='typically outputting a binary response', start=2737.359, duration=5.041), FetchedTranscriptSnippet(text='either', start=2740.72, duration=3.84), FetchedTranscriptSnippet(text='uh pass or fail, true or false, just', start=2742.4, duration=5.28), FetchedTranscriptSnippet(text=\"because it's easier. And we're also\", start=2744.56, duration=7.2), FetchedTranscriptSnippet(text='having the rational be output before the', start=2747.68, duration=6.159), FetchedTranscriptSnippet(text='score', start=2751.76, duration=4.0), FetchedTranscriptSnippet(text=\"because in practice it's something that\", start=2753.839, duration=5.441), FetchedTranscriptSnippet(text='also improves the performance of uh the', start=2755.76, duration=5.68), FetchedTranscriptSnippet(text='element as a judge a little bit if you', start=2759.28, duration=4.24), FetchedTranscriptSnippet(text='want like reasoning models do by', start=2761.44, duration=3.919), FetchedTranscriptSnippet(text='outputting the reasoning chain before', start=2763.52, duration=5.72), FetchedTranscriptSnippet(text='they output the answer.', start=2765.359, duration=3.881), FetchedTranscriptSnippet(text='But then we also saw that there were uh', start=2769.52, duration=3.839), FetchedTranscriptSnippet(text='some biases that came with this', start=2771.76, duration=5.52), FetchedTranscriptSnippet(text='approach. We saw position bias which is', start=2773.359, duration=6.96), FetchedTranscriptSnippet(text='the way you present the elements to', start=2777.28, duration=5.6), FetchedTranscriptSnippet(text='compare matters. So if you present', start=2780.319, duration=4.881), FetchedTranscriptSnippet(text='something first then maybe the LLM will', start=2782.88, duration=5.439), FetchedTranscriptSnippet(text='just prioritize that first. Uh so there', start=2785.2, duration=4.96), FetchedTranscriptSnippet(text='was position bias, there was verbosity', start=2788.319, duration=4.961), FetchedTranscriptSnippet(text='bias which is your LLM just preferring', start=2790.16, duration=5.199), FetchedTranscriptSnippet(text='longer outputs.', start=2793.28, duration=4.48), FetchedTranscriptSnippet(text='Uh and self-enhancement bias was another', start=2795.359, duration=6.561), FetchedTranscriptSnippet(text='one where it prefers its own outputs.', start=2797.76, duration=6.8), FetchedTranscriptSnippet(text='Um and then we also saw a number of', start=2801.92, duration=4.32), FetchedTranscriptSnippet(text='benchmarks', start=2804.56, duration=5.279), FetchedTranscriptSnippet(text='uh that people use nowadays in order to', start=2806.24, duration=6.48), FetchedTranscriptSnippet(text='say how great their LLM is. So if you', start=2809.839, duration=6.161), FetchedTranscriptSnippet(text='see the releases that come out, there', start=2812.72, duration=5.76), FetchedTranscriptSnippet(text='are typically a bunch of metrics across', start=2816.0, duration=4.72), FetchedTranscriptSnippet(text='a number of different benchmarks that', start=2818.48, duration=5.599), FetchedTranscriptSnippet(text='people know about. So that spans uh', start=2820.72, duration=7.2), FetchedTranscriptSnippet(text='knowledge, the ability to reason, coding', start=2824.079, duration=5.52), FetchedTranscriptSnippet(text='which is very important because a lot of', start=2827.92, duration=4.96), FetchedTranscriptSnippet(text='applications are coding related', start=2829.599, duration=5.76), FetchedTranscriptSnippet(text='and then safety and then this is not an', start=2832.88, duration=4.0), FetchedTranscriptSnippet(text='an', start=2835.359, duration=4.0), FetchedTranscriptSnippet(text=\"extensive list so there's actually many\", start=2836.88, duration=4.4), FetchedTranscriptSnippet(text='more dimensions.', start=2839.359, duration=4.641), FetchedTranscriptSnippet(text='Um', start=2841.28, duration=5.52), FetchedTranscriptSnippet(text=\"so yeah I think that's where we stopped\", start=2844.0, duration=6.16), FetchedTranscriptSnippet(text='and it was last lecture', start=2846.8, duration=7.84), FetchedTranscriptSnippet(text='and this is all you are expected to know', start=2850.16, duration=7.439), FetchedTranscriptSnippet(text='for the final.', start=2854.64, duration=6.16), FetchedTranscriptSnippet(text='Everything after that is not going to be', start=2857.599, duration=6.601), FetchedTranscriptSnippet(text='part of the final.', start=2860.8, duration=3.4), FetchedTranscriptSnippet(text='Any questions', start=2864.8, duration=6.36), FetchedTranscriptSnippet(text='on this so far?', start=2867.44, duration=3.72), FetchedTranscriptSnippet(text=\"Cool. Okay. I'm expecting a hundreds for\", start=2874.64, duration=8.24), FetchedTranscriptSnippet(text='everyone for the final. But yeah, um', start=2877.04, duration=9.12), FetchedTranscriptSnippet(text='I would say what I went through', start=2882.88, duration=5.439), FetchedTranscriptSnippet(text='is going to be foundational for the', start=2886.16, duration=4.959), FetchedTranscriptSnippet(text='final. So I guess if you understood', start=2888.319, duration=5.361), FetchedTranscriptSnippet(text='everything I said,', start=2891.119, duration=4.96), FetchedTranscriptSnippet(text=\"I think you're going to be ready for the\", start=2893.68, duration=5.6), FetchedTranscriptSnippet(text='final. So um yeah, but if you have any', start=2896.079, duration=4.481), FetchedTranscriptSnippet(text='questions, you know, Shervin and I are', start=2899.28, duration=4.4), FetchedTranscriptSnippet(text='always here um to uh Oh, yeah. You have', start=2900.56, duration=6.279), FetchedTranscriptSnippet(text='a question?', start=2903.68, duration=3.159), FetchedTranscriptSnippet(text='Yes. So the question is, is the scope', start=2909.359, duration=4.48), FetchedTranscriptSnippet(text='for the final of lecture 5 to lecture 8?', start=2911.2, duration=6.159), FetchedTranscriptSnippet(text='Yes. So for midterm it was lectures 1 2', start=2913.839, duration=6.48), FetchedTranscriptSnippet(text='3 4 and this one is 5 6 7 8. So I guess', start=2917.359, duration=8.041), FetchedTranscriptSnippet(text=\"it's u equal equal size.\", start=2920.319, duration=5.081), FetchedTranscriptSnippet(text='Cool.', start=2925.92, duration=6.32), FetchedTranscriptSnippet(text='Okay, great. So, with that said, we just', start=2927.92, duration=7.6), FetchedTranscriptSnippet(text='finished recapping this entire quarter', start=2932.24, duration=6.079), FetchedTranscriptSnippet(text=\"worth of lectures and now we're going to\", start=2935.52, duration=6.0), FetchedTranscriptSnippet(text=\"go to the second item of today's menu,\", start=2938.319, duration=6.161), FetchedTranscriptSnippet(text='which is looking at some trending', start=2941.52, duration=5.36), FetchedTranscriptSnippet(text='topics.', start=2944.48, duration=3.68), FetchedTranscriptSnippet(text=\"And so, I'm going to start with the\", start=2946.88, duration=3.92), FetchedTranscriptSnippet(text='first one.', start=2948.16, duration=4.32), FetchedTranscriptSnippet(text=\"And I'm going to introduce it as\", start=2950.8, duration=3.519), FetchedTranscriptSnippet(text='follows.', start=2952.48, duration=4.48), FetchedTranscriptSnippet(text='So if you remember we saw that the', start=2954.319, duration=4.161), FetchedTranscriptSnippet(text='transformer', start=2956.96, duration=4.56), FetchedTranscriptSnippet(text='was a concept and an architecture that', start=2958.48, duration=5.839), FetchedTranscriptSnippet(text='was first introduced in the context of', start=2961.52, duration=5.2), FetchedTranscriptSnippet(text='machine translation.', start=2964.319, duration=5.52), FetchedTranscriptSnippet(text='So it performed great. People said okay', start=2966.72, duration=4.96), FetchedTranscriptSnippet(text='it performs great on machine translation', start=2969.839, duration=6.081), FetchedTranscriptSnippet(text='why not try it on other text tasks. So', start=2971.68, duration=6.96), FetchedTranscriptSnippet(text='they tried it performs great', start=2975.92, duration=5.84), FetchedTranscriptSnippet(text='but now the question is can you not use', start=2978.64, duration=7.28), FetchedTranscriptSnippet(text='it for things other than text', start=2981.76, duration=8.48), FetchedTranscriptSnippet(text=\"it's a natural question right so in\", start=2985.92, duration=6.56), FetchedTranscriptSnippet(text='order to answer that question I just', start=2990.24, duration=5.359), FetchedTranscriptSnippet(text='want us to remind ourselves that this', start=2992.48, duration=6.079), FetchedTranscriptSnippet(text='architecture is relying on this concept', start=2995.599, duration=6.24), FetchedTranscriptSnippet(text='of self attention', start=2998.559, duration=5.52), FetchedTranscriptSnippet(text='and this is what is making the', start=3001.839, duration=5.601), FetchedTranscriptSnippet(text='transformer work so Well,', start=3004.079, duration=7.921), FetchedTranscriptSnippet(text='so if we just recap what self attention', start=3007.44, duration=8.0), FetchedTranscriptSnippet(text='is, this uh illustration kind of does', start=3012.0, duration=6.24), FetchedTranscriptSnippet(text='the job quite well.', start=3015.44, duration=5.679), FetchedTranscriptSnippet(text='You have a query and then you have a', start=3018.24, duration=5.28), FetchedTranscriptSnippet(text='bunch of other elements which are', start=3021.119, duration=5.361), FetchedTranscriptSnippet(text='represented by your keys and your values', start=3023.52, duration=5.28), FetchedTranscriptSnippet(text='and you want to know which other', start=3026.48, duration=6.4), FetchedTranscriptSnippet(text='elements are actually relevant', start=3028.8, duration=5.759), FetchedTranscriptSnippet(text='in order to compute the embedding for', start=3032.88, duration=4.959), FetchedTranscriptSnippet(text='that query.', start=3034.559, duration=6.721), FetchedTranscriptSnippet(text='So right now we have only used tokens', start=3037.839, duration=5.76), FetchedTranscriptSnippet(text='you know text tokens', start=3041.28, duration=5.2), FetchedTranscriptSnippet(text='but text tokens', start=3043.599, duration=6.641), FetchedTranscriptSnippet(text=\"they're actually vectors.\", start=3046.48, duration=7.839), FetchedTranscriptSnippet(text='So if you take those vectors', start=3050.24, duration=6.0), FetchedTranscriptSnippet(text='and you actually represent something', start=3054.319, duration=4.401), FetchedTranscriptSnippet(text='else than text', start=3056.24, duration=5.92), FetchedTranscriptSnippet(text='like for instance parts of an image.', start=3058.72, duration=8.879), FetchedTranscriptSnippet(text='The question is would the transformer', start=3062.16, duration=8.8), FetchedTranscriptSnippet(text='based on that kind of input also perform', start=3067.599, duration=6.361), FetchedTranscriptSnippet(text='well.', start=3070.96, duration=3.0), FetchedTranscriptSnippet(text='And so here the key question that I want', start=3074.64, duration=7.36), FetchedTranscriptSnippet(text='to ask is how can we adapt our', start=3078.319, duration=5.201), FetchedTranscriptSnippet(text='transformer', start=3082.0, duration=5.599), FetchedTranscriptSnippet(text='to work on non-ext input and for', start=3083.52, duration=6.079), FetchedTranscriptSnippet(text='instance here we can think of image', start=3087.599, duration=3.921), FetchedTranscriptSnippet(text='understanding input. So you have some', start=3089.599, duration=5.601), FetchedTranscriptSnippet(text=\"image and so it's a traditional um\", start=3091.52, duration=6.319), FetchedTranscriptSnippet(text='computer vision task where you want to', start=3095.2, duration=4.639), FetchedTranscriptSnippet(text='know in which class this image belongs', start=3097.839, duration=3.601), FetchedTranscriptSnippet(text='to.', start=3099.839, duration=4.0), FetchedTranscriptSnippet(text='So you want to know if', start=3101.44, duration=4.48), FetchedTranscriptSnippet(text='having some transformer-based', start=3103.839, duration=3.681), FetchedTranscriptSnippet(text='architecture would work well in that', start=3105.92, duration=3.679), FetchedTranscriptSnippet(text='situation.', start=3107.52, duration=6.16), FetchedTranscriptSnippet(text='Well, the answer to that is well, first', start=3109.599, duration=7.201), FetchedTranscriptSnippet(text='in order to adapt it to this task,', start=3113.68, duration=6.24), FetchedTranscriptSnippet(text='you would take', start=3116.8, duration=6.319), FetchedTranscriptSnippet(text='the encoder part of the transformer', start=3119.92, duration=6.0), FetchedTranscriptSnippet(text='because in order to understand what is', start=3123.119, duration=5.921), FetchedTranscriptSnippet(text='in an image, you need to classify that', start=3125.92, duration=5.36), FetchedTranscriptSnippet(text='image in some sense.', start=3129.04, duration=5.44), FetchedTranscriptSnippet(text=\"So if you remember if there's one model\", start=3131.28, duration=5.12), FetchedTranscriptSnippet(text='in what we saw that was working very', start=3134.48, duration=4.4), FetchedTranscriptSnippet(text='well for classification', start=3136.4, duration=6.56), FetchedTranscriptSnippet(text='was BERT because BERT is encoder only.', start=3138.88, duration=7.84), FetchedTranscriptSnippet(text='It computes meaningful embeddings that', start=3142.96, duration=7.2), FetchedTranscriptSnippet(text='can then be used for projection purposes', start=3146.72, duration=6.96), FetchedTranscriptSnippet(text='or for classification purposes.', start=3150.16, duration=6.48), FetchedTranscriptSnippet(text=\"So it's a very natural choice that here\", start=3153.68, duration=5.36), FetchedTranscriptSnippet(text='we would have. So here we would just', start=3156.64, duration=5.12), FetchedTranscriptSnippet(text='keep the encoder part of the transformer', start=3159.04, duration=4.559), FetchedTranscriptSnippet(text='and then', start=3161.76, duration=4.319), FetchedTranscriptSnippet(text='have the self attention mechanism come', start=3163.599, duration=7.041), FetchedTranscriptSnippet(text='into play and um compute meaningful', start=3166.079, duration=7.76), FetchedTranscriptSnippet(text='embeddings that we could then project', start=3170.64, duration=6.16), FetchedTranscriptSnippet(text='for our relevant task. And this is', start=3173.839, duration=6.24), FetchedTranscriptSnippet(text='exactly what a group of researchers did', start=3176.8, duration=5.6), FetchedTranscriptSnippet(text='back in 2020.', start=3180.079, duration=4.561), FetchedTranscriptSnippet(text='So have you heard of VIT vision', start=3182.4, duration=4.959), FetchedTranscriptSnippet(text='transformer?', start=3184.64, duration=6.16), FetchedTranscriptSnippet(text='Yeah. No. Yeah. So what I described here', start=3187.359, duration=6.081), FetchedTranscriptSnippet(text='is exactly what they did.', start=3190.8, duration=5.519), FetchedTranscriptSnippet(text='So they took an image,', start=3193.44, duration=8.0), FetchedTranscriptSnippet(text='they divided that image into patches.', start=3196.319, duration=7.52), FetchedTranscriptSnippet(text='Those patches', start=3201.44, duration=5.6), FetchedTranscriptSnippet(text='were represented by some vectors.', start=3203.839, duration=5.601), FetchedTranscriptSnippet(text='And of course you have some some kind of', start=3207.04, duration=4.4), FetchedTranscriptSnippet(text='position information that allows you to', start=3209.44, duration=4.72), FetchedTranscriptSnippet(text='know where your your patch is in the', start=3211.44, duration=4.639), FetchedTranscriptSnippet(text='image.', start=3214.16, duration=3.439), FetchedTranscriptSnippet(text='And then you just put it through the', start=3216.079, duration=3.681), FetchedTranscriptSnippet(text='transformer encoder. So the encoder part', start=3217.599, duration=4.081), FetchedTranscriptSnippet(text='of the transformer', start=3219.76, duration=4.88), FetchedTranscriptSnippet(text='and you compute the representation', start=3221.68, duration=5.919), FetchedTranscriptSnippet(text='corresponding to the CLS class very', start=3224.64, duration=5.76), FetchedTranscriptSnippet(text='similar to birds and you would just', start=3227.599, duration=5.361), FetchedTranscriptSnippet(text='project that representation', start=3230.4, duration=7.04), FetchedTranscriptSnippet(text='over some classes of interest', start=3232.96, duration=8.879), FetchedTranscriptSnippet(text='and then you would perform your um your', start=3237.44, duration=7.36), FetchedTranscriptSnippet(text='uh I guess computation uh like this. So', start=3241.839, duration=7.28), FetchedTranscriptSnippet(text='what that paper found was that if you', start=3244.8, duration=8.319), FetchedTranscriptSnippet(text='train such a model on a lot of image', start=3249.119, duration=7.041), FetchedTranscriptSnippet(text='data on a lot of image data you then', start=3253.119, duration=5.681), FetchedTranscriptSnippet(text='outperform these traditional', start=3256.16, duration=4.88), FetchedTranscriptSnippet(text='convolutional neural network kind of', start=3258.8, duration=4.48), FetchedTranscriptSnippet(text='methods.', start=3261.04, duration=5.039), FetchedTranscriptSnippet(text='And so those kind of', start=3263.28, duration=4.799), FetchedTranscriptSnippet(text='uh remarkable', start=3266.079, duration=4.721), FetchedTranscriptSnippet(text='because so why is it remarkable? Because', start=3268.079, duration=5.361), FetchedTranscriptSnippet(text='in the vision case,', start=3270.8, duration=5.36), FetchedTranscriptSnippet(text='so there is this concept of inductive', start=3273.44, duration=7.919), FetchedTranscriptSnippet(text='bias where you want to gear your model', start=3276.16, duration=6.72), FetchedTranscriptSnippet(text='towards', start=3281.359, duration=4.96), FetchedTranscriptSnippet(text='looking at certain things in order to to', start=3282.88, duration=6.08), FetchedTranscriptSnippet(text='deduce the results.', start=3286.319, duration=5.76), FetchedTranscriptSnippet(text='So convolutional neural networks', start=3288.96, duration=7.52), FetchedTranscriptSnippet(text='are a kind of model that are designed in', start=3292.079, duration=7.681), FetchedTranscriptSnippet(text='a way for you to look at the image', start=3296.48, duration=6.0), FetchedTranscriptSnippet(text='in some you know sliding way. You know', start=3299.76, duration=4.48), FetchedTranscriptSnippet(text='you look at your image a little bit like', start=3302.48, duration=3.92), FetchedTranscriptSnippet(text='you would look at it in practice as a', start=3304.24, duration=4.56), FetchedTranscriptSnippet(text='human.', start=3306.4, duration=6.0), FetchedTranscriptSnippet(text='And people had hypothesized that such', start=3308.8, duration=6.08), FetchedTranscriptSnippet(text='such a bias such an indictive bias would', start=3312.4, duration=4.8), FetchedTranscriptSnippet(text='actually make sense for something like a', start=3314.88, duration=4.239), FetchedTranscriptSnippet(text='vision task.', start=3317.2, duration=3.84), FetchedTranscriptSnippet(text='So you contrast that with the vision', start=3319.119, duration=3.601), FetchedTranscriptSnippet(text='transformer', start=3321.04, duration=4.72), FetchedTranscriptSnippet(text='which is actually letting all parts of', start=3322.72, duration=6.96), FetchedTranscriptSnippet(text='the image attend to one another which', start=3325.76, duration=6.4), FetchedTranscriptSnippet(text='has on the other side very low inductive', start=3329.68, duration=6.399), FetchedTranscriptSnippet(text='bias. So what this paper showed was if', start=3332.16, duration=8.64), FetchedTranscriptSnippet(text='you give your model enough data', start=3336.079, duration=7.04), FetchedTranscriptSnippet(text='then it will actually learn how to', start=3340.8, duration=4.4), FetchedTranscriptSnippet(text='classify', start=3343.119, duration=3.921), FetchedTranscriptSnippet(text='um I guess your images in this in this', start=3345.2, duration=3.599), FetchedTranscriptSnippet(text='classes. So this was like kind of a', start=3347.04, duration=4.0), FetchedTranscriptSnippet(text='remarkable results.', start=3348.799, duration=4.161), FetchedTranscriptSnippet(text='Um so I think this is like pretty', start=3351.04, duration=3.84), FetchedTranscriptSnippet(text='remarkable and a nice extension of', start=3352.96, duration=4.159), FetchedTranscriptSnippet(text='everything we saw.', start=3354.88, duration=4.719), FetchedTranscriptSnippet(text='So with that in mind,', start=3357.119, duration=5.44), FetchedTranscriptSnippet(text='um I want us to just go through an end', start=3359.599, duration=6.881), FetchedTranscriptSnippet(text='toend example of how you would process', start=3362.559, duration=8.8), FetchedTranscriptSnippet(text='an image and go through that um vit so', start=3366.48, duration=7.44), FetchedTranscriptSnippet(text='vision transformer in order to make your', start=3371.359, duration=6.081), FetchedTranscriptSnippet(text='um prediction. So here you would take uh', start=3373.92, duration=5.84), FetchedTranscriptSnippet(text='like your favorite image that you would', start=3377.44, duration=5.359), FetchedTranscriptSnippet(text='just split into patches. So here you can', start=3379.76, duration=7.359), FetchedTranscriptSnippet(text='think of you predefining some uh fixed', start=3382.799, duration=6.721), FetchedTranscriptSnippet(text='size patches.', start=3387.119, duration=4.561), FetchedTranscriptSnippet(text=\"So here I would say like 3x3 let's say\", start=3389.52, duration=5.2), FetchedTranscriptSnippet(text='and then each patch has some um fixed', start=3391.68, duration=5.679), FetchedTranscriptSnippet(text='number of pixels', start=3394.72, duration=6.079), FetchedTranscriptSnippet(text='and then what you do is for each patch', start=3397.359, duration=6.321), FetchedTranscriptSnippet(text='you try to have some vector', start=3400.799, duration=4.961), FetchedTranscriptSnippet(text='representation.', start=3403.68, duration=6.24), FetchedTranscriptSnippet(text='So you can think of each patch as so', start=3405.76, duration=5.76), FetchedTranscriptSnippet(text=\"what is a patch? So it's composed of\", start=3409.92, duration=3.36), FetchedTranscriptSnippet(text='pixels.', start=3411.52, duration=5.36), FetchedTranscriptSnippet(text='So if each pixel has three values which', start=3413.28, duration=6.72), FetchedTranscriptSnippet(text='correspond to red, green and blue, then', start=3416.88, duration=5.6), FetchedTranscriptSnippet(text='you can find', start=3420.0, duration=5.839), FetchedTranscriptSnippet(text='a way to project those on some lower', start=3422.48, duration=6.48), FetchedTranscriptSnippet(text='dimensional flattened space', start=3425.839, duration=5.361), FetchedTranscriptSnippet(text='and you can learn how you would project', start=3428.96, duration=6.0), FetchedTranscriptSnippet(text='that through some kind of linear layer.', start=3431.2, duration=6.0), FetchedTranscriptSnippet(text='So', start=3434.96, duration=6.8), FetchedTranscriptSnippet(text='long story short, you just find a way to', start=3437.2, duration=6.48), FetchedTranscriptSnippet(text='associate a vector to each of these', start=3441.76, duration=3.92), FetchedTranscriptSnippet(text='patches', start=3443.68, duration=5.919), FetchedTranscriptSnippet(text='which you you then represent', start=3445.68, duration=6.32), FetchedTranscriptSnippet(text='every single one of your inputs. And', start=3449.599, duration=4.401), FetchedTranscriptSnippet(text='then you have of course a special', start=3452.0, duration=4.16), FetchedTranscriptSnippet(text='embedding for the CLS token which you', start=3454.0, duration=4.48), FetchedTranscriptSnippet(text='can also learn.', start=3456.16, duration=6.399), FetchedTranscriptSnippet(text='And you add the position embedding.', start=3458.48, duration=5.839), FetchedTranscriptSnippet(text='So you do the same for all of your', start=3462.559, duration=5.841), FetchedTranscriptSnippet(text='inputs and then very similar to birds', start=3464.319, duration=6.641), FetchedTranscriptSnippet(text='just put that through your encoder. Let', start=3468.4, duration=5.76), FetchedTranscriptSnippet(text='everyone interact with everyone', start=3470.96, duration=5.76), FetchedTranscriptSnippet(text='and then at the end of the day what you', start=3474.16, duration=5.84), FetchedTranscriptSnippet(text='care about is a representation of the', start=3476.72, duration=6.0), FetchedTranscriptSnippet(text='input that is meaningful. So typically', start=3480.0, duration=5.92), FetchedTranscriptSnippet(text='people take the encoded embedding of the', start=3482.72, duration=6.16), FetchedTranscriptSnippet(text='CLS token. So the reason why they take', start=3485.92, duration=5.28), FetchedTranscriptSnippet(text=\"that is one because it's a convention\", start=3488.88, duration=6.959), FetchedTranscriptSnippet(text='but second one is this CLS token. So the', start=3491.2, duration=6.639), FetchedTranscriptSnippet(text='encoded embedding', start=3495.839, duration=3.921), FetchedTranscriptSnippet(text='is actually', start=3497.839, duration=4.641), FetchedTranscriptSnippet(text='an embedding that has interacted with', start=3499.76, duration=5.599), FetchedTranscriptSnippet(text='all other tokens through this self', start=3502.48, duration=5.04), FetchedTranscriptSnippet(text='attention mechanism.', start=3505.359, duration=4.641), FetchedTranscriptSnippet(text='So it has seen everything', start=3507.52, duration=6.96), FetchedTranscriptSnippet(text='and then you would project that CLS', start=3510.0, duration=7.839), FetchedTranscriptSnippet(text='token encoded embedding onto some class', start=3514.48, duration=6.16), FetchedTranscriptSnippet(text='through a feed for neural network in', start=3517.839, duration=7.361), FetchedTranscriptSnippet(text='order to predict your final class.', start=3520.64, duration=6.479), FetchedTranscriptSnippet(text=\"So in this case we know it's a picture\", start=3525.2, duration=4.08), FetchedTranscriptSnippet(text='of a teddy bear. So here we would want', start=3527.119, duration=4.24), FetchedTranscriptSnippet(text='the model to classify this as a teddy', start=3529.28, duration=5.079), FetchedTranscriptSnippet(text='bear.', start=3531.359, duration=3.0), FetchedTranscriptSnippet(text='So far so good. Does that make sense?', start=3534.4, duration=5.399), FetchedTranscriptSnippet(text='Cool. Uh, so now, okay, we know how to', start=3540.88, duration=5.36), FetchedTranscriptSnippet(text='process', start=3544.4, duration=5.919), FetchedTranscriptSnippet(text='image input, right? Now, so another', start=3546.24, duration=10.92), FetchedTranscriptSnippet(text='question is how would you have your LLM', start=3550.319, duration=6.841), FetchedTranscriptSnippet(text='answer questions about your image, which', start=3557.2, duration=3.84), FetchedTranscriptSnippet(text='is something that you can do actually', start=3559.92, duration=3.52), FetchedTranscriptSnippet(text='nowadays. Like if you open chat GPT you', start=3561.04, duration=7.519), FetchedTranscriptSnippet(text='can input an image and ask it questions.', start=3563.44, duration=7.359), FetchedTranscriptSnippet(text='So', start=3568.559, duration=4.321), FetchedTranscriptSnippet(text='you would have two kinds of inputs. So', start=3570.799, duration=4.8), FetchedTranscriptSnippet(text='you would have an image which we saw we', start=3572.88, duration=5.199), FetchedTranscriptSnippet(text='can find a way to represent', start=3575.599, duration=5.601), FetchedTranscriptSnippet(text='and then the text which you now know', start=3578.079, duration=4.72), FetchedTranscriptSnippet(text='very well how to represent like with', start=3581.2, duration=3.76), FetchedTranscriptSnippet(text='tokens.', start=3582.799, duration=5.361), FetchedTranscriptSnippet(text='So the way you would', start=3584.96, duration=6.8), FetchedTranscriptSnippet(text='allow the model or let the model', start=3588.16, duration=6.0), FetchedTranscriptSnippet(text='process. All of this', start=3591.76, duration=4.0), FetchedTranscriptSnippet(text='is typically as follows. So there are', start=3594.16, duration=3.28), FetchedTranscriptSnippet(text='like a couple of methods. The first one', start=3595.76, duration=4.559), FetchedTranscriptSnippet(text='is the more most common one which is you', start=3597.44, duration=5.84), FetchedTranscriptSnippet(text='just feed everything as input.', start=3600.319, duration=6.321), FetchedTranscriptSnippet(text='So the image token as input, the um text', start=3603.28, duration=6.559), FetchedTranscriptSnippet(text='tokens as input and you have some', start=3606.64, duration=6.08), FetchedTranscriptSnippet(text='representation to have the model just', start=3609.839, duration=4.48), FetchedTranscriptSnippet(text='know that these are image tokens and', start=3612.72, duration=5.119), FetchedTranscriptSnippet(text='this is like text token and then you let', start=3614.319, duration=8.081), FetchedTranscriptSnippet(text='it generate an answer in a decoder only', start=3617.839, duration=6.321), FetchedTranscriptSnippet(text='fashion, auto reggressive fashion', start=3622.4, duration=5.04), FetchedTranscriptSnippet(text='exactly like you would do it', start=3624.16, duration=5.84), FetchedTranscriptSnippet(text='the first method and a lot of such', start=3627.44, duration=6.56), FetchedTranscriptSnippet(text='models are designed that way. So there', start=3630.0, duration=7.92), FetchedTranscriptSnippet(text='is for instance a very popular uh open', start=3634.0, duration=7.119), FetchedTranscriptSnippet(text='weight I believe um vision language', start=3637.92, duration=6.0), FetchedTranscriptSnippet(text=\"model VLM that's what they are called uh\", start=3641.119, duration=5.121), FetchedTranscriptSnippet(text='model called lava', start=3643.92, duration=4.879), FetchedTranscriptSnippet(text='and this is how they do it. So they have', start=3646.24, duration=5.359), FetchedTranscriptSnippet(text='some encoder on the image parts uh that', start=3648.799, duration=6.56), FetchedTranscriptSnippet(text='produces some tokens that are then uh', start=3651.599, duration=5.681), FetchedTranscriptSnippet(text='concatenated with text tokens that are', start=3655.359, duration=5.2), FetchedTranscriptSnippet(text='input into the LLM.', start=3657.28, duration=6.24), FetchedTranscriptSnippet(text=\"So that's one method.\", start=3660.559, duration=5.601), FetchedTranscriptSnippet(text='The second method which is less common', start=3663.52, duration=7.599), FetchedTranscriptSnippet(text='is to have the images be input at the', start=3666.16, duration=9.28), FetchedTranscriptSnippet(text='cross attention layer.', start=3671.119, duration=6.561), FetchedTranscriptSnippet(text='So here what you would do is you have', start=3675.44, duration=4.48), FetchedTranscriptSnippet(text='your text input', start=3677.68, duration=4.879), FetchedTranscriptSnippet(text=\"and then your image input. You don't put\", start=3679.92, duration=5.439), FetchedTranscriptSnippet(text='it in the input. You actually let it', start=3682.559, duration=5.841), FetchedTranscriptSnippet(text='interact with the text tokens within the', start=3685.359, duration=6.401), FetchedTranscriptSnippet(text='cross attention layer.', start=3688.4, duration=3.36), FetchedTranscriptSnippet(text='And this is something that for instance', start=3691.839, duration=6.72), FetchedTranscriptSnippet(text='llama 3 had represented in their paper.', start=3693.92, duration=6.56), FetchedTranscriptSnippet(text='This technique is typically less common.', start=3698.559, duration=6.641), FetchedTranscriptSnippet(text='The first one is more common.', start=3700.48, duration=10.72), FetchedTranscriptSnippet(text='So I guess what I want to say is CME 295', start=3705.2, duration=8.48), FetchedTranscriptSnippet(text='focused on the transformer specifically', start=3711.2, duration=4.8), FetchedTranscriptSnippet(text='in the case of', start=3713.68, duration=5.439), FetchedTranscriptSnippet(text='texttoext problems. So text generation', start=3716.0, duration=6.48), FetchedTranscriptSnippet(text='is all you know this class', start=3719.119, duration=6.641), FetchedTranscriptSnippet(text='but we also have the transformer that', start=3722.48, duration=6.639), FetchedTranscriptSnippet(text='was used for non-ext applications. So', start=3725.76, duration=5.599), FetchedTranscriptSnippet(text='here we saw image understanding so', start=3729.119, duration=5.44), FetchedTranscriptSnippet(text='vision understanding with the vit and', start=3731.359, duration=6.641), FetchedTranscriptSnippet(text='then uh we will not have the time to say', start=3734.559, duration=6.881), FetchedTranscriptSnippet(text='this now but also for image generation', start=3738.0, duration=7.359), FetchedTranscriptSnippet(text='tasks we can also have parts of the', start=3741.44, duration=8.0), FetchedTranscriptSnippet(text='transformer be used in that architecture', start=3745.359, duration=7.041), FetchedTranscriptSnippet(text='and so you may uh you know hear about', start=3749.44, duration=6.56), FetchedTranscriptSnippet(text='diffusion transformer or multimodel', start=3752.4, duration=5.36), FetchedTranscriptSnippet(text=\"diffusion transformer that's actually\", start=3756.0, duration=5.119), FetchedTranscriptSnippet(text='rely on the self attention mechanism', start=3757.76, duration=5.92), FetchedTranscriptSnippet(text='and um this is actually not an', start=3761.119, duration=4.96), FetchedTranscriptSnippet(text='exhaustive list. This is also something', start=3763.68, duration=5.52), FetchedTranscriptSnippet(text='that has been used in other uh domains', start=3766.079, duration=8.0), FetchedTranscriptSnippet(text='like recommendations, speech and so on.', start=3769.2, duration=7.599), FetchedTranscriptSnippet(text='So I guess I what I want you to remember', start=3774.079, duration=7.201), FetchedTranscriptSnippet(text='from this is that transformers', start=3776.799, duration=7.921), FetchedTranscriptSnippet(text='were like was an architecture that', start=3781.28, duration=5.68), FetchedTranscriptSnippet(text='performed very well for machine', start=3784.72, duration=4.32), FetchedTranscriptSnippet(text='translation tasks', start=3786.96, duration=6.24), FetchedTranscriptSnippet(text='but then it proved to perform very well', start=3789.04, duration=7.12), FetchedTranscriptSnippet(text='for other text related tasks', start=3793.2, duration=5.2), FetchedTranscriptSnippet(text='and it was then reused in a bunch of', start=3796.16, duration=4.959), FetchedTranscriptSnippet(text='other domains which also proved to be', start=3798.4, duration=5.04), FetchedTranscriptSnippet(text='quite successful. So I would just', start=3801.119, duration=4.72), FetchedTranscriptSnippet(text='encourage you after this class to also', start=3803.44, duration=6.72), FetchedTranscriptSnippet(text='keep an open mind for non-ext related', start=3805.839, duration=7.041), FetchedTranscriptSnippet(text='transformer applications and the ones', start=3810.16, duration=5.28), FetchedTranscriptSnippet(text='that I mentioned here are maybe just a', start=3812.88, duration=5.36), FetchedTranscriptSnippet(text='few first few pointers into the kind of', start=3815.44, duration=6.48), FetchedTranscriptSnippet(text='papers that you can look at.', start=3818.24, duration=7.119), FetchedTranscriptSnippet(text='Cool. So here we said that transformer', start=3821.92, duration=6.399), FetchedTranscriptSnippet(text='was something that came from the text', start=3825.359, duration=6.161), FetchedTranscriptSnippet(text=\"world that's also uh useful and used in\", start=3828.319, duration=5.201), FetchedTranscriptSnippet(text='other worlds.', start=3831.52, duration=4.079), FetchedTranscriptSnippet(text='Now I want to tell you about something', start=3833.52, duration=7.599), FetchedTranscriptSnippet(text='else that was uh I guess used and useful', start=3835.599, duration=9.121), FetchedTranscriptSnippet(text='in the non-ext world that may be useful', start=3841.119, duration=5.841), FetchedTranscriptSnippet(text='in the text world', start=3844.72, duration=3.68), FetchedTranscriptSnippet(text='and I want to tell you about', start=3846.96, duration=4.879), FetchedTranscriptSnippet(text='diffusionbased LLMs.', start=3848.4, duration=7.199), FetchedTranscriptSnippet(text='So who has heard the term diffusion?', start=3851.839, duration=6.561), FetchedTranscriptSnippet(text='Who knows about diffusion?', start=3855.599, duration=4.48), FetchedTranscriptSnippet(text='Yeah,', start=3858.4, duration=3.6), FetchedTranscriptSnippet(text='cool. So we will see how we can apply', start=3860.079, duration=4.641), FetchedTranscriptSnippet(text='that to LLM. So this is a very trendy', start=3862.0, duration=5.599), FetchedTranscriptSnippet(text='topic. I believe the first paper started', start=3864.72, duration=6.16), FetchedTranscriptSnippet(text=\"in the early 2020s, but I guess it's\", start=3867.599, duration=6.641), FetchedTranscriptSnippet(text='only now that people are starting to', start=3870.88, duration=7.04), FetchedTranscriptSnippet(text='have this really work.', start=3874.24, duration=6.079), FetchedTranscriptSnippet(text='I just want to start with a motivation', start=3877.92, duration=6.399), FetchedTranscriptSnippet(text='which is that up until now we have taken', start=3880.319, duration=8.161), FetchedTranscriptSnippet(text='for granted the fact that our LLM is an', start=3884.319, duration=7.04), FetchedTranscriptSnippet(text='auto reggressive LLM and by auto', start=3888.48, duration=5.92), FetchedTranscriptSnippet(text='reggressive what do I mean by that?', start=3891.359, duration=6.72), FetchedTranscriptSnippet(text='So it takes some input', start=3894.4, duration=6.8), FetchedTranscriptSnippet(text='and what the LLM tries to do is to', start=3898.079, duration=6.561), FetchedTranscriptSnippet(text='predict the next token. So given', start=3901.2, duration=5.919), FetchedTranscriptSnippet(text='everything so far, we predict the next', start=3904.64, duration=4.32), FetchedTranscriptSnippet(text='token.', start=3907.119, duration=5.2), FetchedTranscriptSnippet(text='We do that and then we take that token', start=3908.96, duration=5.04), FetchedTranscriptSnippet(text='that we just predicted along with', start=3912.319, duration=5.361), FetchedTranscriptSnippet(text='everything that we have predicted so far', start=3914.0, duration=6.079), FetchedTranscriptSnippet(text='and then we again', start=3917.68, duration=5.04), FetchedTranscriptSnippet(text='predict the next token.', start=3920.079, duration=6.401), FetchedTranscriptSnippet(text='We predict it and we go again and again', start=3922.72, duration=5.92), FetchedTranscriptSnippet(text='up until you know finishing the sequence', start=3926.48, duration=5.2), FetchedTranscriptSnippet(text='with that end of sequence token which', start=3928.64, duration=5.04), FetchedTranscriptSnippet(text='makes the generation stop.', start=3931.68, duration=4.399), FetchedTranscriptSnippet(text='So this is a true auto reggressive', start=3933.68, duration=6.0), FetchedTranscriptSnippet(text='generation as in we take the input so', start=3936.079, duration=7.441), FetchedTranscriptSnippet(text='far in order to predict the next token', start=3939.68, duration=6.8), FetchedTranscriptSnippet(text='and then we repeat this process until', start=3943.52, duration=6.12), FetchedTranscriptSnippet(text='the end.', start=3946.48, duration=3.16), FetchedTranscriptSnippet(text=\"So it's something that people now try to\", start=3950.0, duration=7.2), FetchedTranscriptSnippet(text='kind of give it a name which is like', start=3955.44, duration=3.919), FetchedTranscriptSnippet(text='auto reggressive model kind of model.', start=3957.2, duration=5.359), FetchedTranscriptSnippet(text='So, ARM, if you kind of see this', start=3959.359, duration=7.601), FetchedTranscriptSnippet(text=\"notation, that's what it means. Um, the\", start=3962.559, duration=7.361), FetchedTranscriptSnippet(text='problem with that kind of paradigm is', start=3966.96, duration=6.079), FetchedTranscriptSnippet(text='that inference time generation', start=3969.92, duration=5.04), FetchedTranscriptSnippet(text='is actually not something you can', start=3973.039, duration=3.76), FetchedTranscriptSnippet(text='parallelize', start=3974.96, duration=5.44), FetchedTranscriptSnippet(text=\"because you always need what's before in\", start=3976.799, duration=7.641), FetchedTranscriptSnippet(text='order to predict the next one.', start=3980.4, duration=4.04), FetchedTranscriptSnippet(text='But I just want to say that inference', start=3984.559, duration=6.161), FetchedTranscriptSnippet(text='time generation is not paralyzable. But', start=3986.559, duration=8.0), FetchedTranscriptSnippet(text='training is paralyzable.', start=3990.72, duration=5.68), FetchedTranscriptSnippet(text='So if you remember the way we do', start=3994.559, duration=7.28), FetchedTranscriptSnippet(text='training is we input all the tokens', start=3996.4, duration=8.399), FetchedTranscriptSnippet(text='that we want our model to predict and', start=4001.839, duration=9.601), FetchedTranscriptSnippet(text='then we let the model generate tokens', start=4004.799, duration=8.641), FetchedTranscriptSnippet(text='out of this. So basically in a decoder', start=4011.44, duration=4.96), FetchedTranscriptSnippet(text='only setting you have this causal mask', start=4013.44, duration=6.24), FetchedTranscriptSnippet(text='which lets your model not cheat if you', start=4016.4, duration=7.679), FetchedTranscriptSnippet(text='want and not use the future ones.', start=4019.68, duration=6.159), FetchedTranscriptSnippet(text='So I just want to say that when I say', start=4024.079, duration=5.121), FetchedTranscriptSnippet(text='that uh this paradigm is not paralyzable', start=4025.839, duration=4.881), FetchedTranscriptSnippet(text='I just want to emphasize on the fact', start=4029.2, duration=3.2), FetchedTranscriptSnippet(text=\"that it's a inference time that I'm\", start=4030.72, duration=3.76), FetchedTranscriptSnippet(text='saying training time you can actually', start=4032.4, duration=5.959), FetchedTranscriptSnippet(text='paralyze that quite well.', start=4034.48, duration=3.879), FetchedTranscriptSnippet(text=\"So as I mentioned that's one of the\", start=4038.48, duration=5.52), FetchedTranscriptSnippet(text='reasons why people have tried to look at', start=4041.44, duration=4.72), FetchedTranscriptSnippet(text='other paradigms', start=4044.0, duration=5.039), FetchedTranscriptSnippet(text='and in particular um so if you know', start=4046.16, duration=4.56), FetchedTranscriptSnippet(text='about diffusion you know that it works', start=4049.039, duration=4.8), FetchedTranscriptSnippet(text='very well for the vision domain', start=4050.72, duration=6.56), FetchedTranscriptSnippet(text='and so people have tried adapting', start=4053.839, duration=5.601), FetchedTranscriptSnippet(text='this paradigm for the text generation', start=4057.28, duration=4.079), FetchedTranscriptSnippet(text='case', start=4059.44, duration=3.679), FetchedTranscriptSnippet(text='and uh so this is like a bunch of', start=4061.359, duration=4.401), FetchedTranscriptSnippet(text='screenshots we took from announcement', start=4063.119, duration=5.361), FetchedTranscriptSnippet(text='that happened this year. So for instance', start=4065.76, duration=4.64), FetchedTranscriptSnippet(text='uh earlier this year there was an', start=4068.48, duration=4.079), FetchedTranscriptSnippet(text='experimental text diffusion model from', start=4070.4, duration=5.36), FetchedTranscriptSnippet(text='Google that they presented during the IO', start=4072.559, duration=4.881), FetchedTranscriptSnippet(text='event', start=4075.76, duration=3.52), FetchedTranscriptSnippet(text='um which was very impressive because it', start=4077.44, duration=4.32), FetchedTranscriptSnippet(text='led to a lot of speedups. And then we', start=4079.28, duration=5.68), FetchedTranscriptSnippet(text='have some um like different startups. So', start=4081.76, duration=5.599), FetchedTranscriptSnippet(text='Inception is one of them uh that made', start=4084.96, duration=4.24), FetchedTranscriptSnippet(text='headlines I believe a couple of weeks', start=4087.359, duration=5.841), FetchedTranscriptSnippet(text='ago or last week no sorry a month ago um', start=4089.2, duration=6.88), FetchedTranscriptSnippet(text='that also are pursuing this route. Um,', start=4093.2, duration=5.76), FetchedTranscriptSnippet(text='so all of that to say that this', start=4096.08, duration=5.36), FetchedTranscriptSnippet(text='direction is a very trendy and hot', start=4098.96, duration=5.6), FetchedTranscriptSnippet(text='direction that potentially has a lot of', start=4101.44, duration=5.68), FetchedTranscriptSnippet(text='promise.', start=4104.56, duration=7.84), FetchedTranscriptSnippet(text='But the key issue with this is that text', start=4107.12, duration=7.119), FetchedTranscriptSnippet(text='is discrete', start=4112.4, duration=5.68), FetchedTranscriptSnippet(text='whereas images are continuous.', start=4114.239, duration=6.161), FetchedTranscriptSnippet(text=\"And we're going to see why that\", start=4118.08, duration=5.92), FetchedTranscriptSnippet(text='distinction that I just made matters.', start=4120.4, duration=5.68), FetchedTranscriptSnippet(text=\"So I'm going to try to explain to you\", start=4124.0, duration=5.359), FetchedTranscriptSnippet(text='what diffusion is in two minutes.', start=4126.08, duration=4.96), FetchedTranscriptSnippet(text='So', start=4129.359, duration=4.241), FetchedTranscriptSnippet(text='in the image world', start=4131.04, duration=5.84), FetchedTranscriptSnippet(text='in order to generate an image', start=4133.6, duration=6.239), FetchedTranscriptSnippet(text='what people typically do is they start', start=4136.88, duration=5.359), FetchedTranscriptSnippet(text='from noise', start=4139.839, duration=4.4), FetchedTranscriptSnippet(text='and then they try to generate some', start=4142.239, duration=4.08), FetchedTranscriptSnippet(text='image.', start=4144.239, duration=5.12), FetchedTranscriptSnippet(text='Now now you may wonder okay why noise?', start=4146.319, duration=6.48), FetchedTranscriptSnippet(text=\"Well, you cannot do something that's um\", start=4149.359, duration=5.681), FetchedTranscriptSnippet(text='you know uh auto reggressive because I', start=4152.799, duration=4.161), FetchedTranscriptSnippet(text=\"guess like if you were to say okay let's\", start=4155.04, duration=5.279), FetchedTranscriptSnippet(text=\"predict the pixels one at a time uh it's\", start=4156.96, duration=4.799), FetchedTranscriptSnippet(text='just not tractable because there are', start=4160.319, duration=3.36), FetchedTranscriptSnippet(text='many pixel in in an image and this is', start=4161.759, duration=4.48), FetchedTranscriptSnippet(text='typically not how you produce uh an', start=4163.679, duration=7.201), FetchedTranscriptSnippet(text='image but some other reasons are that uh', start=4166.239, duration=6.56), FetchedTranscriptSnippet(text='noise is just something that you can', start=4170.88, duration=4.959), FetchedTranscriptSnippet(text='model very well with uh some very', start=4172.799, duration=4.88), FetchedTranscriptSnippet(text='popular distributions so gausian', start=4175.839, duration=4.161), FetchedTranscriptSnippet(text='distribution if you know about', start=4177.679, duration=5.841), FetchedTranscriptSnippet(text='it has very nice properties. Um, also', start=4180.0, duration=5.44), FetchedTranscriptSnippet(text=\"noise is very easy to sample. So, it's\", start=4183.52, duration=5.52), FetchedTranscriptSnippet(text='very easy to start with that. Um, noise', start=4185.44, duration=6.0), FetchedTranscriptSnippet(text='is also a way for you to introduce', start=4189.04, duration=4.96), FetchedTranscriptSnippet(text=\"randomness because you don't necessarily\", start=4191.44, duration=4.56), FetchedTranscriptSnippet(text='want to always produce the same image.', start=4194.0, duration=6.4), FetchedTranscriptSnippet(text='You want to have uh the uh I guess', start=4196.0, duration=7.28), FetchedTranscriptSnippet(text='choice of generating images that are', start=4200.4, duration=5.759), FetchedTranscriptSnippet(text='slightly different from one another.', start=4203.28, duration=4.959), FetchedTranscriptSnippet(text='And uh just mathematically it works', start=4206.159, duration=7.201), FetchedTranscriptSnippet(text='quite well. And um speaking of that, the', start=4208.239, duration=8.0), FetchedTranscriptSnippet(text='goal is to learn', start=4213.36, duration=5.92), FetchedTranscriptSnippet(text='some transformation that would allow you', start=4216.239, duration=6.241), FetchedTranscriptSnippet(text='to go from noise', start=4219.28, duration=7.439), FetchedTranscriptSnippet(text='to the target image distribution.', start=4222.48, duration=7.199), FetchedTranscriptSnippet(text='So all of what I said here is just kind', start=4226.719, duration=5.121), FetchedTranscriptSnippet(text='of reasons for me to tell you, okay,', start=4229.679, duration=5.601), FetchedTranscriptSnippet(text='noise is actually a choice that is quite', start=4231.84, duration=5.839), FetchedTranscriptSnippet(text='natural to start with in order to', start=4235.28, duration=4.8), FetchedTranscriptSnippet(text='generate an image.', start=4237.679, duration=6.241), FetchedTranscriptSnippet(text='And to give you an analogy,', start=4240.08, duration=6.24), FetchedTranscriptSnippet(text=\"um let's suppose you're a sculpture\", start=4243.92, duration=4.4), FetchedTranscriptSnippet(text='sculptor. So the person who does', start=4246.32, duration=3.76), FetchedTranscriptSnippet(text='sculptures.', start=4248.32, duration=4.32), FetchedTranscriptSnippet(text='So if you want to do a sculpture, you', start=4250.08, duration=7.92), FetchedTranscriptSnippet(text='typically start with some rock.', start=4252.64, duration=7.599), FetchedTranscriptSnippet(text='But then rocks are, you know, different', start=4258.0, duration=5.04), FetchedTranscriptSnippet(text='from one another. They always have uh', start=4260.239, duration=6.801), FetchedTranscriptSnippet(text='things that are unique to them. And', start=4263.04, duration=9.679), FetchedTranscriptSnippet(text='still you would focus on what to remove', start=4267.04, duration=9.84), FetchedTranscriptSnippet(text='in order to obtain the end sculpture. So', start=4272.719, duration=5.921), FetchedTranscriptSnippet(text='you can think of the rock as being your', start=4276.88, duration=3.52), FetchedTranscriptSnippet(text='noise', start=4278.64, duration=5.599), FetchedTranscriptSnippet(text='and your end result as being your target', start=4280.4, duration=5.839), FetchedTranscriptSnippet(text='data distribution.', start=4284.239, duration=3.92), FetchedTranscriptSnippet(text='So I just want to have this quote by', start=4286.239, duration=4.0), FetchedTranscriptSnippet(text='Michelangelo. So the sculpture is', start=4288.159, duration=4.56), FetchedTranscriptSnippet(text='already complete within the marble block', start=4290.239, duration=4.721), FetchedTranscriptSnippet(text='before I start my work. It is already', start=4292.719, duration=4.0), FetchedTranscriptSnippet(text='there. I just have to chisel away the', start=4294.96, duration=4.239), FetchedTranscriptSnippet(text=\"superus material. The reason why I'm\", start=4296.719, duration=5.281), FetchedTranscriptSnippet(text='reading that is you can have a a nice', start=4299.199, duration=6.48), FetchedTranscriptSnippet(text='analogy between what Michelangelo said', start=4302.0, duration=8.64), FetchedTranscriptSnippet(text='and the process of denoising', start=4305.679, duration=8.881), FetchedTranscriptSnippet(text='the noise to get an image.', start=4310.64, duration=6.72), FetchedTranscriptSnippet(text='So this is all just motivating how image', start=4314.56, duration=4.639), FetchedTranscriptSnippet(text='generation is done. So you start from', start=4317.36, duration=3.44), FetchedTranscriptSnippet(text='noise', start=4319.199, duration=4.641), FetchedTranscriptSnippet(text='and you want to generate an image. So', start=4320.8, duration=5.68), FetchedTranscriptSnippet(text='the way you do that for diffusion is to', start=4323.84, duration=5.04), FetchedTranscriptSnippet(text='learn some transformation', start=4326.48, duration=6.16), FetchedTranscriptSnippet(text='that would allow you to go from noise', start=4328.88, duration=7.08), FetchedTranscriptSnippet(text='to image.', start=4332.64, duration=3.32), FetchedTranscriptSnippet(text='So you have two steps. I mean you have', start=4336.239, duration=4.081), FetchedTranscriptSnippet(text='more than two steps but we have these', start=4338.32, duration=3.6), FetchedTranscriptSnippet(text='two main steps for diffusion models', start=4340.32, duration=5.76), FetchedTranscriptSnippet(text='where you first want to start from clean', start=4341.92, duration=6.64), FetchedTranscriptSnippet(text='images', start=4346.08, duration=6.72), FetchedTranscriptSnippet(text='and you add noise gradually', start=4348.56, duration=7.28), FetchedTranscriptSnippet(text='until until you obtain some very noisy', start=4352.8, duration=4.8), FetchedTranscriptSnippet(text='image', start=4355.84, duration=4.72), FetchedTranscriptSnippet(text='and then from that', start=4357.6, duration=6.4), FetchedTranscriptSnippet(text='what diffusion models try to do is to', start=4360.56, duration=7.84), FetchedTranscriptSnippet(text='predict the noise to remove in order to', start=4364.0, duration=7.04), FetchedTranscriptSnippet(text='obtain the image.', start=4368.4, duration=4.16), FetchedTranscriptSnippet(text=\"So, it's a little bit like, you know,\", start=4371.04, duration=4.88), FetchedTranscriptSnippet(text=\"you're the sculpture sculpture person\", start=4372.56, duration=5.28), FetchedTranscriptSnippet(text='and you have your rock. You just want to', start=4375.92, duration=4.48), FetchedTranscriptSnippet(text='learn what pieces of rock you need to', start=4377.84, duration=5.04), FetchedTranscriptSnippet(text='remove in order to obtain your final', start=4380.4, duration=4.799), FetchedTranscriptSnippet(text='piece of art.', start=4382.88, duration=5.359), FetchedTranscriptSnippet(text='So, this is what diffusion is. So it', start=4385.199, duration=6.881), FetchedTranscriptSnippet(text='works pretty well because noise as I', start=4388.239, duration=5.361), FetchedTranscriptSnippet(text='mentioned is typically something that', start=4392.08, duration=3.44), FetchedTranscriptSnippet(text='people draw', start=4393.6, duration=4.72), FetchedTranscriptSnippet(text='from a gausian distribution.', start=4395.52, duration=5.679), FetchedTranscriptSnippet(text='Gausian distributions are mathematically', start=4398.32, duration=5.52), FetchedTranscriptSnippet(text='very well defined have a lot of nice', start=4401.199, duration=5.361), FetchedTranscriptSnippet(text=\"properties. So that's why they work so\", start=4403.84, duration=4.8), FetchedTranscriptSnippet(text='well.', start=4406.56, duration=4.159), FetchedTranscriptSnippet(text='But now the question is how would you', start=4408.64, duration=5.36), FetchedTranscriptSnippet(text='adapt this to the text world? Because in', start=4410.719, duration=6.241), FetchedTranscriptSnippet(text=\"the text world as you know we're talking\", start=4414.0, duration=4.8), FetchedTranscriptSnippet(text='about tokens.', start=4416.96, duration=4.239), FetchedTranscriptSnippet(text='Tokens are discrete.', start=4418.8, duration=4.16), FetchedTranscriptSnippet(text=\"So there's not this concept of you know\", start=4421.199, duration=6.161), FetchedTranscriptSnippet(text='adding noise. Cannot have that.', start=4422.96, duration=9.12), FetchedTranscriptSnippet(text='So pe what people have tried to um to do', start=4427.36, duration=7.52), FetchedTranscriptSnippet(text='was to find a text equivalent that would', start=4432.08, duration=6.639), FetchedTranscriptSnippet(text='make sense. And this is what the current', start=4434.88, duration=5.359), FetchedTranscriptSnippet(text='research', start=4438.719, duration=5.681), FetchedTranscriptSnippet(text='points to which is that noise is to', start=4440.239, duration=11.081), FetchedTranscriptSnippet(text='images what the mask token is to text.', start=4444.4, duration=6.92), FetchedTranscriptSnippet(text='So mask is just a way for us to just not', start=4451.76, duration=6.72), FetchedTranscriptSnippet(text='have the information coming from one', start=4456.4, duration=5.12), FetchedTranscriptSnippet(text='part of the sequence.', start=4458.48, duration=5.36), FetchedTranscriptSnippet(text='And I just want to go through the', start=4461.52, duration=4.4), FetchedTranscriptSnippet(text='revised two-step process that we saw', start=4463.84, duration=4.24), FetchedTranscriptSnippet(text='here for text.', start=4465.92, duration=6.319), FetchedTranscriptSnippet(text='So here for the forward process', start=4468.08, duration=7.2), FetchedTranscriptSnippet(text='instead of noising your input', start=4472.239, duration=7.361), FetchedTranscriptSnippet(text='you would just have more and more', start=4475.28, duration=8.28), FetchedTranscriptSnippet(text='inputs that would be masked.', start=4479.6, duration=3.96), FetchedTranscriptSnippet(text=\"So that's the for process and at the end\", start=4484.159, duration=4.961), FetchedTranscriptSnippet(text='you would just obtain a sequence full of', start=4486.719, duration=5.681), FetchedTranscriptSnippet(text='mass tokens.', start=4489.12, duration=7.36), FetchedTranscriptSnippet(text='So what you want to do is to learn', start=4492.4, duration=5.759), FetchedTranscriptSnippet(text='some', start=4496.48, duration=6.64), FetchedTranscriptSnippet(text='model that allows you to unmask', start=4498.159, duration=8.161), FetchedTranscriptSnippet(text='these mass tokens in a way that', start=4503.12, duration=7.599), FetchedTranscriptSnippet(text='reconstructs the original sentence.', start=4506.32, duration=6.72), FetchedTranscriptSnippet(text=\"So there's some math that goes into it.\", start=4510.719, duration=4.081), FetchedTranscriptSnippet(text='Obviously in a few minutes we will not', start=4513.04, duration=4.24), FetchedTranscriptSnippet(text='have time to go into that. But I just', start=4514.8, duration=4.879), FetchedTranscriptSnippet(text='want to emphasize on the key idea which', start=4517.28, duration=4.16), FetchedTranscriptSnippet(text='is', start=4519.679, duration=4.56), FetchedTranscriptSnippet(text='you want to do diffusion but in a way', start=4521.44, duration=5.68), FetchedTranscriptSnippet(text='that makes sense for text inputs.', start=4524.239, duration=4.801), FetchedTranscriptSnippet(text='And the way the way it would make sense', start=4527.12, duration=4.559), FetchedTranscriptSnippet(text='is to consider', start=4529.04, duration=5.84), FetchedTranscriptSnippet(text='the noise for images as being mask', start=4531.679, duration=4.961), FetchedTranscriptSnippet(text='tokens', start=4534.88, duration=5.48), FetchedTranscriptSnippet(text='for text input.', start=4536.64, duration=3.72), FetchedTranscriptSnippet(text='Cool. And so with that in mind, you have', start=4541.84, duration=4.48), FetchedTranscriptSnippet(text='a bunch of models that are being', start=4544.96, duration=4.96), FetchedTranscriptSnippet(text='released these days which are called', start=4546.32, duration=8.64), FetchedTranscriptSnippet(text='masked diffusion models, MDM.', start=4549.92, duration=8.0), FetchedTranscriptSnippet(text='So whenever you see MDM now, you know', start=4554.96, duration=5.6), FetchedTranscriptSnippet(text=\"what kind of model we're talking about.\", start=4557.92, duration=8.64), FetchedTranscriptSnippet(text='So notations are still very um not very', start=4560.56, duration=8.56), FetchedTranscriptSnippet(text='well defined. So it may change in the', start=4566.56, duration=4.72), FetchedTranscriptSnippet(text='future. But one other term you will see', start=4569.12, duration=6.88), FetchedTranscriptSnippet(text='out there is also DLLM diffusion based', start=4571.28, duration=6.959), FetchedTranscriptSnippet(text='LLM', start=4576.0, duration=5.199), FetchedTranscriptSnippet(text=\"and this is what it's doing. So instead\", start=4578.239, duration=6.321), FetchedTranscriptSnippet(text='of predicting a token in an auto', start=4581.199, duration=6.641), FetchedTranscriptSnippet(text='reggressive fashion like one at a time,', start=4584.56, duration=6.72), FetchedTranscriptSnippet(text='what it does is that at inference time', start=4587.84, duration=6.96), FetchedTranscriptSnippet(text='it goes from a completely masked', start=4591.28, duration=5.919), FetchedTranscriptSnippet(text='input sequence', start=4594.8, duration=6.16), FetchedTranscriptSnippet(text='and it tries to predict what tokens were', start=4597.199, duration=7.201), FetchedTranscriptSnippet(text='behind these mass tokens.', start=4600.96, duration=6.16), FetchedTranscriptSnippet(text='So of course um you know in a real life', start=4604.4, duration=4.319), FetchedTranscriptSnippet(text='setting you would have some prompts', start=4607.12, duration=5.2), FetchedTranscriptSnippet(text='here. you would have some prompts. So of', start=4608.719, duration=6.241), FetchedTranscriptSnippet(text='course in order to predict this answer', start=4612.32, duration=5.28), FetchedTranscriptSnippet(text='you would have some conditioning. So you', start=4614.96, duration=4.239), FetchedTranscriptSnippet(text='would tell your model okay given this', start=4617.6, duration=3.68), FetchedTranscriptSnippet(text=\"prompts you're going to start with all\", start=4619.199, duration=6.48), FetchedTranscriptSnippet(text='these mass tokens just try to predict', start=4621.28, duration=7.2), FetchedTranscriptSnippet(text='what the answer is.', start=4625.679, duration=5.441), FetchedTranscriptSnippet(text=\"So in case you're having trouble with\", start=4628.48, duration=5.44), FetchedTranscriptSnippet(text='the intuition. So I also had trouble in', start=4631.12, duration=4.24), FetchedTranscriptSnippet(text='the beginning you know why would it make', start=4633.92, duration=5.52), FetchedTranscriptSnippet(text='sense for text to be solved in a', start=4635.36, duration=6.319), FetchedTranscriptSnippet(text='diffusion manner because typically when', start=4639.44, duration=4.719), FetchedTranscriptSnippet(text='you write you write one word at a time.', start=4641.679, duration=6.161), FetchedTranscriptSnippet(text='So one helpful way to think about this', start=4644.159, duration=5.441), FetchedTranscriptSnippet(text='is', start=4647.84, duration=3.28), FetchedTranscriptSnippet(text=\"let's suppose you want to write a\", start=4649.6, duration=4.079), FetchedTranscriptSnippet(text='speech.', start=4651.12, duration=5.119), FetchedTranscriptSnippet(text='So you would not directly write your', start=4653.679, duration=5.04), FetchedTranscriptSnippet(text='speech in a linear way.', start=4656.239, duration=5.761), FetchedTranscriptSnippet(text='You would first have like a rough plan.', start=4658.719, duration=4.561), FetchedTranscriptSnippet(text=\"you say okay I'm going to talk about\", start=4662.0, duration=3.76), FetchedTranscriptSnippet(text='this in the first place second third you', start=4663.28, duration=4.64), FetchedTranscriptSnippet(text='have some kind of draft', start=4665.76, duration=4.479), FetchedTranscriptSnippet(text='and then you try to refine what is in', start=4667.92, duration=5.36), FetchedTranscriptSnippet(text='each of these sections', start=4670.239, duration=5.761), FetchedTranscriptSnippet(text='so you can think of diffusion as kind of', start=4673.28, duration=7.52), FetchedTranscriptSnippet(text='working like this so it tries to have a', start=4676.0, duration=10.159), FetchedTranscriptSnippet(text='course to fine refinement of the output', start=4680.8, duration=7.2), FetchedTranscriptSnippet(text='so it can predict things that are you', start=4686.159, duration=3.52), FetchedTranscriptSnippet(text='know after a certain token that has not', start=4688.0, duration=4.64), FetchedTranscriptSnippet(text='been predicted But you can think of this', start=4689.679, duration=5.04), FetchedTranscriptSnippet(text='as being', start=4692.64, duration=4.0), FetchedTranscriptSnippet(text='something that goes from a very drafty', start=4694.719, duration=6.881), FetchedTranscriptSnippet(text='version to a very refined version.', start=4696.64, duration=7.039), FetchedTranscriptSnippet(text=\"So that's what I think about this\", start=4701.6, duration=5.119), FetchedTranscriptSnippet(text=\"process. Hopefully that's helpful. And\", start=4703.679, duration=6.881), FetchedTranscriptSnippet(text='the key advantage here is that the', start=4706.719, duration=6.801), FetchedTranscriptSnippet(text='decoding is now done in much fewer', start=4710.56, duration=5.04), FetchedTranscriptSnippet(text='forward passes', start=4713.52, duration=5.76), FetchedTranscriptSnippet(text='because previously you had to do as many', start=4715.6, duration=6.559), FetchedTranscriptSnippet(text='forward passes as there were tokens to', start=4719.28, duration=5.28), FetchedTranscriptSnippet(text='predict.', start=4722.159, duration=5.681), FetchedTranscriptSnippet(text='But here for diffusion you only need to', start=4724.56, duration=7.76), FetchedTranscriptSnippet(text='do as many passes as there are steps in', start=4727.84, duration=6.8), FetchedTranscriptSnippet(text='your diffusion process. And the number', start=4732.32, duration=5.52), FetchedTranscriptSnippet(text='of steps is something you can fix.', start=4734.64, duration=5.44), FetchedTranscriptSnippet(text='So the higher the step, the more high', start=4737.84, duration=5.359), FetchedTranscriptSnippet(text=\"quality your output is, but it's\", start=4740.08, duration=6.639), FetchedTranscriptSnippet(text='typically much lower than the length of', start=4743.199, duration=6.561), FetchedTranscriptSnippet(text='your output.', start=4746.719, duration=6.801), FetchedTranscriptSnippet(text='So that is the core reason why', start=4749.76, duration=6.8), FetchedTranscriptSnippet(text='this model is so much faster than the', start=4753.52, duration=5.92), FetchedTranscriptSnippet(text='auto reggressive one.', start=4756.56, duration=5.76), FetchedTranscriptSnippet(text=\"And um of course you know uh we don't\", start=4759.44, duration=4.64), FetchedTranscriptSnippet(text='have uh that much time but in case', start=4762.32, duration=3.76), FetchedTranscriptSnippet(text=\"you're curious in case you're interested\", start=4764.08, duration=4.24), FetchedTranscriptSnippet(text=\"after the final once you're completely\", start=4766.08, duration=6.0), FetchedTranscriptSnippet(text='freed in terms of uh things to think of', start=4768.32, duration=7.359), FetchedTranscriptSnippet(text='uh just put some references that could', start=4772.08, duration=5.44), FetchedTranscriptSnippet(text=\"be help helpful. There's a paper that\", start=4775.679, duration=5.04), FetchedTranscriptSnippet(text='came out earlier this year called LADA', start=4777.52, duration=6.08), FetchedTranscriptSnippet(text='large language', start=4780.719, duration=5.201), FetchedTranscriptSnippet(text='uh diffusion', start=4783.6, duration=4.16), FetchedTranscriptSnippet(text=\"model with masking. Actually, I don't\", start=4785.92, duration=4.72), FetchedTranscriptSnippet(text='remember the full acronym, but it is', start=4787.76, duration=5.52), FetchedTranscriptSnippet(text='actually going through the math and why', start=4790.64, duration=5.68), FetchedTranscriptSnippet(text='the thing that I just mentioned works.', start=4793.28, duration=4.48), FetchedTranscriptSnippet(text=\"Uh, and then there's like a bunch of\", start=4796.32, duration=3.68), FetchedTranscriptSnippet(text='other papers that would also be helpful.', start=4797.76, duration=4.64), FetchedTranscriptSnippet(text='So, the links are in the at the bottom', start=4800.0, duration=6.32), FetchedTranscriptSnippet(text=\"of the slide in case you're interested.\", start=4802.4, duration=6.72), FetchedTranscriptSnippet(text='And I just want to go through two last', start=4806.32, duration=6.32), FetchedTranscriptSnippet(text='things before giving it to Shervin.', start=4809.12, duration=6.48), FetchedTranscriptSnippet(text='So first on the advantages of this new', start=4812.64, duration=4.64), FetchedTranscriptSnippet(text='paradigm.', start=4815.6, duration=5.68), FetchedTranscriptSnippet(text='So the first one is the speed.', start=4817.28, duration=6.48), FetchedTranscriptSnippet(text=\"So as we mentioned it's going to be much\", start=4821.28, duration=5.84), FetchedTranscriptSnippet(text='faster than traditional auto reggressive', start=4823.76, duration=6.16), FetchedTranscriptSnippet(text='models especially for outputs that are', start=4827.12, duration=6.16), FetchedTranscriptSnippet(text='longer. And so some benchmarks they even', start=4829.92, duration=5.44), FetchedTranscriptSnippet(text=\"say that it's something along the lines\", start=4833.28, duration=5.52), FetchedTranscriptSnippet(text='of 10x faster.', start=4835.36, duration=8.16), FetchedTranscriptSnippet(text='So for cases like coding it can be very', start=4838.8, duration=7.68), FetchedTranscriptSnippet(text='powerful because you may have to do', start=4843.52, duration=6.639), FetchedTranscriptSnippet(text='several model calls and uh you know you', start=4846.48, duration=6.0), FetchedTranscriptSnippet(text=\"as a user you're just waiting for that\", start=4850.159, duration=4.321), FetchedTranscriptSnippet(text='code to happen and you know just having', start=4852.48, duration=3.679), FetchedTranscriptSnippet(text='a lower latency makes a lot of', start=4854.48, duration=3.84), FetchedTranscriptSnippet(text='difference.', start=4856.159, duration=5.52), FetchedTranscriptSnippet(text='The other thing is that the nature of', start=4858.32, duration=8.08), FetchedTranscriptSnippet(text='this approach is actually considering', start=4861.679, duration=6.801), FetchedTranscriptSnippet(text='the text as a whole in order to make the', start=4866.4, duration=3.68), FetchedTranscriptSnippet(text='predictions.', start=4868.48, duration=4.64), FetchedTranscriptSnippet(text=\"And so there's a category of coding\", start=4870.08, duration=8.8), FetchedTranscriptSnippet(text='tasks that are called fill in the middle', start=4873.12, duration=9.2), FetchedTranscriptSnippet(text='which is about trying to figure out you', start=4878.88, duration=5.76), FetchedTranscriptSnippet(text='know you have a bunch of code and you', start=4882.32, duration=5.44), FetchedTranscriptSnippet(text=\"want to know what's missing.\", start=4884.64, duration=5.76), FetchedTranscriptSnippet(text='in the middle and so fill in the middle', start=4887.76, duration=5.12), FetchedTranscriptSnippet(text='and diffusion models are typically', start=4890.4, duration=4.56), FetchedTranscriptSnippet(text='better formulated for the kind these', start=4892.88, duration=5.04), FetchedTranscriptSnippet(text='kinds of tasks because they can consider', start=4894.96, duration=7.12), FetchedTranscriptSnippet(text='I guess input from multiple directions', start=4897.92, duration=7.36), FetchedTranscriptSnippet(text=\"and um you know that's why this approach\", start=4902.08, duration=5.599), FetchedTranscriptSnippet(text='can be probably something that can be', start=4905.28, duration=4.0), FetchedTranscriptSnippet(text='useful', start=4907.679, duration=5.321), FetchedTranscriptSnippet(text='for some applications.', start=4909.28, duration=3.72), FetchedTranscriptSnippet(text='So in terms of the current work, so', start=4913.12, duration=4.079), FetchedTranscriptSnippet(text='these models they look great you know', start=4915.44, duration=4.32), FetchedTranscriptSnippet(text='what I mentioned to you looks great but', start=4917.199, duration=6.0), FetchedTranscriptSnippet(text='the performance was not on par with the', start=4919.76, duration=5.439), FetchedTranscriptSnippet(text='current frontier models at least for', start=4923.199, duration=5.281), FetchedTranscriptSnippet(text=\"some time but it's something that may\", start=4925.199, duration=4.801), FetchedTranscriptSnippet(text='change.', start=4928.48, duration=4.0), FetchedTranscriptSnippet(text='So the papers that I mentioned they are', start=4930.0, duration=4.96), FetchedTranscriptSnippet(text='actually posting performance that is', start=4932.48, duration=4.32), FetchedTranscriptSnippet(text='kind of catching up with the models that', start=4934.96, duration=4.4), FetchedTranscriptSnippet(text='are auto reggressive.', start=4936.8, duration=5.359), FetchedTranscriptSnippet(text='So there is some promise in there. And', start=4939.36, duration=5.279), FetchedTranscriptSnippet(text='then uh the other line of work is just', start=4942.159, duration=4.56), FetchedTranscriptSnippet(text='to adapt', start=4944.639, duration=4.08), FetchedTranscriptSnippet(text='all the techniques that people have come', start=4946.719, duration=4.641), FetchedTranscriptSnippet(text='up with uh like for instance you know', start=4948.719, duration=4.081), FetchedTranscriptSnippet(text='reasoning chains. How do you adapt that', start=4951.36, duration=3.12), FetchedTranscriptSnippet(text='for diffusion?', start=4952.8, duration=4.24), FetchedTranscriptSnippet(text='Um like you know and so on. You know', start=4954.48, duration=4.239), FetchedTranscriptSnippet(text='there are so many techniques that are', start=4957.04, duration=4.0), FetchedTranscriptSnippet(text='intrinsically more', start=4958.719, duration=5.041), FetchedTranscriptSnippet(text='better suited for auto reggressive', start=4961.04, duration=6.4), FetchedTranscriptSnippet(text='kinds of models that can be adapted for', start=4963.76, duration=5.919), FetchedTranscriptSnippet(text='that', start=4967.44, duration=5.44), FetchedTranscriptSnippet(text=\"and that's what people are working on.\", start=4969.679, duration=5.52), FetchedTranscriptSnippet(text='So long story short,', start=4972.88, duration=6.72), FetchedTranscriptSnippet(text='what we saw was that things we saw in', start=4975.199, duration=7.921), FetchedTranscriptSnippet(text='this class could be used in other', start=4979.6, duration=6.24), FetchedTranscriptSnippet(text='domains. Like for instance, we saw the', start=4983.12, duration=5.44), FetchedTranscriptSnippet(text='vision transformer', start=4985.84, duration=5.12), FetchedTranscriptSnippet(text='uh that was borrowing the transformer', start=4988.56, duration=4.639), FetchedTranscriptSnippet(text='for vision related tasks. But we also', start=4990.96, duration=5.84), FetchedTranscriptSnippet(text='saw that things from other domains', start=4993.199, duration=7.121), FetchedTranscriptSnippet(text='could also be used in the text world.', start=4996.8, duration=5.04), FetchedTranscriptSnippet(text=\"And that's what we saw with diffusion\", start=5000.32, duration=4.879), FetchedTranscriptSnippet(text='LMS. Um, and so this is probably, you', start=5001.84, duration=5.28), FetchedTranscriptSnippet(text='know, of course a subset of everything', start=5005.199, duration=4.96), FetchedTranscriptSnippet(text=\"that's happening.\", start=5007.12, duration=4.88), FetchedTranscriptSnippet(text=\"And so with that, I think we're\", start=5010.159, duration=5.121), FetchedTranscriptSnippet(text='concluding our second item of our menu.', start=5012.0, duration=6.56), FetchedTranscriptSnippet(text=\"And um, I'm going to just give it to\", start=5015.28, duration=6.28), FetchedTranscriptSnippet(text='Shervin.', start=5018.56, duration=3.0), FetchedTranscriptSnippet(text='Thank you, Ashin.', start=5022.719, duration=4.721), FetchedTranscriptSnippet(text='And with that, welcome to the last part', start=5024.639, duration=6.241), FetchedTranscriptSnippet(text='of the season finale of CM295.', start=5027.44, duration=5.759), FetchedTranscriptSnippet(text='And as Ein mentioned, now is the time', start=5030.88, duration=5.839), FetchedTranscriptSnippet(text='for some closing thoughts and see um', start=5033.199, duration=7.681), FetchedTranscriptSnippet(text='what we can get away from this class and', start=5036.719, duration=7.361), FetchedTranscriptSnippet(text='uh concepts that are u neighboring to', start=5040.88, duration=4.72), FetchedTranscriptSnippet(text='it.', start=5044.08, duration=4.48), FetchedTranscriptSnippet(text='Uh so first Afin went through the', start=5045.6, duration=5.599), FetchedTranscriptSnippet(text='concept of diffusion and images and we', start=5048.56, duration=4.639), FetchedTranscriptSnippet(text='saw some similarities. we could draw', start=5051.199, duration=5.281), FetchedTranscriptSnippet(text=\"with text. And now we're going to see\", start=5053.199, duration=5.841), FetchedTranscriptSnippet(text='what kinds of inspirations have both', start=5056.48, duration=5.44), FetchedTranscriptSnippet(text='modalities taken from each other. And', start=5059.04, duration=5.679), FetchedTranscriptSnippet(text=\"we're going to see um that actually like\", start=5061.92, duration=7.84), FetchedTranscriptSnippet(text='a lot of things can be um reused.', start=5064.719, duration=7.201), FetchedTranscriptSnippet(text='So the first thing that I want to', start=5069.76, duration=4.56), FetchedTranscriptSnippet(text='mention in terms of what has been reused', start=5071.92, duration=6.239), FetchedTranscriptSnippet(text='is the architecture part. So Afinen uh', start=5074.32, duration=6.8), FetchedTranscriptSnippet(text='mentioned this uh like diffusion concept', start=5078.159, duration=6.241), FetchedTranscriptSnippet(text='that was born in the field of images but', start=5081.12, duration=6.64), FetchedTranscriptSnippet(text='that was taken for text and was able to', start=5084.4, duration=6.64), FetchedTranscriptSnippet(text='yield uh lower latency like a higher', start=5087.76, duration=5.04), FetchedTranscriptSnippet(text=\"speedups which is great when you're a\", start=5091.04, duration=4.72), FetchedTranscriptSnippet(text='user. Uh so this was one example of a', start=5092.8, duration=4.48), FetchedTranscriptSnippet(text='win.', start=5095.76, duration=5.68), FetchedTranscriptSnippet(text='Uh and then on the other direction um', start=5097.28, duration=6.56), FetchedTranscriptSnippet(text='traditionally images have been dealing', start=5101.44, duration=6.88), FetchedTranscriptSnippet(text='with um convolutions mostly as as uh', start=5103.84, duration=9.04), FetchedTranscriptSnippet(text='model architecture type but uh these', start=5108.32, duration=7.12), FetchedTranscriptSnippet(text='papers saw that replacing convolutions', start=5112.88, duration=4.4), FetchedTranscriptSnippet(text='with transformers', start=5115.44, duration=5.52), FetchedTranscriptSnippet(text='uh was very good even um yielding better', start=5117.28, duration=6.08), FetchedTranscriptSnippet(text='results. So all these latest', start=5120.96, duration=4.48), FetchedTranscriptSnippet(text='diffusionbased papers in the field of', start=5123.36, duration=5.92), FetchedTranscriptSnippet(text='images typically use transformers', start=5125.44, duration=5.68), FetchedTranscriptSnippet(text=\"and then here I'm linking one of the\", start=5129.28, duration=5.52), FetchedTranscriptSnippet(text='papers that Afin already uh briefly went', start=5131.12, duration=6.0), FetchedTranscriptSnippet(text='through.', start=5134.8, duration=5.12), FetchedTranscriptSnippet(text='But not only uh is it the architecture', start=5137.12, duration=5.44), FetchedTranscriptSnippet(text='sides that is uh that that is the', start=5139.92, duration=5.36), FetchedTranscriptSnippet(text='subject of pollination between these', start=5142.56, duration=6.0), FetchedTranscriptSnippet(text='modalities. You could even think of', start=5145.28, duration=5.2), FetchedTranscriptSnippet(text='other kinds of components like the', start=5148.56, duration=5.119), FetchedTranscriptSnippet(text='input. And for this one I want to', start=5150.48, duration=7.759), FetchedTranscriptSnippet(text='mention the example of deepsek OCR. So I', start=5153.679, duration=5.921), FetchedTranscriptSnippet(text=\"don't know if you've heard of this\", start=5158.239, duration=4.161), FetchedTranscriptSnippet(text='paper. It just came out very recently', start=5159.6, duration=6.4), FetchedTranscriptSnippet(text='and contrary to what the names the name', start=5162.4, duration=7.839), FetchedTranscriptSnippet(text='suggests. So, OCR stands for optical rec', start=5166.0, duration=6.32), FetchedTranscriptSnippet(text='uh like recognition, character', start=5170.239, duration=5.041), FetchedTranscriptSnippet(text=\"recognition and it's usually a field\", start=5172.32, duration=7.52), FetchedTranscriptSnippet(text='that tries to convert some scanned image', start=5175.28, duration=8.08), FetchedTranscriptSnippet(text='into text but actually that paper', start=5179.84, duration=6.799), FetchedTranscriptSnippet(text=\"doesn't boast some improvement on the\", start=5183.36, duration=7.359), FetchedTranscriptSnippet(text='OCR task itself rather it showed that', start=5186.639, duration=7.6), FetchedTranscriptSnippet(text='you could learn some function that', start=5190.719, duration=5.601), FetchedTranscriptSnippet(text='reconstructs', start=5194.239, duration=6.48), FetchedTranscriptSnippet(text='text tokens based on vision tokens and', start=5196.32, duration=7.28), FetchedTranscriptSnippet(text='not only on vision tokens on very few', start=5200.719, duration=6.721), FetchedTranscriptSnippet(text='vision tokens. So it showed that the', start=5203.6, duration=6.48), FetchedTranscriptSnippet(text='representation power of patches of', start=5207.44, duration=6.64), FetchedTranscriptSnippet(text='images as tokens was very strong. And', start=5210.08, duration=5.76), FetchedTranscriptSnippet(text='you have some researchers that bring', start=5214.08, duration=5.76), FetchedTranscriptSnippet(text='some rationale to it like um you know', start=5215.84, duration=6.72), FetchedTranscriptSnippet(text='hey tokenizers are not the best tool', start=5219.84, duration=5.6), FetchedTranscriptSnippet(text='anyway. and then things in patches', start=5222.56, duration=5.28), FetchedTranscriptSnippet(text='convey the meaning of text already with', start=5225.44, duration=5.68), FetchedTranscriptSnippet(text='the example of emojis and so on that you', start=5227.84, duration=5.28), FetchedTranscriptSnippet(text='would otherwise need to represent with', start=5231.12, duration=6.4), FetchedTranscriptSnippet(text='way more tokens in text. Um and then', start=5233.12, duration=6.48), FetchedTranscriptSnippet(text='another example I want to mention is', start=5237.52, duration=4.08), FetchedTranscriptSnippet(text='even when you look inside the', start=5239.6, duration=3.52), FetchedTranscriptSnippet(text='architectures', start=5241.6, duration=4.88), FetchedTranscriptSnippet(text='some of the tricks uh can be reused and', start=5243.12, duration=6.24), FetchedTranscriptSnippet(text=\"adapted in each field. So here I'm\", start=5246.48, duration=6.48), FetchedTranscriptSnippet(text='mentioning the example of rope which fin', start=5249.36, duration=6.24), FetchedTranscriptSnippet(text='mentioned in the recap that was used in', start=5252.96, duration=5.12), FetchedTranscriptSnippet(text='text to represent uh the relative', start=5255.6, duration=6.079), FetchedTranscriptSnippet(text='position of tokens and in the case of', start=5258.08, duration=7.04), FetchedTranscriptSnippet(text='images or even multimodel setting where', start=5261.679, duration=7.281), FetchedTranscriptSnippet(text='you have the presence of both text and', start=5265.12, duration=6.96), FetchedTranscriptSnippet(text=\"image within the architecture. you're\", start=5268.96, duration=7.44), FetchedTranscriptSnippet(text='able to adapt that trick uh by', start=5272.08, duration=8.72), FetchedTranscriptSnippet(text='reformulating it in 2D. So here uh the', start=5276.4, duration=7.839), FetchedTranscriptSnippet(text='figure shows how you can attribute rope', start=5280.8, duration=6.08), FetchedTranscriptSnippet(text='positions in the 2D grids and how you', start=5284.239, duration=6.641), FetchedTranscriptSnippet(text='could place text tokens such that the', start=5286.88, duration=6.319), FetchedTranscriptSnippet(text='relative computation of position still', start=5290.88, duration=5.56), FetchedTranscriptSnippet(text='makes sense.', start=5293.199, duration=3.241), FetchedTranscriptSnippet(text='And you know even beyond that I would', start=5297.36, duration=6.48), FetchedTranscriptSnippet(text='say that the ongoing research for', start=5301.6, duration=5.92), FetchedTranscriptSnippet(text='transformers is very much alive and', start=5303.84, duration=5.68), FetchedTranscriptSnippet(text='people are still figuring out all the', start=5307.52, duration=4.48), FetchedTranscriptSnippet(text=\"details that we're working with today\", start=5309.52, duration=5.28), FetchedTranscriptSnippet(text='and you see refinements all the time', start=5312.0, duration=6.0), FetchedTranscriptSnippet(text='coming uh in terms of new papers. So', start=5314.8, duration=5.839), FetchedTranscriptSnippet(text=\"it's um you know it's something that is\", start=5318.0, duration=4.48), FetchedTranscriptSnippet(text='still developing', start=5320.639, duration=3.441), FetchedTranscriptSnippet(text='and', start=5322.48, duration=4.719), FetchedTranscriptSnippet(text='you can look at it from multiple angles.', start=5324.08, duration=5.599), FetchedTranscriptSnippet(text='One is each of these design decisions', start=5327.199, duration=5.04), FetchedTranscriptSnippet(text=\"that we've had they are still being\", start=5329.679, duration=5.361), FetchedTranscriptSnippet(text=\"iterated on. So like I'm listing a few\", start=5332.239, duration=6.96), FetchedTranscriptSnippet(text='items here as an example. So one is the', start=5335.04, duration=6.72), FetchedTranscriptSnippet(text='optimizer side. You might be familiar', start=5339.199, duration=5.121), FetchedTranscriptSnippet(text='with the atom optimizer and its update', start=5341.76, duration=5.2), FetchedTranscriptSnippet(text='role which has been popular for quite', start=5344.32, duration=6.8), FetchedTranscriptSnippet(text='some time and it seems that uh state is', start=5346.96, duration=7.6), FetchedTranscriptSnippet(text='being challenged with a newer paper. So', start=5351.12, duration=7.76), FetchedTranscriptSnippet(text='I referenced here the Kim K2 paper that', start=5354.56, duration=7.28), FetchedTranscriptSnippet(text='came out a few months ago that uh', start=5358.88, duration=4.96), FetchedTranscriptSnippet(text='introduces a new kind of optimizer', start=5361.84, duration=4.96), FetchedTranscriptSnippet(text='called muon and the latest version of', start=5363.84, duration=6.48), FetchedTranscriptSnippet(text='that muon clip seems to be a potential', start=5366.8, duration=6.72), FetchedTranscriptSnippet(text='candidate for this optimizer to to', start=5370.32, duration=6.319), FetchedTranscriptSnippet(text='become like the new standard. So this', start=5373.52, duration=5.92), FetchedTranscriptSnippet(text='field even', start=5376.639, duration=5.201), FetchedTranscriptSnippet(text='like as basic as it can be is still', start=5379.44, duration=3.92), FetchedTranscriptSnippet(text='developing', start=5381.84, duration=4.16), FetchedTranscriptSnippet(text=\"but it's not only the optimizer side you\", start=5383.36, duration=5.279), FetchedTranscriptSnippet(text='also have the topic of normalization', start=5386.0, duration=5.92), FetchedTranscriptSnippet(text='where Afin mentioned that the difference', start=5388.639, duration=5.52), FetchedTranscriptSnippet(text='between the original transformer paper', start=5391.92, duration=6.16), FetchedTranscriptSnippet(text='and what you see today in LLM papers', start=5394.159, duration=6.0), FetchedTranscriptSnippet(text=\"um you don't have the same kind of\", start=5398.08, duration=4.079), FetchedTranscriptSnippet(text='normalization anymore in the past you', start=5400.159, duration=4.48), FetchedTranscriptSnippet(text='had postnorm', start=5402.159, duration=5.121), FetchedTranscriptSnippet(text='but Now you have pre-norm which brings', start=5404.639, duration=5.761), FetchedTranscriptSnippet(text='the normalization earlier on in the', start=5407.28, duration=5.2), FetchedTranscriptSnippet(text='layer.', start=5410.4, duration=5.12), FetchedTranscriptSnippet(text='Uh but beyond that design choice of the', start=5412.48, duration=5.84), FetchedTranscriptSnippet(text='loca location of normalization you even', start=5415.52, duration=6.8), FetchedTranscriptSnippet(text='have the type of loca uh of', start=5418.32, duration=6.879), FetchedTranscriptSnippet(text='normalization that changes. So the', start=5422.32, duration=6.16), FetchedTranscriptSnippet(text='transformer paper used layer norm but', start=5425.199, duration=5.681), FetchedTranscriptSnippet(text='these days you might see other kinds of', start=5428.48, duration=4.64), FetchedTranscriptSnippet(text='uh normalization techniques like RMS', start=5430.88, duration=4.72), FetchedTranscriptSnippet(text='norm which uses less parameters and', start=5433.12, duration=6.48), FetchedTranscriptSnippet(text='others. So the theory behind it is not', start=5435.6, duration=6.48), FetchedTranscriptSnippet(text='set just yet.', start=5439.6, duration=4.16), FetchedTranscriptSnippet(text='Uh so you have other kinds of', start=5442.08, duration=5.44), FetchedTranscriptSnippet(text='parameters. Um Ashin mentioned the', start=5443.76, duration=7.12), FetchedTranscriptSnippet(text='grouped query attention paper and you', start=5447.52, duration=7.52), FetchedTranscriptSnippet(text='see these days in LLM papers not a fixed', start=5450.88, duration=7.44), FetchedTranscriptSnippet(text='design rather every paper adopts their', start=5455.04, duration=5.119), FetchedTranscriptSnippet(text='uh their own technique. Sometimes you', start=5458.32, duration=6.16), FetchedTranscriptSnippet(text='see one kind of u attention used at a', start=5460.159, duration=7.52), FetchedTranscriptSnippet(text='given layer but then it switches and', start=5464.48, duration=5.199), FetchedTranscriptSnippet(text='different papers take different design', start=5467.679, duration=5.681), FetchedTranscriptSnippet(text=\"decisions so it's not set in stone. Um\", start=5469.679, duration=6.321), FetchedTranscriptSnippet(text='then you also have activation functions.', start=5473.36, duration=5.6), FetchedTranscriptSnippet(text='So traditionally in deep learning a lot', start=5476.0, duration=6.4), FetchedTranscriptSnippet(text='of emphasis was put on ReLU which is uh', start=5478.96, duration=7.44), FetchedTranscriptSnippet(text='very simple and used worked very well.', start=5482.4, duration=7.2), FetchedTranscriptSnippet(text='But in the world of LLM the shift was', start=5486.4, duration=8.08), FetchedTranscriptSnippet(text='towards uh ReLU like um activation', start=5489.6, duration=7.28), FetchedTranscriptSnippet(text='functions but not exactly relu. So you', start=5494.48, duration=6.239), FetchedTranscriptSnippet(text='had gausian error linear uh units you', start=5496.88, duration=6.16), FetchedTranscriptSnippet(text='you had like other kinds and the the', start=5500.719, duration=4.48), FetchedTranscriptSnippet(text='research there is still ongoing. So you', start=5503.04, duration=5.44), FetchedTranscriptSnippet(text='you still see um you still see new', start=5505.199, duration=5.841), FetchedTranscriptSnippet(text='activation functions coming in uh now', start=5508.48, duration=5.679), FetchedTranscriptSnippet(text='and then and then you have also whether', start=5511.04, duration=5.119), FetchedTranscriptSnippet(text='to take the design option of uh', start=5514.159, duration=7.441), FetchedTranscriptSnippet(text='considering the LLM as ane or not and uh', start=5516.159, duration=7.681), FetchedTranscriptSnippet(text='even the number of layers of your LLM', start=5521.6, duration=4.4), FetchedTranscriptSnippet(text='and other hyperparameters like number of', start=5523.84, duration=3.68), FetchedTranscriptSnippet(text='heads', start=5526.0, duration=5.84), FetchedTranscriptSnippet(text='um size of the number of units in the', start=5527.52, duration=7.679), FetchedTranscriptSnippet(text='FFN all of that is still up for debates', start=5531.84, duration=5.2), FetchedTranscriptSnippet(text='uh in terms of like design decisions. So', start=5535.199, duration=4.561), FetchedTranscriptSnippet(text=\"it's not fixed.\", start=5537.04, duration=5.199), FetchedTranscriptSnippet(text='Uh and then another area of research I', start=5539.76, duration=5.76), FetchedTranscriptSnippet(text='want to mention is the data part which', start=5542.239, duration=5.121), FetchedTranscriptSnippet(text='is crucial.', start=5545.52, duration=5.76), FetchedTranscriptSnippet(text='So the first LLMs they enjoyed a', start=5547.36, duration=6.799), FetchedTranscriptSnippet(text='relatively clean state of things because', start=5551.28, duration=5.68), FetchedTranscriptSnippet(text='you could scrape the internet and hope', start=5554.159, duration=5.841), FetchedTranscriptSnippet(text='for a lot of data that was for sure', start=5556.96, duration=7.12), FetchedTranscriptSnippet(text='human generated. So you could learn', start=5560.0, duration=7.679), FetchedTranscriptSnippet(text='these patterns from quote unquote a high', start=5564.08, duration=6.48), FetchedTranscriptSnippet(text=\"quality source even though it's like not\", start=5567.679, duration=4.881), FetchedTranscriptSnippet(text='in high quality format when you look at', start=5570.56, duration=5.119), FetchedTranscriptSnippet(text='typical internet data but it was still', start=5572.56, duration=6.72), FetchedTranscriptSnippet(text='uh generated by human. So these days the', start=5575.679, duration=5.52), FetchedTranscriptSnippet(text='state has changed. You type anything you', start=5579.28, duration=5.28), FetchedTranscriptSnippet(text='want in your favorite search browser.', start=5581.199, duration=6.161), FetchedTranscriptSnippet(text='Chances are the first results are 80%', start=5584.56, duration=6.4), FetchedTranscriptSnippet(text='LLM generated. So are we doomed?', start=5587.36, duration=5.44), FetchedTranscriptSnippet(text='Maybe not', start=5590.96, duration=4.16), FetchedTranscriptSnippet(text='uh because actually you see the', start=5592.8, duration=5.359), FetchedTranscriptSnippet(text='development of more and more work in', start=5595.12, duration=5.36), FetchedTranscriptSnippet(text='data curation. So in the past you would', start=5598.159, duration=4.721), FetchedTranscriptSnippet(text='just scrape the whole internet and train', start=5600.48, duration=4.96), FetchedTranscriptSnippet(text='next token prediction on it. But now you', start=5602.88, duration=5.44), FetchedTranscriptSnippet(text='have more and more this work of curating', start=5605.44, duration=5.199), FetchedTranscriptSnippet(text='data sets of interest and you have', start=5608.32, duration=4.56), FetchedTranscriptSnippet(text='companies that work on it and you have', start=5610.639, duration=5.681), FetchedTranscriptSnippet(text='the emergence of newer', start=5612.88, duration=6.08), FetchedTranscriptSnippet(text='fine-tuning modes. So in the past you', start=5616.32, duration=5.52), FetchedTranscriptSnippet(text='had pre-training and then fine-tuning.', start=5618.96, duration=5.679), FetchedTranscriptSnippet(text='Now you have pre-training, mid training', start=5621.84, duration=4.879), FetchedTranscriptSnippet(text='and fine-tuning. And the mid-training', start=5624.639, duration=5.52), FetchedTranscriptSnippet(text='part trains still on a large corpus of', start=5626.719, duration=6.401), FetchedTranscriptSnippet(text='data but higher quality. So people are', start=5630.159, duration=6.241), FetchedTranscriptSnippet(text='finding ways around it. Um and I would', start=5633.12, duration=6.64), FetchedTranscriptSnippet(text=\"say the picture is not all grim but it's\", start=5636.4, duration=5.759), FetchedTranscriptSnippet(text='just that we need to do more work in', start=5639.76, duration=5.04), FetchedTranscriptSnippet(text='order to be um to have meaningful data', start=5642.159, duration=5.841), FetchedTranscriptSnippet(text='at hand. And the paper that is linked', start=5644.8, duration=5.439), FetchedTranscriptSnippet(text='and at the bottom of the of the slide is', start=5648.0, duration=6.48), FetchedTranscriptSnippet(text='dealing with the phenomenon of what if', start=5650.239, duration=7.041), FetchedTranscriptSnippet(text='you were training on LLM generated data', start=5654.48, duration=4.88), FetchedTranscriptSnippet(text=\"and it's talking about a concept called\", start=5657.28, duration=4.16), FetchedTranscriptSnippet(text='model collapse', start=5659.36, duration=4.4), FetchedTranscriptSnippet(text='and it says that', start=5661.44, duration=6.08), FetchedTranscriptSnippet(text='LLM generated text is typically less', start=5663.76, duration=5.28), FetchedTranscriptSnippet(text='diverse.', start=5667.52, duration=4.32), FetchedTranscriptSnippet(text='So the data distribution that you would', start=5669.04, duration=4.8), FetchedTranscriptSnippet(text='see at training time changes and it', start=5671.84, duration=5.04), FetchedTranscriptSnippet(text='leads to less meaningful learning at', start=5673.84, duration=4.56), FetchedTranscriptSnippet(text=\"training time which is why it's\", start=5676.88, duration=4.96), FetchedTranscriptSnippet(text='typically bad and it motivates the need', start=5678.4, duration=7.279), FetchedTranscriptSnippet(text='for more work on the data part.', start=5681.84, duration=7.04), FetchedTranscriptSnippet(text='Okay. Nice. Um and then you know even', start=5685.679, duration=5.361), FetchedTranscriptSnippet(text='taking a step back on the very', start=5688.88, duration=5.68), FetchedTranscriptSnippet(text=\"architecture we've been um using all\", start=5691.04, duration=6.56), FetchedTranscriptSnippet(text=\"along is it the best one? it's not it's\", start=5694.56, duration=6.48), FetchedTranscriptSnippet(text='not clear. So that itself is an area of', start=5697.6, duration=7.28), FetchedTranscriptSnippet(text='research and um future breakthroughs', start=5701.04, duration=7.36), FetchedTranscriptSnippet(text='might come from redesigning this uh this', start=5704.88, duration=6.52), FetchedTranscriptSnippet(text='architecture.', start=5708.4, duration=3.0), FetchedTranscriptSnippet(text='Okay. So in the past few years a lot of', start=5711.92, duration=6.719), FetchedTranscriptSnippet(text='the research that we have seen has been', start=5715.76, duration=5.84), FetchedTranscriptSnippet(text='on improving benchmarks', start=5718.639, duration=5.6), FetchedTranscriptSnippet(text='even more each time. So you have a set', start=5721.6, duration=5.2), FetchedTranscriptSnippet(text='of benchmarks. Everyone tries to get the', start=5724.239, duration=5.521), FetchedTranscriptSnippet(text=\"best results. So it's a natural trend\", start=5726.8, duration=4.64), FetchedTranscriptSnippet(text='because you want to have more and more', start=5729.76, duration=4.8), FetchedTranscriptSnippet(text='powerful models that fulfill all your', start=5731.44, duration=6.32), FetchedTranscriptSnippet(text=\"use cases. But let's say we reach a\", start=5734.56, duration=5.76), FetchedTranscriptSnippet(text='point where all the use cases we care', start=5737.76, duration=5.12), FetchedTranscriptSnippet(text='about are solved.', start=5740.32, duration=4.72), FetchedTranscriptSnippet(text='Then what?', start=5742.88, duration=4.319), FetchedTranscriptSnippet(text=\"So I think we're going to see the\", start=5745.04, duration=5.36), FetchedTranscriptSnippet(text='emergence of this second border of the', start=5747.199, duration=8.161), FetchedTranscriptSnippet(text='Parto Frontier where we care most about', start=5750.4, duration=8.319), FetchedTranscriptSnippet(text='making predictions from LLM cost', start=5755.36, duration=6.319), FetchedTranscriptSnippet(text='effective um and still very high', start=5758.719, duration=4.801), FetchedTranscriptSnippet(text='quality.', start=5761.679, duration=5.281), FetchedTranscriptSnippet(text='So uh we see this emergence of uh', start=5763.52, duration=7.6), FetchedTranscriptSnippet(text='smaller and smaller LLMs like I think it', start=5766.96, duration=6.64), FetchedTranscriptSnippet(text='has been dubbed small language models', start=5771.12, duration=7.36), FetchedTranscriptSnippet(text='SLM uh like in the literature and um', start=5773.6, duration=7.84), FetchedTranscriptSnippet(text='yeah typically you hear sometimes LLM', start=5778.48, duration=5.36), FetchedTranscriptSnippet(text='providers say that they lose money even', start=5781.44, duration=5.52), FetchedTranscriptSnippet(text='on the highest tier plans. So I think it', start=5783.84, duration=6.08), FetchedTranscriptSnippet(text='reflects the fact that you need to be', start=5786.96, duration=5.759), FetchedTranscriptSnippet(text='smarter in the compute that you spend', start=5789.92, duration=6.56), FetchedTranscriptSnippet(text='for serving LLM queries at test time and', start=5792.719, duration=5.761), FetchedTranscriptSnippet(text='uh yeah I think this this will motivate', start=5796.48, duration=4.719), FetchedTranscriptSnippet(text='more and more uh this line of research', start=5798.48, duration=6.44), FetchedTranscriptSnippet(text='in the coming years', start=5801.199, duration=3.721), FetchedTranscriptSnippet(text='and then there is another area that', start=5804.96, duration=4.32), FetchedTranscriptSnippet(text=\"we've not touched on at all in this\", start=5807.199, duration=4.881), FetchedTranscriptSnippet(text='class which is the hardware part. So', start=5809.28, duration=6.16), FetchedTranscriptSnippet(text='typically the kind of device that you', start=5812.08, duration=6.48), FetchedTranscriptSnippet(text='use to train these LLMs are GPUs which', start=5815.44, duration=6.88), FetchedTranscriptSnippet(text='are great at one thing matrix multiply.', start=5818.56, duration=6.639), FetchedTranscriptSnippet(text=\"Uh but the thing is uh we've kept these\", start=5822.32, duration=4.64), FetchedTranscriptSnippet(text='kinds of architectures to train our', start=5825.199, duration=4.321), FetchedTranscriptSnippet(text='models even though the architecture', start=5826.96, duration=6.159), FetchedTranscriptSnippet(text=\"doesn't only need matrix multiplies as a\", start=5829.52, duration=5.44), FetchedTranscriptSnippet(text='foundational', start=5833.119, duration=3.761), FetchedTranscriptSnippet(text='um', start=5834.96, duration=6.64), FetchedTranscriptSnippet(text='like atomic unit of compute. the uh self', start=5836.88, duration=6.96), FetchedTranscriptSnippet(text='attention world and the transformer', start=5841.6, duration=6.72), FetchedTranscriptSnippet(text='world has all these special needs. Um', start=5843.84, duration=8.72), FetchedTranscriptSnippet(text='you know the Q K transpose part we saw', start=5848.32, duration=7.359), FetchedTranscriptSnippet(text='was actually very expensive which has', start=5852.56, duration=6.4), FetchedTranscriptSnippet(text='motivated papers such as flash attention', start=5855.679, duration=7.361), FetchedTranscriptSnippet(text='to as Afin mentioned actually forgo of', start=5858.96, duration=6.88), FetchedTranscriptSnippet(text='some of the data for the sake of not', start=5863.04, duration=5.52), FetchedTranscriptSnippet(text='doing too much movement on the memory', start=5865.84, duration=4.48), FetchedTranscriptSnippet(text='side', start=5868.56, duration=4.0), FetchedTranscriptSnippet(text='even if it meant recomputing the same', start=5870.32, duration=4.319), FetchedTranscriptSnippet(text='things afterwards. And then a lot of', start=5872.56, duration=4.72), FetchedTranscriptSnippet(text='work has been on optimizing where the', start=5874.639, duration=6.241), FetchedTranscriptSnippet(text='flow of memory within the GPU resided.', start=5877.28, duration=6.56), FetchedTranscriptSnippet(text='And this shows that maybe you need a', start=5880.88, duration=7.04), FetchedTranscriptSnippet(text='more um optimized uh hardware', start=5883.84, duration=9.6), FetchedTranscriptSnippet(text='architecture in order to uh to to um to', start=5887.92, duration=7.92), FetchedTranscriptSnippet(text='solve these use cases. So there is a', start=5893.44, duration=5.44), FetchedTranscriptSnippet(text='recent paper that came out um that', start=5895.84, duration=6.56), FetchedTranscriptSnippet(text='actually encodes all of these operations', start=5898.88, duration=6.96), FetchedTranscriptSnippet(text='as part of the hardware. So in the past', start=5902.4, duration=7.12), FetchedTranscriptSnippet(text='the core um the core operation that the', start=5905.84, duration=6.879), FetchedTranscriptSnippet(text='GPU was great at is matrix multiply and', start=5909.52, duration=6.4), FetchedTranscriptSnippet(text='based on it you try to build all of the', start=5912.719, duration=6.561), FetchedTranscriptSnippet(text='input output that you want. But here', start=5915.92, duration=5.279), FetchedTranscriptSnippet(text='this paper that came out I think in', start=5919.28, duration=3.68), FetchedTranscriptSnippet(text='September', start=5921.199, duration=5.44), FetchedTranscriptSnippet(text='shows a proof of concept where you can', start=5922.96, duration=6.8), FetchedTranscriptSnippet(text='all do all of these computations as a', start=5926.639, duration=5.6), FetchedTranscriptSnippet(text='side effect of implementing input and', start=5929.76, duration=6.56), FetchedTranscriptSnippet(text='outputs with analog signals. So you have', start=5932.239, duration=5.601), FetchedTranscriptSnippet(text='all of these computations that are', start=5936.32, duration=4.0), FetchedTranscriptSnippet(text='embedded as part of the hardware and', start=5937.84, duration=5.92), FetchedTranscriptSnippet(text='based on pulses as input that simulates', start=5940.32, duration=8.0), FetchedTranscriptSnippet(text='your array values. These uh hardware', start=5943.76, duration=6.64), FetchedTranscriptSnippet(text='architectures', start=5948.32, duration=4.48), FetchedTranscriptSnippet(text='have some physical properties like you', start=5950.4, duration=6.56), FetchedTranscriptSnippet(text='could think of kirhoff uh law in the', start=5952.8, duration=7.68), FetchedTranscriptSnippet(text='like field of um I think intensity um', start=5956.96, duration=6.8), FetchedTranscriptSnippet(text='you can add them up and it uses', start=5960.48, duration=6.639), FetchedTranscriptSnippet(text='properties like this to have um what you', start=5963.76, duration=7.2), FetchedTranscriptSnippet(text='need as input and just read out the', start=5967.119, duration=7.921), FetchedTranscriptSnippet(text='result uh as output.', start=5970.96, duration=7.759), FetchedTranscriptSnippet(text='So uh when uh the paper simulated this', start=5975.04, duration=6.48), FetchedTranscriptSnippet(text='kind of architecture uh they observed', start=5978.719, duration=6.241), FetchedTranscriptSnippet(text='without uh too much surprise quite a bit', start=5981.52, duration=5.92), FetchedTranscriptSnippet(text='of improvement both on the latency and', start=5984.96, duration=6.0), FetchedTranscriptSnippet(text='energy saving parts. Uh both explained', start=5987.44, duration=5.279), FetchedTranscriptSnippet(text=\"because you don't need to do the\", start=5990.96, duration=4.8), FetchedTranscriptSnippet(text='computations yourself. Uh you just get', start=5992.719, duration=5.44), FetchedTranscriptSnippet(text='them as a side effect of uh of your', start=5995.76, duration=5.399), FetchedTranscriptSnippet(text='hardware.', start=5998.159, duration=3.0), FetchedTranscriptSnippet(text='Now I want to take a step back and look', start=6001.84, duration=6.96), FetchedTranscriptSnippet(text='at our users at our use cases of LLMs', start=6005.199, duration=7.201), FetchedTranscriptSnippet(text='today and what could lie ahead. Uh what', start=6008.8, duration=6.399), FetchedTranscriptSnippet(text='could be the most exciting for you. So', start=6012.4, duration=5.12), FetchedTranscriptSnippet(text=\"today we've seen that in just a few\", start=6015.199, duration=5.281), FetchedTranscriptSnippet(text='years I think it has become quite', start=6017.52, duration=5.119), FetchedTranscriptSnippet(text='important to know how to use them if you', start=6020.48, duration=4.32), FetchedTranscriptSnippet(text='want to speed up everything you you do', start=6022.639, duration=5.441), FetchedTranscriptSnippet(text='in your daily life. So a few lectures', start=6024.8, duration=6.08), FetchedTranscriptSnippet(text='ago we talked about the coding case', start=6028.08, duration=5.76), FetchedTranscriptSnippet(text='where um do you have all these AI', start=6030.88, duration=6.88), FetchedTranscriptSnippet(text='assistant coding tools that um enable', start=6033.84, duration=7.92), FetchedTranscriptSnippet(text='enable you to turn into code some', start=6037.76, duration=7.04), FetchedTranscriptSnippet(text='natural language prompts. So you just', start=6041.76, duration=5.28), FetchedTranscriptSnippet(text='you know ask for something and it will', start=6044.8, duration=3.76), FetchedTranscriptSnippet(text='uh help you do that task with a', start=6047.04, duration=6.4), FetchedTranscriptSnippet(text='so-called agent mode. And um this is', start=6048.56, duration=6.48), FetchedTranscriptSnippet(text='just something that you would do as an', start=6053.44, duration=6.0), FetchedTranscriptSnippet(text='engineer. But even beyond that uh other', start=6055.04, duration=6.88), FetchedTranscriptSnippet(text='use cases are deeply impacted by it', start=6059.44, duration=4.799), FetchedTranscriptSnippet(text='because you have um a lot of problems', start=6061.92, duration=7.12), FetchedTranscriptSnippet(text='that today can be turned into a text to', start=6064.239, duration=8.48), FetchedTranscriptSnippet(text='query or text to code problem. Uh so you', start=6069.04, duration=5.599), FetchedTranscriptSnippet(text='could think of even the visualization', start=6072.719, duration=5.121), FetchedTranscriptSnippet(text='world. you could um so for example there', start=6074.639, duration=6.641), FetchedTranscriptSnippet(text='was a launch from Google uh recently', start=6077.84, duration=6.0), FetchedTranscriptSnippet(text='that showed that you could uh generate', start=6081.28, duration=4.56), FetchedTranscriptSnippet(text='visualizations on the fly based on some', start=6083.84, duration=5.44), FetchedTranscriptSnippet(text='principles and this is already changing', start=6085.84, duration=6.64), FetchedTranscriptSnippet(text='um quite a bit the', start=6089.28, duration=6.08), FetchedTranscriptSnippet(text='picture of what you can do today. Uh', start=6092.48, duration=5.12), FetchedTranscriptSnippet(text='something else that I think is used by', start=6095.36, duration=4.16), FetchedTranscriptSnippet(text='most people actually today when using', start=6097.6, duration=5.68), FetchedTranscriptSnippet(text='these chat bots is general uh like being', start=6099.52, duration=5.679), FetchedTranscriptSnippet(text='a general assistant. So you ask about', start=6103.28, duration=4.48), FetchedTranscriptSnippet(text='common facts and all the facts that it', start=6105.199, duration=4.241), FetchedTranscriptSnippet(text='has learned at training time becomes', start=6107.76, duration=5.84), FetchedTranscriptSnippet(text='useful. It browses the web um more', start=6109.44, duration=6.4), FetchedTranscriptSnippet(text='efficiently than you and converts into', start=6113.6, duration=4.16), FetchedTranscriptSnippet(text='natural language the things that you', start=6115.84, duration=5.6), FetchedTranscriptSnippet(text='care about. Um but then there are also', start=6117.76, duration=6.56), FetchedTranscriptSnippet(text='other domains that were impacted by it.', start=6121.44, duration=6.32), FetchedTranscriptSnippet(text='So you could think creativity where a', start=6124.32, duration=6.64), FetchedTranscriptSnippet(text='lot of jobs such as marketing uh or', start=6127.76, duration=6.879), FetchedTranscriptSnippet(text='others rely on uh getting something out', start=6130.96, duration=6.32), FetchedTranscriptSnippet(text='of a blank page and usually if you start', start=6134.639, duration=4.801), FetchedTranscriptSnippet(text=\"from a draft it's much easier to get\", start=6137.28, duration=4.56), FetchedTranscriptSnippet(text='something done rather than just thinking', start=6139.44, duration=4.88), FetchedTranscriptSnippet(text=\"of it from from scratch. So it's used as\", start=6141.84, duration=6.0), FetchedTranscriptSnippet(text='an eight here. And also one use case', start=6144.32, duration=5.68), FetchedTranscriptSnippet(text=\"that I've seen in class that I think is\", start=6147.84, duration=5.2), FetchedTranscriptSnippet(text='is great that some of you do you know', start=6150.0, duration=5.119), FetchedTranscriptSnippet(text='sometimes I talk about something or Afin', start=6153.04, duration=3.44), FetchedTranscriptSnippet(text='talks about something and I see people', start=6155.119, duration=5.12), FetchedTranscriptSnippet(text='typing typing on JGPT related concepts', start=6156.48, duration=5.6), FetchedTranscriptSnippet(text=\"and I think it's very smart to do that\", start=6160.239, duration=3.92), FetchedTranscriptSnippet(text='because brainstorming', start=6162.08, duration=5.36), FetchedTranscriptSnippet(text='the concepts that you learn is great for', start=6164.159, duration=5.121), FetchedTranscriptSnippet(text='actually grasping the concepts of', start=6167.44, duration=5.04), FetchedTranscriptSnippet(text='interest and getting that early feedback', start=6169.28, duration=6.879), FetchedTranscriptSnippet(text='loop is uh very useful for learning. So', start=6172.48, duration=6.96), FetchedTranscriptSnippet(text='I have a lot of hopes regarding uh how', start=6176.159, duration=6.241), FetchedTranscriptSnippet(text='like how great of a time it is for you', start=6179.44, duration=5.279), FetchedTranscriptSnippet(text='to learn as opposed to maybe uh you know', start=6182.4, duration=5.759), FetchedTranscriptSnippet(text='a nice time maybe 10 years ago. So yeah', start=6184.719, duration=5.121), FetchedTranscriptSnippet(text='keep doing that and I think it will be a', start=6188.159, duration=3.921), FetchedTranscriptSnippet(text='growing use case.', start=6189.84, duration=5.2), FetchedTranscriptSnippet(text='So looking forward', start=6192.08, duration=6.0), FetchedTranscriptSnippet(text='um so I said tomorrow on the slide but', start=6195.04, duration=7.52), FetchedTranscriptSnippet(text='actually two days ago there was a launch', start=6198.08, duration=7.52), FetchedTranscriptSnippet(text='uh that went in the direction of what I', start=6202.56, duration=5.92), FetchedTranscriptSnippet(text='was thinking about which is uh like all', start=6205.6, duration=6.32), FetchedTranscriptSnippet(text='the agentic things that we talked about', start=6208.48, duration=6.719), FetchedTranscriptSnippet(text='they are still very much confined into', start=6211.92, duration=6.0), FetchedTranscriptSnippet(text='people that know about the field like', start=6215.199, duration=5.04), FetchedTranscriptSnippet(text=\"everyday people they wouldn't typically\", start=6217.92, duration=3.84), FetchedTranscriptSnippet(text='use quote unquote', start=6220.239, duration=4.241), FetchedTranscriptSnippet(text='agentic workflows. So I think one field', start=6221.76, duration=4.72), FetchedTranscriptSnippet(text='of development that we will see more and', start=6224.48, duration=4.8), FetchedTranscriptSnippet(text='more is all these use cases being', start=6226.48, duration=6.32), FetchedTranscriptSnippet(text='democratized. So people can now create', start=6229.28, duration=6.32), FetchedTranscriptSnippet(text='things that can be useful to them with', start=6232.8, duration=4.399), FetchedTranscriptSnippet(text='easier', start=6235.6, duration=3.28), FetchedTranscriptSnippet(text='um you know mediums just natural', start=6237.199, duration=4.881), FetchedTranscriptSnippet(text='language no need to code.', start=6238.88, duration=7.759), FetchedTranscriptSnippet(text='uh moving forward uh to later um so all', start=6242.08, duration=6.48), FetchedTranscriptSnippet(text='this AI assistant coding that I was', start=6246.639, duration=3.921), FetchedTranscriptSnippet(text='mentioning you could think of it as', start=6248.56, duration=4.159), FetchedTranscriptSnippet(text='helping you browse the internet in a', start=6250.56, duration=4.72), FetchedTranscriptSnippet(text='very natural fashion so it seems right', start=6252.719, duration=5.44), FetchedTranscriptSnippet(text=\"now when you just execute tasks you're\", start=6255.28, duration=5.68), FetchedTranscriptSnippet(text='way too microscopic in what you do and', start=6258.159, duration=5.841), FetchedTranscriptSnippet(text='this is typically what uh AI assistant', start=6260.96, duration=5.52), FetchedTranscriptSnippet(text='could help you do so there are like', start=6264.0, duration=4.88), FetchedTranscriptSnippet(text='recent product launches that reflect', start=6266.48, duration=5.44), FetchedTranscriptSnippet(text='these growing interest such as chat', start=6268.88, duration=6.319), FetchedTranscriptSnippet(text=\"GPT's atlas. So I think it launched in\", start=6271.92, duration=5.36), FetchedTranscriptSnippet(text=\"October. I don't know if they released\", start=6275.199, duration=6.081), FetchedTranscriptSnippet(text='some public number uh on usage. I', start=6277.28, duration=6.8), FetchedTranscriptSnippet(text=\"suspect it's still timid because you\", start=6281.28, duration=4.959), FetchedTranscriptSnippet(text='still have challenges when it comes to', start=6284.08, duration=6.32), FetchedTranscriptSnippet(text='security. Uh anyone could inject some uh', start=6286.239, duration=7.121), FetchedTranscriptSnippet(text='bad prompt in there and maybe exfiltrate', start=6290.4, duration=5.52), FetchedTranscriptSnippet(text=\"things from you, but I'm sure the\", start=6293.36, duration=6.0), FetchedTranscriptSnippet(text='community will come up with uh more ways', start=6295.92, duration=6.319), FetchedTranscriptSnippet(text='to get around it. So in the past you had', start=6299.36, duration=5.839), FetchedTranscriptSnippet(text='https for example to say that the', start=6302.239, duration=4.801), FetchedTranscriptSnippet(text='connection was secure. Maybe tomorrow', start=6305.199, duration=4.321), FetchedTranscriptSnippet(text=\"you'll have some certificate that will\", start=6307.04, duration=4.4), FetchedTranscriptSnippet(text='guarantee that a site website is safe', start=6309.52, duration=4.8), FetchedTranscriptSnippet(text='for AI assistant browsing.', start=6311.44, duration=6.48), FetchedTranscriptSnippet(text='um and looking even at a higher level,', start=6314.32, duration=7.04), FetchedTranscriptSnippet(text='maybe just browsing on your uh desktop', start=6317.92, duration=6.0), FetchedTranscriptSnippet(text='or your mobile phone at the LLM level.', start=6321.36, duration=6.4), FetchedTranscriptSnippet(text='Uh at the OS level might be um something', start=6323.92, duration=8.0), FetchedTranscriptSnippet(text='that the LLM can u can help. So when we', start=6327.76, duration=9.12), FetchedTranscriptSnippet(text='talked about agents, we mentioned how um', start=6331.92, duration=7.6), FetchedTranscriptSnippet(text='nonreliable it could be because as you', start=6336.88, duration=4.239), FetchedTranscriptSnippet(text='have more and more steps, the', start=6339.52, duration=4.4), FetchedTranscriptSnippet(text='probability for a failure increases and', start=6341.119, duration=5.04), FetchedTranscriptSnippet(text='stabilizing predictions is something of', start=6343.92, duration=3.92), FetchedTranscriptSnippet(text='interest.', start=6346.159, duration=4.321), FetchedTranscriptSnippet(text='And um even in the longer run, I think', start=6347.84, duration=5.44), FetchedTranscriptSnippet(text='one test that we can have in mind as to', start=6350.48, duration=6.48), FetchedTranscriptSnippet(text=\"how far we've come is whether the common\", start=6353.28, duration=6.0), FetchedTranscriptSnippet(text='use case of having a customer service', start=6356.96, duration=5.44), FetchedTranscriptSnippet(text='that is served by AI is truly useful. So', start=6359.28, duration=4.879), FetchedTranscriptSnippet(text=\"I don't know about you, but every time I\", start=6362.4, duration=4.0), FetchedTranscriptSnippet(text=\"have a problem and I'm on the phone and\", start=6364.159, duration=4.721), FetchedTranscriptSnippet(text='I hear some AI assistant maybe LLM', start=6366.4, duration=5.2), FetchedTranscriptSnippet(text='powered robot and like you know quick', start=6368.88, duration=5.44), FetchedTranscriptSnippet(text=\"quick I want a human. I don't want that.\", start=6371.6, duration=5.599), FetchedTranscriptSnippet(text='And uh and I think it shows how hard', start=6374.32, duration=5.44), FetchedTranscriptSnippet(text='this space is, the space of problems is', start=6377.199, duration=6.801), FetchedTranscriptSnippet(text='because human has way more dimensions of', start=6379.76, duration=8.08), FetchedTranscriptSnippet(text='of value that an LLM could bring. So', start=6384.0, duration=5.44), FetchedTranscriptSnippet(text='empathy,', start=6387.84, duration=3.279), FetchedTranscriptSnippet(text='um like groundedness, there are some', start=6389.44, duration=4.08), FetchedTranscriptSnippet(text='things that you and I we perceive as you', start=6391.119, duration=3.681), FetchedTranscriptSnippet(text='know things that make sense even though', start=6393.52, duration=3.679), FetchedTranscriptSnippet(text=\"they're not in our system prompts. So I\", start=6394.8, duration=4.08), FetchedTranscriptSnippet(text='think there there are hard problems to', start=6397.199, duration=4.96), FetchedTranscriptSnippet(text='to solve there.', start=6398.88, duration=6.64), FetchedTranscriptSnippet(text='And even moving forward', start=6402.159, duration=6.0), FetchedTranscriptSnippet(text='um there are some key challenges that we', start=6405.52, duration=5.92), FetchedTranscriptSnippet(text='have with the current architecture. So', start=6408.159, duration=5.921), FetchedTranscriptSnippet(text='um we saw during the class that you had', start=6411.44, duration=5.92), FetchedTranscriptSnippet(text='to go through a training process that u', start=6414.08, duration=6.4), FetchedTranscriptSnippet(text='went to like fix some weights but these', start=6417.36, duration=6.24), FetchedTranscriptSnippet(text='weights are not changing afterwards. And', start=6420.48, duration=5.6), FetchedTranscriptSnippet(text='we use tricks such as rags a rag or', start=6423.6, duration=5.76), FetchedTranscriptSnippet(text='tools to get around this issue. But', start=6426.08, duration=5.2), FetchedTranscriptSnippet(text='could we think of a system that learns', start=6429.36, duration=4.08), FetchedTranscriptSnippet(text='continuously? I think that is an open', start=6431.28, duration=4.0), FetchedTranscriptSnippet(text='question. Then there is a topic of', start=6433.44, duration=4.32), FetchedTranscriptSnippet(text='hallucinations which I put into', start=6435.28, duration=4.32), FetchedTranscriptSnippet(text=\"quotation marks because I'm not sure if\", start=6437.76, duration=4.0), FetchedTranscriptSnippet(text=\"it's fair to say that the LLM\", start=6439.6, duration=4.8), FetchedTranscriptSnippet(text=\"hallucinates just because we've trained\", start=6441.76, duration=5.12), FetchedTranscriptSnippet(text='the LLM to predict the next token by', start=6444.4, duration=7.279), FetchedTranscriptSnippet(text='nature, not map statements to facts. So', start=6446.88, duration=9.2), FetchedTranscriptSnippet(text='hallucinating is in some sense a core', start=6451.679, duration=8.641), FetchedTranscriptSnippet(text='design uh choice of the these LLMs. Uh', start=6456.08, duration=6.24), FetchedTranscriptSnippet(text='personalization, interpretability,', start=6460.32, duration=6.08), FetchedTranscriptSnippet(text='safety, the the list goes on.', start=6462.32, duration=7.76), FetchedTranscriptSnippet(text='Um now I want to briefly cover', start=6466.4, duration=6.08), FetchedTranscriptSnippet(text='what you can um like how you can', start=6470.08, duration=4.32), FetchedTranscriptSnippet(text='exercise this muscle of staying up to', start=6472.48, duration=5.84), FetchedTranscriptSnippet(text='date from now. So you have archive that', start=6474.4, duration=5.92), FetchedTranscriptSnippet(text='uh usually contains all these great', start=6478.32, duration=4.399), FetchedTranscriptSnippet(text='greatest and latest papers that you can', start=6480.32, duration=5.359), FetchedTranscriptSnippet(text='take a look at. Of course the venues', start=6482.719, duration=5.44), FetchedTranscriptSnippet(text='like new rips right now are great to', start=6485.679, duration=6.881), FetchedTranscriptSnippet(text='highlight papers um like some papers', start=6488.159, duration=8.0), FetchedTranscriptSnippet(text='uh and then uh I highly encourage you be', start=6492.56, duration=6.24), FetchedTranscriptSnippet(text='besides the papers uh looking at the', start=6496.159, duration=4.801), FetchedTranscriptSnippet(text='associated code bases that the authors', start=6498.8, duration=4.24), FetchedTranscriptSnippet(text=\"provide. So right now it's a common\", start=6500.96, duration=4.4), FetchedTranscriptSnippet(text='place to just provide the implementation', start=6503.04, duration=4.4), FetchedTranscriptSnippet(text='of what you are proposing and I think', start=6505.36, duration=3.52), FetchedTranscriptSnippet(text=\"it's very insightful to learn the\", start=6507.44, duration=3.04), FetchedTranscriptSnippet(text='concepts', start=6508.88, duration=4.08), FetchedTranscriptSnippet(text='and uh there is a paper with code that', start=6510.48, duration=4.159), FetchedTranscriptSnippet(text='existed in the past and that has been', start=6512.96, duration=5.44), FetchedTranscriptSnippet(text='replaced by hugging facees uh trending', start=6514.639, duration=6.401), FetchedTranscriptSnippet(text='papers which I think is a good place to', start=6518.4, duration=7.279), FetchedTranscriptSnippet(text='to take a look at the latest uh methods', start=6521.04, duration=8.079), FetchedTranscriptSnippet(text='and then um on the uh social network', start=6525.679, duration=9.681), FetchedTranscriptSnippet(text='side uh Twitter or X uh has a lot of u a', start=6529.119, duration=7.681), FetchedTranscriptSnippet(text='lot of the latest that is often', start=6535.36, duration=2.72), FetchedTranscriptSnippet(text='discussed. So you have a strong', start=6536.8, duration=2.8), FetchedTranscriptSnippet(text='community there and if you have an', start=6538.08, duration=4.32), FetchedTranscriptSnippet(text='account on that social media you have a', start=6539.6, duration=5.84), FetchedTranscriptSnippet(text='lot of great people to follow um to like', start=6542.4, duration=6.08), FetchedTranscriptSnippet(text='stay updated but also you have resources', start=6545.44, duration=6.719), FetchedTranscriptSnippet(text='on YouTube uh with a highlight on Yanik', start=6548.48, duration=6.56), FetchedTranscriptSnippet(text='Kilchshire which I think was the first', start=6552.159, duration=5.121), FetchedTranscriptSnippet(text='uh YouTuber to cover the transformer', start=6555.04, duration=5.599), FetchedTranscriptSnippet(text='paper back in 2017 in great detail and I', start=6557.28, duration=5.28), FetchedTranscriptSnippet(text='think you know some of these YouTubers', start=6560.639, duration=4.881), FetchedTranscriptSnippet(text=\"they're very good at um talking through\", start=6562.56, duration=6.4), FetchedTranscriptSnippet(text='um like papers in great detail.', start=6565.52, duration=6.8), FetchedTranscriptSnippet(text='And another highlight is Andrish Karpath', start=6568.96, duration=6.0), FetchedTranscriptSnippet(text='uh who was at Stanford about 10 years', start=6572.32, duration=5.12), FetchedTranscriptSnippet(text=\"ago and he's I think one of the best\", start=6574.96, duration=4.56), FetchedTranscriptSnippet(text='educators out there. So I highly', start=6577.44, duration=4.96), FetchedTranscriptSnippet(text='recommend his videos and you have a', start=6579.52, duration=6.32), FetchedTranscriptSnippet(text='company blogs that are also great', start=6582.4, duration=4.96), FetchedTranscriptSnippet(text='and', start=6585.84, duration=3.76), FetchedTranscriptSnippet(text='uh like this study guide that we', start=6587.36, duration=5.12), FetchedTranscriptSnippet(text=\"associated with the class. Um, so we've\", start=6589.6, duration=4.96), FetchedTranscriptSnippet(text=\"had it for this year and what we'll try\", start=6592.48, duration=4.96), FetchedTranscriptSnippet(text='to do uh in the coming years is try to', start=6594.56, duration=4.96), FetchedTranscriptSnippet(text='keep it updated at least on a yearly', start=6597.44, duration=5.199), FetchedTranscriptSnippet(text='basis. So you can consider this resource', start=6599.52, duration=6.32), FetchedTranscriptSnippet(text=\"as maybe some companion and we've got\", start=6602.639, duration=5.841), FetchedTranscriptSnippet(text='the chance to collaborate with uh', start=6605.84, duration=4.64), FetchedTranscriptSnippet(text='experts around the world to make it', start=6608.48, duration=3.44), FetchedTranscriptSnippet(text='available in other languages in case', start=6610.48, duration=4.0), FetchedTranscriptSnippet(text=\"you're interested.\", start=6611.92, duration=4.799), FetchedTranscriptSnippet(text='And taking a step back, just want to say', start=6614.48, duration=5.36), FetchedTranscriptSnippet(text='that Afin and I were very grateful to', start=6616.719, duration=6.4), FetchedTranscriptSnippet(text='teach this class this quarter. Um, thank', start=6619.84, duration=5.839), FetchedTranscriptSnippet(text='you so much for coming here, you know,', start=6623.119, duration=5.12), FetchedTranscriptSnippet(text='on Friday evening, which is quite', start=6625.679, duration=4.081), FetchedTranscriptSnippet(text='telling cuz, uh, you know, Friday', start=6628.239, duration=4.0), FetchedTranscriptSnippet(text='evening is usually time for fun, not for', start=6629.76, duration=4.8), FetchedTranscriptSnippet(text=\"lectures. And also now I think it's\", start=6632.239, duration=4.321), FetchedTranscriptSnippet(text='probably your last lecture of the whole', start=6634.56, duration=4.96), FetchedTranscriptSnippet(text='quarter because uh, yeah, next week is', start=6636.56, duration=5.04), FetchedTranscriptSnippet(text='finals. So yeah, thank you for coming', start=6639.52, duration=3.92), FetchedTranscriptSnippet(text='and for asking all these great', start=6641.6, duration=4.16), FetchedTranscriptSnippet(text='questions. You were one of the reasons', start=6643.44, duration=4.64), FetchedTranscriptSnippet(text='why this class was so great and', start=6645.76, duration=4.0), FetchedTranscriptSnippet(text='interactive.', start=6648.08, duration=4.24), FetchedTranscriptSnippet(text='Also, thank you to the folks who are', start=6649.76, duration=5.359), FetchedTranscriptSnippet(text='watching online from home. I was one of', start=6652.32, duration=5.359), FetchedTranscriptSnippet(text='you uh eight years ago. I would uh', start=6655.119, duration=4.08), FetchedTranscriptSnippet(text='almost never go to class, always', start=6657.679, duration=3.361), FetchedTranscriptSnippet(text='watching lectures from home from a cozy', start=6659.199, duration=3.841), FetchedTranscriptSnippet(text='place. I hope the lectures were', start=6661.04, duration=3.599), FetchedTranscriptSnippet(text='entertaining', start=6663.04, duration=4.639), FetchedTranscriptSnippet(text='and that you got something from it.', start=6664.639, duration=6.881), FetchedTranscriptSnippet(text=\"Um, and I couldn't conclude\", start=6667.679, duration=6.721), FetchedTranscriptSnippet(text='uh without bringing our favorite teddy', start=6671.52, duration=7.119), FetchedTranscriptSnippet(text='bear one last time. Thanking you uh all', start=6674.4, duration=6.319), FetchedTranscriptSnippet(text='for your attention and wishing you all', start=6678.639, duration=6.52), FetchedTranscriptSnippet(text='the best. Thank you.', start=6680.719, duration=4.44)], video_id='Q86qzJ1K1Ss', language='English (auto-generated)', language_code='en', is_generated=True)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c00911-17b8-4f46-a3bf-adadd2d12712",
   "metadata": {},
   "source": [
    "## Text Splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6ab57208-baba-411e-b28f-ab7ac76f6072",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
    "chunk = splitter.create_documents([transcript])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2a8ab23e-4ce5-46a2-b6bf-72312fd38254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1682cb50-aadd-4bae-8a03-5413ba5d09ee",
   "metadata": {},
   "source": [
    "## Step 2 - Indexing (Embedding Generation and Storing in Vector Store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1d24b988-a143-4107-9d7e-0fb53d0a4a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\ankit\\anaconda3\\lib\\site-packages (5.2.2)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from sentence-transformers) (5.0.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.3.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: shellingham in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (69.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (0.14.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ankit\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3571de52-da44-4e02-827b-a106afe8c688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3c67244e-052c-45ea-8fff-e06c1aa88fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c435871a973144dbbddd25197f6b34c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "vector_store = FAISS.from_documents(chunk, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b27528c2-5eef-4c07-b1c4-4957411f0ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '7d4bd177-68c3-4375-94fc-0a6380c9c203',\n",
       " 1: '3f8801a2-137e-434c-917c-c583fdc70746',\n",
       " 2: 'b2ce37d6-743e-47f4-b65f-3a6ba9d19c32',\n",
       " 3: '24c0598f-ee65-42e1-9225-35894790558a',\n",
       " 4: 'ad30538e-8029-40c5-a031-31231e4b3a49',\n",
       " 5: 'e3d987f6-fee5-460e-b193-6c6035f6d538',\n",
       " 6: '326a8b41-7560-47f4-919e-dd1826edf4d8',\n",
       " 7: 'bed5decd-0d70-475c-8c08-d9e0c6d79875',\n",
       " 8: 'fcd1f3b8-82ca-4877-a2c7-15efc51c3d71',\n",
       " 9: '99c2a350-26ed-4624-855d-51ca5ff8fb6c',\n",
       " 10: '26791360-9998-4b8d-ab35-fc7a487d55a0',\n",
       " 11: '8addbced-91f4-4b48-9834-f016e5ea50d2',\n",
       " 12: '45578c91-71c4-422e-851f-b71751d27954',\n",
       " 13: '95250f53-5490-4432-aae6-1e64242e0391',\n",
       " 14: '9fbfddf7-d12c-4bc3-81af-646a33eedf81',\n",
       " 15: '1df32ac1-aa4a-4d39-a0d1-182bf06e61b8',\n",
       " 16: 'bbf6b353-629f-433d-b073-fdd50f7eab19',\n",
       " 17: '39bf8a26-372c-4e6c-a0d9-49e1f0ad1ce1',\n",
       " 18: '256d9729-262d-404b-a4b0-7debf3d2562c',\n",
       " 19: '60208128-af83-40f5-9534-b84ac1e0126f',\n",
       " 20: '60126c46-6dbe-4079-8490-2f46eb3abfbd',\n",
       " 21: '8094333d-ff9f-4839-b920-6e28cfda5bf3',\n",
       " 22: '0ea5a7c2-7716-4f1c-be36-12fe9cc9f473',\n",
       " 23: '0b5c36d4-f3a6-4eb9-8988-a2de218922d3',\n",
       " 24: '39e5871d-c887-49f2-86b3-8379bee3e0fc',\n",
       " 25: '78bc476c-f30a-468e-9e3b-c130a3fd6dee',\n",
       " 26: '1086fac6-3768-4c12-9ed6-5a827ee86481',\n",
       " 27: 'd30f32ff-4fd3-42fa-aa29-176f635cd190',\n",
       " 28: '30f51149-1864-4793-9470-e9fa117654d1',\n",
       " 29: 'f1bb0d8b-36ec-48b6-bc06-8987ff4c101a',\n",
       " 30: 'c1159eaa-ca01-47c8-98b6-a9fa6d1eb27f',\n",
       " 31: 'e3314ad0-be7d-4c1c-935a-60e3fdd52a5f',\n",
       " 32: '5b6ca233-4d0e-4a46-8537-67b5ec23f607',\n",
       " 33: '628443ea-9a74-4d12-906d-43103451feef',\n",
       " 34: '1b08361c-1937-450d-9295-52850d4c1675',\n",
       " 35: 'afc09dd9-e7d5-4032-b4ae-2ce8a9b7db2c',\n",
       " 36: 'daddcadf-ac94-42b6-ae66-015fdd376233',\n",
       " 37: 'd60556b7-c45b-4aa8-95df-c077e9a9c713',\n",
       " 38: '2bc3c01c-3b9a-47c2-9ce4-b589a756937a',\n",
       " 39: 'ee6f3007-a2a7-4250-9422-a518056ae589',\n",
       " 40: '4dc5c922-18bb-463e-9e15-d28e1f9d57f3',\n",
       " 41: '69ba00ab-00d9-4155-8daf-f56bf1c0cf11',\n",
       " 42: 'cff9892b-0ae0-4ede-a96a-99ce1df8fc43',\n",
       " 43: '5d947990-2dd1-4f3c-ac27-e6cdd7020c25',\n",
       " 44: 'e2ac8962-e0c8-4d75-b60d-7aa589f484d1',\n",
       " 45: 'e7bd4425-30d3-499e-baf7-26859e3ed86e',\n",
       " 46: 'b2379381-2204-4061-81cb-dd7818d973cd',\n",
       " 47: '5789a97a-7590-4fcd-b799-443bcf3d92b2',\n",
       " 48: '9f92ea32-4acf-4d6e-9194-98356d1ef3fc',\n",
       " 49: '73190efd-da1b-43af-88ea-f3cfc74a6e62',\n",
       " 50: 'cdf2164c-c86e-43bd-bda0-a1e76eef0b4b',\n",
       " 51: '353fac88-27b4-407d-8755-211dbb319ecf',\n",
       " 52: '031194f9-a11a-4d31-ae86-b478f96b90d8',\n",
       " 53: '588a8d62-1672-4123-8a1b-49921d45ac3e',\n",
       " 54: '5e1ce8ec-eefd-4caf-bc50-3748d495f173',\n",
       " 55: '9d28008a-749c-4d8f-8ed6-53a324ce743b',\n",
       " 56: '827be903-abbe-493e-8c62-1869cb096bf9',\n",
       " 57: '4fb82013-7aa8-417b-a0db-f9095c0daff1',\n",
       " 58: 'fa7a4769-ded6-4a87-8dcf-cd0319374afe',\n",
       " 59: 'adcb2233-7882-4c79-8dea-d9f53930b96f',\n",
       " 60: '30b6c1c5-f8a9-4272-a25c-b7705e0459e0',\n",
       " 61: '3706f00a-51e1-45aa-b57b-4f39bedc7f2c',\n",
       " 62: '3140e8bc-f7ec-41f2-a586-89f479e92af8',\n",
       " 63: 'cb28d03f-1191-4ded-9c74-6f3bffeced94',\n",
       " 64: '42bec073-912d-43b2-915b-e71d3eecdb80',\n",
       " 65: 'e820f545-83c8-41b1-9fe7-457cd7eb8d58',\n",
       " 66: '25a062a2-a836-4214-ab3a-272d6621a734',\n",
       " 67: 'b9b931f2-a5b1-4683-aa1d-ce5ead4d1c3e',\n",
       " 68: 'df02618c-a1e8-4dc4-9d30-19c24c231c50',\n",
       " 69: '9592d661-d4ed-4ff9-81c7-b168782f9345',\n",
       " 70: '2facd5e4-9574-4d57-84a3-01a91e60b6bf',\n",
       " 71: 'b5f58263-3363-425a-843f-16f986272a9f',\n",
       " 72: '98b12065-9a0d-4495-bb15-e07149743e04',\n",
       " 73: '8fcaf721-d092-4b6d-94b0-60df1cb7ff10',\n",
       " 74: '8d0d472c-53fd-4f5a-9b63-04d235feea9e',\n",
       " 75: 'cea7a3af-1ec7-41d1-8051-e94d37cf3e4a',\n",
       " 76: '2b9e4912-1d21-43dc-b676-c9df581a413b',\n",
       " 77: '082c1e50-3ff4-49fe-a1e3-0416b7ea6ffb',\n",
       " 78: 'ed4f56d6-019a-4897-99b9-55d7772362a7',\n",
       " 79: 'c3c7e533-a8fb-4da8-aeca-76e19ae5cd39',\n",
       " 80: 'aa8822ed-0bf0-442f-94d3-6c2a685129d8',\n",
       " 81: 'cdfda724-2861-4d45-a90e-3ea3fbd8987e',\n",
       " 82: '3dddbef7-59ee-4cd9-81da-1752e8b1df03',\n",
       " 83: 'dc62de3e-ef6f-4275-b45d-36bb0fa3276f',\n",
       " 84: 'd4fb857f-5cb6-4440-b85b-9754d11ee4d9',\n",
       " 85: '8f743823-2dfe-4945-90e0-9321b58d4390',\n",
       " 86: '2eabb1d2-e4a9-4eb3-9d52-10f85e33f078',\n",
       " 87: 'a0940f67-8dd7-448d-b0e9-b1e72d8fd40e',\n",
       " 88: '1694280c-e11d-4fa4-a0b0-1d887d088703',\n",
       " 89: '2f6e4c00-53b8-4116-9ab2-ba94e5c16d32',\n",
       " 90: '8b601d96-0a7d-4738-afbc-582d35bc034b',\n",
       " 91: 'bbbfb18f-a48c-47d2-9d29-0782bf542f10',\n",
       " 92: '8cfbd304-0bb6-4b00-929c-77acd02f42b4',\n",
       " 93: 'b779abe8-a7e9-4376-8753-9a1ce9ec6b4a',\n",
       " 94: 'fc7cbf54-7160-417d-9dda-bbd11df14c09',\n",
       " 95: '641ba04d-8e5a-49f9-a3ec-d00c3bbc6956',\n",
       " 96: '6f62198c-2d73-461b-bb8f-8a17c497d15b'}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.index_to_docstore_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b78e6c22-bdf6-407b-8352-aef84f1912a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.get_by_ids([\"a5241452-cce2-4df5-9d51-aa2548fb3494\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2cb093-c879-42c7-94fb-84a318ac1526",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "308a4e8f-740e-486d-b26e-a7f9f9b5c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type = \"similarity\", search_kwargs = {\"k\":4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b5bc6a89-9205-4565-baf1-156e316d28a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000028C71896DB0>, search_kwargs={'k': 4})"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a3a581ff-0e32-4d59-93df-aa52be5470a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='2facd5e4-9574-4d57-84a3-01a91e60b6bf', metadata={}, page_content=\"we saw the vision transformer uh that was borrowing the transformer for vision related tasks. But we also saw that things from other domains could also be used in the text world. And that's what we saw with diffusion LMS. Um, and so this is probably, you know, of course a subset of everything that's happening. And so with that, I think we're concluding our second item of our menu. And um, I'm going to just give it to Shervin. Thank you, Ashin. And with that, welcome to the last part of the season finale of CM295. And as Ein mentioned, now is the time for some closing thoughts and see um what we can get away from this class and uh concepts that are u neighboring to it. Uh so first Afin went through the concept of diffusion and images and we saw some similarities. we could draw with text. And now we're going to see what kinds of inspirations have both modalities taken from each other. And we're going to see um that actually like a lot of things can be um reused. So the first thing that\"),\n",
       " Document(id='4fb82013-7aa8-417b-a0db-f9095c0daff1', metadata={}, page_content=\"we have some um like different startups. So Inception is one of them uh that made headlines I believe a couple of weeks ago or last week no sorry a month ago um that also are pursuing this route. Um, so all of that to say that this direction is a very trendy and hot direction that potentially has a lot of promise. But the key issue with this is that text is discrete whereas images are continuous. And we're going to see why that distinction that I just made matters. So I'm going to try to explain to you what diffusion is in two minutes. So in the image world in order to generate an image what people typically do is they start from noise and then they try to generate some image. Now now you may wonder okay why noise? Well, you cannot do something that's um you know uh auto reggressive because I guess like if you were to say okay let's predict the pixels one at a time uh it's just not tractable because there are many pixel in in an image and this is typically not how you produce uh an\"),\n",
       " Document(id='b2379381-2204-4061-81cb-dd7818d973cd', metadata={}, page_content='bit like you would look at it in practice as a human. And people had hypothesized that such such a bias such an indictive bias would actually make sense for something like a vision task. So you contrast that with the vision transformer which is actually letting all parts of the image attend to one another which has on the other side very low inductive bias. So what this paper showed was if you give your model enough data then it will actually learn how to classify um I guess your images in this in this classes. So this was like kind of a remarkable results. Um so I think this is like pretty remarkable and a nice extension of everything we saw. So with that in mind, um I want us to just go through an end toend example of how you would process an image and go through that um vit so vision transformer in order to make your um prediction. So here you would take uh like your favorite image that you would just split into patches. So here you can think of you predefining some uh fixed size'),\n",
       " Document(id='326a8b41-7560-47f4-919e-dd1826edf4d8', metadata={}, page_content=\"the way we consider positions because in the original transformer paper positions were encoded in an absolute way as in each position had its own embedding and this embedding was added to the token embedding. But then if we think about it positions actually we don't really care about the absolute position. We care about the relative position between tokens and in particular we care about how far tokens are in the self attention computation. Which is why we saw this methods that is now quite popular called rotary position embeddings aka rope that is now quite used. And it is a method that rotates query and keys both of which happen in the self attention computation. And so here um what is uh quantified here is purely a function of the relative distance between um two tokens and not only that it is something that is uh taken care of in the self attention layer which is what we care about. So this was one big improvement and then we saw some other improvements especially when it came to\")]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"what is the context of the video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72362dad-3f99-43e1-97f9-2a5663c587d7",
   "metadata": {},
   "source": [
    "## Step 3 -> Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "40c989be-9485-40e9-8c70-abaddf6c4181",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ec1c9fd3-b672-4003-80f3-0853f6589bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template = \"\"\"You are a helpful assistant.\n",
    "      Answer ONLY from the provided transcript context.\n",
    "      If the context is insufficient, just say you don't know.\n",
    "\n",
    "    {context}\n",
    "    Question: {question}\"\"\",\n",
    "    input_variable = [\"context\",\"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "df8a2393-865b-4bdd-8b9e-8b1754565815",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is the topic of LLM discussed in this video? if yes then what was discussed\"\n",
    "retrieved_docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f8fcaa01-927d-43fd-94ab-1dc517e789e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='2facd5e4-9574-4d57-84a3-01a91e60b6bf', metadata={}, page_content=\"we saw the vision transformer uh that was borrowing the transformer for vision related tasks. But we also saw that things from other domains could also be used in the text world. And that's what we saw with diffusion LMS. Um, and so this is probably, you know, of course a subset of everything that's happening. And so with that, I think we're concluding our second item of our menu. And um, I'm going to just give it to Shervin. Thank you, Ashin. And with that, welcome to the last part of the season finale of CM295. And as Ein mentioned, now is the time for some closing thoughts and see um what we can get away from this class and uh concepts that are u neighboring to it. Uh so first Afin went through the concept of diffusion and images and we saw some similarities. we could draw with text. And now we're going to see what kinds of inspirations have both modalities taken from each other. And we're going to see um that actually like a lot of things can be um reused. So the first thing that\"),\n",
       " Document(id='827be903-abbe-493e-8c62-1869cb096bf9', metadata={}, page_content=\"So I just want to say that when I say that uh this paradigm is not paralyzable I just want to emphasize on the fact that it's a inference time that I'm saying training time you can actually paralyze that quite well. So as I mentioned that's one of the reasons why people have tried to look at other paradigms and in particular um so if you know about diffusion you know that it works very well for the vision domain and so people have tried adapting this paradigm for the text generation case and uh so this is like a bunch of screenshots we took from announcement that happened this year. So for instance uh earlier this year there was an experimental text diffusion model from Google that they presented during the IO event um which was very impressive because it led to a lot of speedups. And then we have some um like different startups. So Inception is one of them uh that made headlines I believe a couple of weeks ago or last week no sorry a month ago um that also are pursuing this route.\"),\n",
       " Document(id='fc7cbf54-7160-417d-9dda-bbd11df14c09', metadata={}, page_content=\"Kilchshire which I think was the first uh YouTuber to cover the transformer paper back in 2017 in great detail and I think you know some of these YouTubers they're very good at um talking through um like papers in great detail. And another highlight is Andrish Karpath uh who was at Stanford about 10 years ago and he's I think one of the best educators out there. So I highly recommend his videos and you have a company blogs that are also great and uh like this study guide that we associated with the class. Um, so we've had it for this year and what we'll try to do uh in the coming years is try to keep it updated at least on a yearly basis. So you can consider this resource as maybe some companion and we've got the chance to collaborate with uh experts around the world to make it available in other languages in case you're interested. And taking a step back, just want to say that Afin and I were very grateful to teach this class this quarter. Um, thank you so much for coming here, you\"),\n",
       " Document(id='b5f58263-3363-425a-843f-16f986272a9f', metadata={}, page_content=\"now we're going to see what kinds of inspirations have both modalities taken from each other. And we're going to see um that actually like a lot of things can be um reused. So the first thing that I want to mention in terms of what has been reused is the architecture part. So Afinen uh mentioned this uh like diffusion concept that was born in the field of images but that was taken for text and was able to yield uh lower latency like a higher speedups which is great when you're a user. Uh so this was one example of a win. Uh and then on the other direction um traditionally images have been dealing with um convolutions mostly as as uh model architecture type but uh these papers saw that replacing convolutions with transformers uh was very good even um yielding better results. So all these latest diffusionbased papers in the field of images typically use transformers and then here I'm linking one of the papers that Afin already uh briefly went through. But not only uh is it the\")]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "239b3d48-d645-442f-bc43-e3e04fd3725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0a44e883-2578-42d6-a49b-2eb0f40acc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"we saw the vision transformer uh that was borrowing the transformer for vision related tasks. But we also saw that things from other domains could also be used in the text world. And that's what we saw with diffusion LMS. Um, and so this is probably, you know, of course a subset of everything that's happening. And so with that, I think we're concluding our second item of our menu. And um, I'm going to just give it to Shervin. Thank you, Ashin. And with that, welcome to the last part of the season finale of CM295. And as Ein mentioned, now is the time for some closing thoughts and see um what we can get away from this class and uh concepts that are u neighboring to it. Uh so first Afin went through the concept of diffusion and images and we saw some similarities. we could draw with text. And now we're going to see what kinds of inspirations have both modalities taken from each other. And we're going to see um that actually like a lot of things can be um reused. So the first thing that\\n\\nSo I just want to say that when I say that uh this paradigm is not paralyzable I just want to emphasize on the fact that it's a inference time that I'm saying training time you can actually paralyze that quite well. So as I mentioned that's one of the reasons why people have tried to look at other paradigms and in particular um so if you know about diffusion you know that it works very well for the vision domain and so people have tried adapting this paradigm for the text generation case and uh so this is like a bunch of screenshots we took from announcement that happened this year. So for instance uh earlier this year there was an experimental text diffusion model from Google that they presented during the IO event um which was very impressive because it led to a lot of speedups. And then we have some um like different startups. So Inception is one of them uh that made headlines I believe a couple of weeks ago or last week no sorry a month ago um that also are pursuing this route.\\n\\nKilchshire which I think was the first uh YouTuber to cover the transformer paper back in 2017 in great detail and I think you know some of these YouTubers they're very good at um talking through um like papers in great detail. And another highlight is Andrish Karpath uh who was at Stanford about 10 years ago and he's I think one of the best educators out there. So I highly recommend his videos and you have a company blogs that are also great and uh like this study guide that we associated with the class. Um, so we've had it for this year and what we'll try to do uh in the coming years is try to keep it updated at least on a yearly basis. So you can consider this resource as maybe some companion and we've got the chance to collaborate with uh experts around the world to make it available in other languages in case you're interested. And taking a step back, just want to say that Afin and I were very grateful to teach this class this quarter. Um, thank you so much for coming here, you\\n\\nnow we're going to see what kinds of inspirations have both modalities taken from each other. And we're going to see um that actually like a lot of things can be um reused. So the first thing that I want to mention in terms of what has been reused is the architecture part. So Afinen uh mentioned this uh like diffusion concept that was born in the field of images but that was taken for text and was able to yield uh lower latency like a higher speedups which is great when you're a user. Uh so this was one example of a win. Uh and then on the other direction um traditionally images have been dealing with um convolutions mostly as as uh model architecture type but uh these papers saw that replacing convolutions with transformers uh was very good even um yielding better results. So all these latest diffusionbased papers in the field of images typically use transformers and then here I'm linking one of the papers that Afin already uh briefly went through. But not only uh is it the\""
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8bc371b7-452b-48e8-9537-a9a2ba3fec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "575b6e9d-c824-42d8-9720-68b737b6bd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text=\"You are a helpful assistant.\\n      Answer ONLY from the provided transcript context.\\n      If the context is insufficient, just say you don't know.\\n\\n    we saw the vision transformer uh that was borrowing the transformer for vision related tasks. But we also saw that things from other domains could also be used in the text world. And that's what we saw with diffusion LMS. Um, and so this is probably, you know, of course a subset of everything that's happening. And so with that, I think we're concluding our second item of our menu. And um, I'm going to just give it to Shervin. Thank you, Ashin. And with that, welcome to the last part of the season finale of CM295. And as Ein mentioned, now is the time for some closing thoughts and see um what we can get away from this class and uh concepts that are u neighboring to it. Uh so first Afin went through the concept of diffusion and images and we saw some similarities. we could draw with text. And now we're going to see what kinds of inspirations have both modalities taken from each other. And we're going to see um that actually like a lot of things can be um reused. So the first thing that\\n\\nSo I just want to say that when I say that uh this paradigm is not paralyzable I just want to emphasize on the fact that it's a inference time that I'm saying training time you can actually paralyze that quite well. So as I mentioned that's one of the reasons why people have tried to look at other paradigms and in particular um so if you know about diffusion you know that it works very well for the vision domain and so people have tried adapting this paradigm for the text generation case and uh so this is like a bunch of screenshots we took from announcement that happened this year. So for instance uh earlier this year there was an experimental text diffusion model from Google that they presented during the IO event um which was very impressive because it led to a lot of speedups. And then we have some um like different startups. So Inception is one of them uh that made headlines I believe a couple of weeks ago or last week no sorry a month ago um that also are pursuing this route.\\n\\nKilchshire which I think was the first uh YouTuber to cover the transformer paper back in 2017 in great detail and I think you know some of these YouTubers they're very good at um talking through um like papers in great detail. And another highlight is Andrish Karpath uh who was at Stanford about 10 years ago and he's I think one of the best educators out there. So I highly recommend his videos and you have a company blogs that are also great and uh like this study guide that we associated with the class. Um, so we've had it for this year and what we'll try to do uh in the coming years is try to keep it updated at least on a yearly basis. So you can consider this resource as maybe some companion and we've got the chance to collaborate with uh experts around the world to make it available in other languages in case you're interested. And taking a step back, just want to say that Afin and I were very grateful to teach this class this quarter. Um, thank you so much for coming here, you\\n\\nnow we're going to see what kinds of inspirations have both modalities taken from each other. And we're going to see um that actually like a lot of things can be um reused. So the first thing that I want to mention in terms of what has been reused is the architecture part. So Afinen uh mentioned this uh like diffusion concept that was born in the field of images but that was taken for text and was able to yield uh lower latency like a higher speedups which is great when you're a user. Uh so this was one example of a win. Uh and then on the other direction um traditionally images have been dealing with um convolutions mostly as as uh model architecture type but uh these papers saw that replacing convolutions with transformers uh was very good even um yielding better results. So all these latest diffusionbased papers in the field of images typically use transformers and then here I'm linking one of the papers that Afin already uh briefly went through. But not only uh is it the\\n    Question: is the topic of Farm in rench discussed in this video? if yes then what was discussed\")"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1225680-a260-4ca8-bee4-1279a55c293f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
